import streamlit as st
import pandas as pd
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
import zipfile
import io
import plotly.express as px
import re
import json
from data_storage import DataStorage
from keyword_tool import KeywordTool
from content_scorer import ContentScorer

APP_TITLE = "GEO æ™ºèƒ½å†…å®¹ä¼˜åŒ–å¹³å°"

# ------------------- é¡µé¢é…ç½® & æç®€ç¾å­¦ CSSï¼ˆäº§å“çº§ç²¾ä¿®ï¼Œä»ç„¶å…‹åˆ¶ï¼‰ -------------------
st.set_page_config(page_title="GEO æ™ºèƒ½å†…å®¹ä¼˜åŒ–å¹³å°", layout="wide", initial_sidebar_state="expanded")

st.markdown(
    """
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=Noto+Sans+SC:wght@400;500;600&display=swap');

:root{
  --bg:#FFFFFF;
  --panel:#F7FAFC;
  --text:#1A202C;
  --muted:#4A5568;
  --border:#E2E8F0;
  --primary:#2563EB;
  --shadow: 0 1px 2px rgba(16,24,40,.04), 0 6px 16px rgba(16,24,40,.06);
  --radius:12px;
}

.stApp { background: var(--bg); }
html, body, [class*="css"]  { font-family: "Inter","Noto Sans SC",-apple-system,BlinkMacSystemFont,"Segoe UI",Arial,sans-serif; color: var(--text); }

.block-container { max-width: 980px; padding-top: 1.6rem; padding-bottom: 3.5rem; }

/* Sidebar æ›´è½» */
section[data-testid="stSidebar"] { background: var(--panel); border-right: 1px solid var(--border); }

/* æ ‡é¢˜å±‚çº§ */
h1 { font-size: 2.15rem; font-weight: 600; letter-spacing: -0.4px; margin-bottom: 1.0rem; }
h2 { font-size: 1.25rem; font-weight: 600; color: var(--text); margin: 1.8rem 0 0.75rem; }
p, li { color: var(--muted); }

/* æŒ‰é’® */
.stButton > button { border-radius: 10px; }

/* è¾“å…¥ */
.stTextInput input, .stTextArea textarea, .stSelectbox div[data-baseweb="select"] {
  border-radius: 10px !important;
}
.stTextInput input, .stTextArea textarea {
  border: 1px solid var(--border) !important;
  padding: 0.75rem !important;
}
.stTextInput input:focus, .stTextArea textarea:focus {
  border-color: var(--primary) !important;
  box-shadow: 0 0 0 3px rgba(37,99,235,.12) !important;
}

/* Tabs äº§å“åŒ– */
.stTabs [data-baseweb="tab-list"] { gap: 8px; }
.stTabs [data-baseweb="tab"]{
  padding: 10px 14px;
  border-radius: 10px;
  background: transparent;
  border: 1px solid transparent;
}
.stTabs [aria-selected="true"]{
  background: rgba(37,99,235,.08);
  border: 1px solid rgba(37,99,235,.20);
}

/* â€œå¡ç‰‡æ„Ÿâ€ï¼šå°½é‡ä½¿ç”¨ st.container(border=True) */
div[data-testid="stVerticalBlockBorderWrapper"]{
  border-radius: var(--radius);
  box-shadow: var(--shadow);
}
/* ========== Button radius override (works across Streamlit versions) ========== */

/* st.button */
div[data-testid="stButton"] button {
  border-radius: 10px !important;
}

/* st.form_submit_button */
div[data-testid="stFormSubmitButton"] button {
  border-radius: 10px !important;
}

/* BaseWeb buttons (Streamlit internal) */
button[data-testid^="baseButton-"] {
  border-radius: 10px !important;
}

/* é˜²æ­¢å‡ºç°â€œåœ†å½¢å¤–åœˆ/æè¾¹â€ */
div[data-testid="stButton"] button:focus,
div[data-testid="stButton"] button:focus-visible,
div[data-testid="stFormSubmitButton"] button:focus,
div[data-testid="stFormSubmitButton"] button:focus-visible,
button[data-testid^="baseButton-"]:focus,
button[data-testid^="baseButton-"]:focus-visible {
  outline: none !important;
  box-shadow: 0 0 0 3px rgba(37,99,235,.12) !important;
}

/* æ¬¡çº§æŒ‰é’®æ›´è½»ï¼Œå’Œ Tabs æ›´åè°ƒï¼ˆä¸ä¼šåƒâ€œåœ†åœˆâ€ï¼‰ */
button[data-testid="baseButton-secondary"],
div[data-testid="stButton"] button[kind="secondary"],
div[data-testid="stFormSubmitButton"] button[kind="secondary"] {
  background: #FFFFFF !important;
  border: 1px solid #E2E8F0 !important;
  color: #1A202C !important;
}

button[data-testid="baseButton-secondary"]:hover {
  background: rgba(37,99,235,.04) !important;
  border-color: rgba(37,99,235,.35) !important;
}

/* primary æŒ‰é’®ç»´æŒä½ çš„è“è‰²ï¼Œä½†ç»Ÿä¸€åœ†è§’ */
button[data-testid="baseButton-primary"]{
    border-radius: 10px !important;
}

/* KPI å¡ç‰‡ç»Ÿä¸€å¤§å° */
div[data-testid="stMetricContainer"] {
    min-height: 130px !important;
    height: 130px !important;
    display: flex !important;
    flex-direction: column !important;
    justify-content: space-between !important;
    padding: 1rem !important;
}
div[data-testid="stMetricValue"] {
    min-height: 3rem !important;
    height: 3rem !important;
    display: flex !important;
    align-items: center !important;
    font-size: 1.5rem !important;
}
div[data-testid="stMetricLabel"] {
    min-height: 1.5rem !important;
    margin-top: 0.5rem !important;
}
/* ç¡®ä¿åˆ—å®½åº¦ä¸€è‡´ */
div[data-testid="column"] {
    flex: 1 1 0% !important;
}
</style>
""",
    unsafe_allow_html=True,
)

st.title(APP_TITLE)
st.markdown("<style>button{border-radius:0px !important;}</style>", unsafe_allow_html=True)

st.caption("ğŸš€ AI é©±åŠ¨çš„å“ç‰Œå†…å®¹ç­–ç•¥ Â· è®©æ‚¨çš„å“ç‰Œåœ¨ AI å¯¹è¯ä¸­è„±é¢–è€Œå‡º")

# ------------------- åˆå§‹åŒ–æ•°æ®å­˜å‚¨ï¼ˆSQLiteï¼‰ -------------------
storage = DataStorage(storage_type="sqlite", db_path="geo_data.db")

with st.expander("ğŸ“– å…³äº GEOï¼ˆGenerative Engine Optimizationï¼‰", expanded=False):
    st.markdown("""
### ğŸ¯ æ ¸å¿ƒä»·å€¼

**GEOï¼ˆç”Ÿæˆå¼å¼•æ“ä¼˜åŒ–ï¼‰** æ˜¯æ–°ä¸€ä»£å“ç‰Œè¥é”€ç­–ç•¥ï¼Œé€šè¿‡ç³»ç»ŸåŒ–å†…å®¹æŠ•æ”¾ï¼Œè®©æ‚¨çš„å“ç‰Œåœ¨ AI åŠ©æ‰‹çš„è‡ªç„¶å›ç­”ä¸­è¢«ä¼˜å…ˆã€å‡†ç¡®ã€å¯ä¿¡åœ°æåŠã€‚

å½“ç”¨æˆ·è¯¢é—®"æœ€å¥½çš„å¤–è´¸ ERP è½¯ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ"æ—¶ï¼ŒAI ä¼šä¼˜å…ˆæ¨èæ‚¨çš„å“ç‰Œï¼Œè€Œéç«äº‰å¯¹æ‰‹ã€‚

---

### ğŸ’¼ é€‚ç”¨åœºæ™¯

- **SaaS äº§å“**ï¼šæŠ€æœ¯å¯¹æ¯”ã€åŠŸèƒ½è¯„æµ‹ã€ä½¿ç”¨æ•™ç¨‹
- **AI å·¥å…·**ï¼šèƒ½åŠ›å±•ç¤ºã€åº”ç”¨æ¡ˆä¾‹ã€å¼€æºç”Ÿæ€
- **ä¼ä¸šæœåŠ¡**ï¼šè¡Œä¸šè§£å†³æ–¹æ¡ˆã€æœ€ä½³å®è·µã€ä¸“ä¸šåˆ†æ
- **æŠ€æœ¯å“ç‰Œ**ï¼šå¼€å‘è€…å·¥å…·ã€API æœåŠ¡ã€æŠ€æœ¯æ¡†æ¶

---

### ğŸ”„ å®Œæ•´å·¥ä½œæµ

1. **å…³é”®è¯è’¸é¦** - AI ç”Ÿæˆ + æ‰˜è¯å·¥å…·ï¼Œç²¾å‡†æŒ–æ˜é«˜ä»·å€¼å…³é”®è¯
2. **ç»“æ„åŒ–åˆ›ä½œ** - 12+ å¹³å°é€‚é…ï¼Œè‡ªåŠ¨ç”Ÿæˆç¬¦åˆ GEO åŸåˆ™çš„ä¸“ä¸šå†…å®¹
3. **æ–‡ç« ä¼˜åŒ–** - å°†ç°æœ‰å†…å®¹ä¼˜åŒ–ä¸º GEO å‹å¥½æ ¼å¼ï¼Œæå‡è¢«å¼•ç”¨æ¦‚ç‡
4. **å¤šæ¨¡å‹éªŒè¯** - å®æ—¶éªŒè¯å“ç‰ŒæåŠç‡ï¼Œå¯¹æ¯”ç«å“è¡¨ç°ï¼Œæ•°æ®é©±åŠ¨ä¼˜åŒ–

---

### ğŸŒ è¦†ç›–å¹³å°

**å†…å®¹å‘å¸ƒå¹³å°**ï¼šçŸ¥ä¹ã€å°çº¢ä¹¦ã€CSDNã€Bç«™ã€å¤´æ¡å·ã€GitHubã€å¾®ä¿¡å…¬ä¼—å·ã€æŠ–éŸ³ã€ç™¾å®¶å·ã€ç½‘æ˜“å·ã€ä¼é¹…å·ã€ç®€ä¹¦

**AI éªŒè¯å¹³å°**ï¼šDeepSeekã€é€šä¹‰åƒé—®ã€è±†åŒ…ã€æ–‡å¿ƒä¸€è¨€ã€Kimiã€ChatGPTã€Groq ç­‰ä¸»æµå¤§æ¨¡å‹

---

### ğŸ“Š é¢„æœŸæ•ˆæœ

- âœ… **å“ç‰ŒæåŠç‡æå‡**ï¼šåœ¨ AI å›ç­”ä¸­çš„å‡ºç°é¢‘ç‡æ˜¾è‘—å¢åŠ 
- âœ… **æœç´¢æ’åä¼˜åŒ–**ï¼šå†…å®¹è¢«å¤§æ¨¡å‹ä¼˜å…ˆå¼•ç”¨ï¼Œé—´æ¥æå‡ SEO
- âœ… **å“ç‰Œæƒå¨æ€§**ï¼šå¤šå¹³å°ã€å¤šè§’åº¦å†…å®¹å»ºç«‹ä¸“ä¸šå½¢è±¡
- âœ… **ç«å“ä¼˜åŠ¿**ï¼šé€šè¿‡æ•°æ®å¯¹æ¯”ï¼Œå‘ç°å¹¶å¼ºåŒ–å·®å¼‚åŒ–ä¼˜åŠ¿
""")

# ------------------- Session Stateï¼šæŒä¹…åŒ–æ¯ä¸ªé˜¶æ®µäº§ç‰©ï¼ˆè§£å†³â€œæ¶ˆå¤±â€ï¼‰ -------------------
def ss_init(key, default):
    if key not in st.session_state:
        st.session_state[key] = default


ss_init(
    "cfg",
    {
        "gen_provider": "DeepSeek",
        "gen_api_key": "sk-a95eda59dd494ab3b56197cc0020e61d",
        "verify_providers": ["DeepSeek"],
        "verify_keys": {"DeepSeek": "sk-a95eda59dd494ab3b56197cc0020e61d"},
        "brand": "æ±‡ä¿¡äº‘AIè½¯ä»¶",
        "advantages": "AIèµ‹èƒ½å¤–è´¸ERPã€æ‰“é€ å¤–è´¸æ™ºèƒ½æ–°å¼•æ“ã€AIé©±åŠ¨å‹ERPã€èµ‹èƒ½å¤–è´¸å…¨æµç¨‹ç®¡ç†ã€å…¨é“¾è·¯ä»·å€¼é—­ç¯",
        "competitors": "å—åŒ—è½¯ä»¶\nç¿è´è½¯ä»¶\nå­šç›Ÿè½¯ä»¶\nå°æ»¡è½¯ä»¶",
        "temperature": 0.7,
    },
)
ss_init("cfg_applied", False)
ss_init("cfg_valid", False)
ss_init("cfg_errors", [])

# æ¨¡å—1ï¼šå…³é”®è¯
ss_init("keywords", [])
ss_init("kw_last_num", 40)
ss_init("kw_generation_mode", "AIç”Ÿæˆ")  # ç”Ÿæˆæ¨¡å¼ï¼šAIç”Ÿæˆ / æ‰˜è¯å·¥å…· / æ··åˆæ¨¡å¼
ss_init("wordbanks", None)  # è¯åº“å­—å…¸
ss_init("keyword_tool", KeywordTool())  # æ‰˜è¯å·¥å…·å®ä¾‹

# æ¨¡å—2ï¼šå†…å®¹
ss_init("generated_contents", [])  # list[dict]
ss_init("zip_bytes", None)
ss_init("zip_filename", "")

# æ¨¡å—3ï¼šæ–‡ç« ä¼˜åŒ–
ss_init("optimized_article", "")
ss_init("opt_changes", "")
ss_init("opt_platform", "é€šç”¨ä¼˜åŒ–")

# æ¨¡å—4ï¼šéªŒè¯
ss_init("verify_combined", None)  # DataFrame or None
ss_init("verify_last_queries", "")

# ------------------- å·¥å…·å‡½æ•° -------------------
INVALID_FS_CHARS = r'<>:"/\\|?*\n\r\t'


def sanitize_filename(name: str, max_len: int = 80) -> str:
    if not name:
        return "untitled"
    name = name.strip()
    name = re.sub(rf"[{re.escape(INVALID_FS_CHARS)}]", "_", name)
    name = re.sub(r"_+", "_", name).strip("_")
    return name[:max_len] if len(name) > max_len else name


def safe_decode_uploaded(uploaded) -> str:
    if not uploaded:
        return ""
    b = uploaded.getvalue()
    for enc in ("utf-8-sig", "utf-8", "gb18030"):
        try:
            return b.decode(enc)
        except Exception:
            pass
    return b.decode("utf-8", errors="replace")


def extract_json_array(text: str):
    """ä»æ¨¡å‹è¾“å‡ºä¸­æŠ½å– JSON æ•°ç»„ï¼ˆJsonOutputParser å¤±è´¥æ—¶å…œåº•ï¼‰ã€‚"""
    if not text:
        return None
    m = re.search(r"\[[\s\S]*\]", text)
    if not m:
        return None
    try:
        return json.loads(m.group(0))
    except Exception:
        return None


def validate_cfg(cfg: dict):
    """ä¿ç•™ä½ åŸæœ¬çš„â€œå¿…é¡»å¡«å†™æ‰€æœ‰ API Keyâ€çº¦æŸï¼Œä½†ä¸ st.stopï¼šæ”¹ä¸ºç¦ç”¨æŒ‰é’® + æç¤ºã€‚"""
    errors = []
    if not cfg.get("gen_api_key", "").strip():
        errors.append("ç”Ÿæˆ&ä¼˜åŒ– LLM çš„ API Key æœªå¡«å†™")

    verify_providers = cfg.get("verify_providers", [])
    verify_keys = cfg.get("verify_keys", {})
    if not verify_providers:
        errors.append("è‡³å°‘é€‰æ‹©ä¸€ä¸ªéªŒè¯æ¨¡å‹")

    for vp in verify_providers:
        if not verify_keys.get(vp, "").strip():
            errors.append(f"éªŒè¯æ¨¡å‹ {vp} çš„ API Key æœªå¡«å†™")

    return (len(errors) == 0), errors


def model_defaults(provider: str) -> str:
    if provider == "DeepSeek":
        return "deepseek-chat"
    if provider == "OpenAI (GPT)":
        return "gpt-4o-mini"
    if provider == "Tongyi (é€šä¹‰åƒé—®)":
        return "qwen-max"
    if provider == "Groq":
        return "llama3-70b-8192"
    if provider == "Moonshot (Kimi)":
        return "moonshot-v1-128k"
    if provider == "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰":
        return ""  # è±†åŒ…ä½¿ç”¨ ENDPOINT_IDï¼Œä¸éœ€è¦æ¨¡å‹å
    if provider == "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰":
        return "ernie-bot-turbo"
    return ""


# ------------------- ç¼“å­˜ LLM å®¢æˆ·ç«¯ï¼ˆæ˜¾è‘—é™ä½â€œé¢‘ç¹ Loadingâ€ï¼‰ -------------------
@st.cache_resource(show_spinner=False)
def build_llm(provider: str, api_key: str, model: str, temperature: float):
    """
    - ä½¿ç”¨ cache_resource ç¼“å­˜å®¢æˆ·ç«¯ï¼Œé¿å…æ¯æ¬¡ rerun é‡å»º
    - Tongyi / Moonshotï¼šä¿ç•™ä½ åŸåŠŸèƒ½è·¯å¾„ï¼ŒåŒæ—¶æä¾›æ›´ç¨³çš„ import å…œåº•
    """
    if provider == "DeepSeek":
        from langchain_deepseek import ChatDeepSeek

        return ChatDeepSeek(api_key=api_key, model=model, temperature=temperature)

    if provider == "OpenAI (GPT)":
        from langchain_openai import ChatOpenAI

        return ChatOpenAI(api_key=api_key, model=model, temperature=temperature)

    if provider == "Tongyi (é€šä¹‰åƒé—®)":
        try:
            from langchain_community.chat_models import ChatTongyi

            return ChatTongyi(api_key=api_key, model=model, model_kwargs={"temperature": temperature})
        except Exception:
            from langchain_aliyun import ChatTongyi  # type: ignore

            return ChatTongyi(api_key=api_key, model=model, temperature=temperature)

    if provider == "Groq":
        from langchain_groq import ChatGroq

        return ChatGroq(api_key=api_key, model=model, temperature=temperature)

    if provider == "Moonshot (Kimi)":
        try:
            from langchain_moonshot import ChatMoonshot  # type: ignore

            return ChatMoonshot(api_key=api_key, model=model, temperature=temperature)
        except Exception:
            from langchain_community.chat_models import MoonshotChat  # type: ignore

            return MoonshotChat(api_key=api_key, model=model, temperature=temperature)

    if provider == "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰":
        try:
            # å°è¯•ä½¿ç”¨ volcengine-python-sdk[ark]
            from volcengine.ark import Ark
            from langchain_core.language_models.chat_models import BaseChatModel
            from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
            from langchain_core.outputs import ChatGeneration, ChatResult
            from typing import List, Optional, Any
            
            class ChatDoubao(BaseChatModel):
                """è±†åŒ…èŠå¤©æ¨¡å‹å°è£…ï¼ˆLangChain å…¼å®¹ï¼‰"""
                volc_ak: str
                volc_sk: str
                endpoint_id: str
                temperature: float = 0.7
                
                def __init__(self, volc_ak: str, volc_sk: str, endpoint_id: str, temperature: float = 0.7):
                    super().__init__(temperature=temperature)
                    self.volc_ak = volc_ak
                    self.volc_sk = volc_sk
                    self.endpoint_id = endpoint_id
                    self.temperature = temperature
                    self.client = Ark(ak=volc_ak, sk=volc_sk)
                
                def _generate(self, messages: List[BaseMessage], stop: Optional[List[str]] = None, run_manager: Optional[Any] = None, **kwargs: Any) -> ChatResult:
                    # è½¬æ¢æ¶ˆæ¯æ ¼å¼
                    volc_messages = []
                    for msg in messages:
                        if isinstance(msg, SystemMessage):
                            volc_messages.append({"role": "system", "content": msg.content})
                        elif isinstance(msg, HumanMessage):
                            volc_messages.append({"role": "user", "content": msg.content})
                        elif isinstance(msg, AIMessage):
                            volc_messages.append({"role": "assistant", "content": msg.content})
                        else:
                            volc_messages.append({"role": "user", "content": str(msg.content)})
                    
                    response = self.client.chat.completions.create(
                        model=self.endpoint_id,
                        messages=volc_messages,
                        temperature=self.temperature,
                    )
                    
                    ai_message = AIMessage(content=response.choices[0].message.content)
                    return ChatResult(generations=[ChatGeneration(message=ai_message)])
                
                @property
                def _llm_type(self) -> str:
                    return "doubao"
            
            # è±†åŒ…çš„ api_key æ ¼å¼ï¼šaccess_key:secret_key:endpoint_id
            parts = api_key.split(":")
            if len(parts) >= 3:
                return ChatDoubao(volc_ak=parts[0], volc_sk=parts[1], endpoint_id=parts[2], temperature=temperature)
            else:
                raise ValueError("è±†åŒ… API Key æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºï¼šaccess_key:secret_key:endpoint_idï¼ˆç”¨å†’å·åˆ†éš”ï¼‰")
        except ImportError:
            # å°è¯•å…¶ä»–å¯¼å…¥æ–¹å¼
            try:
                from volcenginesdkarkruntime import Ark
                # ä½¿ç”¨ç›¸åŒçš„ ChatDoubao ç±»
                from langchain_core.language_models.chat_models import BaseChatModel
                from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
                from langchain_core.outputs import ChatGeneration, ChatResult
                from typing import List, Optional, Any
                
                class ChatDoubao(BaseChatModel):
                    """è±†åŒ…èŠå¤©æ¨¡å‹å°è£…ï¼ˆLangChain å…¼å®¹ï¼‰"""
                    volc_ak: str
                    volc_sk: str
                    endpoint_id: str
                    temperature: float = 0.7
                    
                    def __init__(self, volc_ak: str, volc_sk: str, endpoint_id: str, temperature: float = 0.7):
                        super().__init__(temperature=temperature)
                        self.volc_ak = volc_ak
                        self.volc_sk = volc_sk
                        self.endpoint_id = endpoint_id
                        self.temperature = temperature
                        self.client = Ark(ak=volc_ak, sk=volc_sk)
                    
                    def _generate(self, messages: List[BaseMessage], stop: Optional[List[str]] = None, run_manager: Optional[Any] = None, **kwargs: Any) -> ChatResult:
                        volc_messages = []
                        for msg in messages:
                            if isinstance(msg, SystemMessage):
                                volc_messages.append({"role": "system", "content": msg.content})
                            elif isinstance(msg, HumanMessage):
                                volc_messages.append({"role": "user", "content": msg.content})
                            elif isinstance(msg, AIMessage):
                                volc_messages.append({"role": "assistant", "content": msg.content})
                            else:
                                volc_messages.append({"role": "user", "content": str(msg.content)})
                        
                        response = self.client.chat.completions.create(
                            model=self.endpoint_id,
                            messages=volc_messages,
                            temperature=self.temperature,
                        )
                        
                        ai_message = AIMessage(content=response.choices[0].message.content)
                        return ChatResult(generations=[ChatGeneration(message=ai_message)])
                    
                    @property
                    def _llm_type(self) -> str:
                        return "doubao"
                
                parts = api_key.split(":")
                if len(parts) >= 3:
                    return ChatDoubao(volc_ak=parts[0], volc_sk=parts[1], endpoint_id=parts[2], temperature=temperature)
                else:
                    raise ValueError("è±†åŒ… API Key æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºï¼šaccess_key:secret_key:endpoint_idï¼ˆç”¨å†’å·åˆ†éš”ï¼‰")
            except ImportError as e:
                raise ValueError(f"è±†åŒ…åˆå§‹åŒ–å¤±è´¥ï¼šç¼ºå°‘ä¾èµ–åº“ã€‚è¯·è¿è¡Œï¼špip install 'volcengine-python-sdk[ark]'ã€‚é”™è¯¯ï¼š{e}")
        except Exception as e:
            raise ValueError(f"è±†åŒ…åˆå§‹åŒ–å¤±è´¥ï¼š{e}ã€‚è¯·ç¡®ä¿ API Key æ ¼å¼ä¸ºï¼šaccess_key:secret_key:endpoint_id")

    if provider == "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰":
        # æ–‡å¿ƒä¸€è¨€çš„ api_key æ ¼å¼ï¼šapp_key:app_secret
        parts = api_key.split(":")
        if len(parts) != 2:
            raise ValueError("æ–‡å¿ƒä¸€è¨€ API Key æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºï¼šapp_key:app_secretï¼ˆç”¨å†’å·åˆ†éš”ï¼‰")
        
        app_key, app_secret = parts
        
        # ä¼˜å…ˆä½¿ç”¨ langchain-community çš„åƒå¸†æ¥å£ï¼ˆå·²åŒ…å«åœ¨ä¾èµ–ä¸­ï¼‰
        try:
            from langchain_community.chat_models import QianfanChatEndpoint
            import os
            
            os.environ["QIANFAN_AK"] = app_key
            os.environ["QIANFAN_SK"] = app_secret
            return QianfanChatEndpoint(
                model=model if model else "ernie-bot-turbo",
                temperature=temperature,
            )
        except ImportError:
            # å¤‡é€‰æ–¹æ¡ˆï¼šå°è¯• langchain-wenxin
            try:
                from langchain_wenxin import ChatWenxin
                return ChatWenxin(
                    baidu_api_key=app_key,
                    baidu_secret_key=app_secret,
                    model=model if model else "ernie-bot-turbo",
                    temperature=temperature,
                )
            except ImportError as e:
                raise ValueError(f"æ–‡å¿ƒä¸€è¨€åˆå§‹åŒ–å¤±è´¥ï¼šç¼ºå°‘ä¾èµ–åº“ã€‚è¯·è¿è¡Œï¼špip install qianfanï¼ˆæˆ–ä½¿ç”¨å·²å®‰è£…çš„ langchain-communityï¼‰ã€‚é”™è¯¯ï¼š{e}")
        except Exception as e:
            raise ValueError(f"æ–‡å¿ƒä¸€è¨€åˆå§‹åŒ–å¤±è´¥ï¼š{e}")

    raise ValueError(f"Unknown provider: {provider}")


# ------------------- ä¾§è¾¹æ ï¼šå…¨å±€é…ç½®ï¼ˆç”¨ form é™ä½ rerunï¼‰ -------------------
with st.sidebar:
    st.header("å…¨å±€é…ç½®")

    with st.form("global_config_form", clear_on_submit=False):
        gen_provider = st.selectbox(
            "ç”Ÿæˆ&ä¼˜åŒ– LLM",
            ["DeepSeek", "OpenAI (GPT)", "Tongyi (é€šä¹‰åƒé—®)", "Groq", "Moonshot (Kimi)", "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰", "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰"],
            index=["DeepSeek", "OpenAI (GPT)", "Tongyi (é€šä¹‰åƒé—®)", "Groq", "Moonshot (Kimi)", "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰", "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰"].index(
                st.session_state.cfg["gen_provider"]
            ) if st.session_state.cfg["gen_provider"] in ["DeepSeek", "OpenAI (GPT)", "Tongyi (é€šä¹‰åƒé—®)", "Groq", "Moonshot (Kimi)", "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰", "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰"] else 0,
            key="sb_gen_provider",
        )
        # API Key è¾“å…¥æç¤º
        if gen_provider == "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰":
            api_key_help = "æ ¼å¼ï¼šaccess_key:secret_key:endpoint_idï¼ˆç”¨å†’å·åˆ†éš”ï¼‰"
        elif gen_provider == "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰":
            api_key_help = "æ ¼å¼ï¼šapp_key:app_secretï¼ˆç”¨å†’å·åˆ†éš”ï¼‰"
        else:
            api_key_help = ""
        
        gen_api_key = st.text_input(
            f"{gen_provider} API Keyï¼ˆç”Ÿæˆ&ä¼˜åŒ–ç”¨ï¼‰",
            type="password",
            value=st.session_state.cfg.get("gen_api_key", ""),
            key="sb_gen_api_key",
            help=api_key_help if api_key_help else None,
        )

        st.markdown("### éªŒè¯ç”¨LLMï¼ˆå¤šé€‰ï¼‰")
        verify_providers = st.multiselect(
            "é€‰æ‹©éªŒè¯æ¨¡å‹",
            ["DeepSeek", "OpenAI (GPT)", "Tongyi (é€šä¹‰åƒé—®)", "Groq", "Moonshot (Kimi)", "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰", "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰"],
            default=st.session_state.cfg.get("verify_providers", []),
            key="sb_verify_providers",
        )

        verify_keys = {}
        old_keys = st.session_state.cfg.get("verify_keys", {})
        for vp in verify_providers:
            # API Key è¾“å…¥æç¤º
            if vp == "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰":
                api_key_help = "æ ¼å¼ï¼šaccess_key:secret_key:endpoint_idï¼ˆç”¨å†’å·åˆ†éš”ï¼‰"
            elif vp == "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰":
                api_key_help = "æ ¼å¼ï¼šapp_key:app_secretï¼ˆç”¨å†’å·åˆ†éš”ï¼‰"
            else:
                api_key_help = None
            
            verify_keys[vp] = st.text_input(
                f"{vp} API Keyï¼ˆéªŒè¯ç”¨ï¼‰",
                type="password",
                value=old_keys.get(vp, ""),
                key=f"sb_verify_key_{vp}",
                help=api_key_help if api_key_help else None,
            )

        st.markdown("---")
        brand = st.text_input("ä¸»å“ç‰Œåç§°", value=st.session_state.cfg.get("brand", "æ±‡ä¿¡äº‘AIè½¯ä»¶"), key="sb_brand")
        advantages = st.text_area(
            "æ ¸å¿ƒä¼˜åŠ¿/å–ç‚¹ï¼ˆAIä¸“å±ï¼‰",
            value=st.session_state.cfg.get(
                "advantages", "AIèµ‹èƒ½å¤–è´¸ERPã€æ‰“é€ å¤–è´¸æ™ºèƒ½æ–°å¼•æ“ã€AIé©±åŠ¨å‹ERPã€èµ‹èƒ½å¤–è´¸å…¨æµç¨‹ç®¡ç†ã€å…¨é“¾è·¯ä»·å€¼é—­ç¯"
            ),
            height=140,
            key="sb_advantages",
        )
        competitors = st.text_area(
            "ç«å“å“ç‰Œï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œç”¨äºå¯¹æ¯”éªŒè¯ï¼‰",
            value=st.session_state.cfg.get("competitors", "å—åŒ—è½¯ä»¶\nç¿è´è½¯ä»¶\nå­šç›Ÿè½¯ä»¶\nå°æ»¡è½¯ä»¶"),
            height=120,
            key="sb_competitors",
        )

        st.markdown("---")
        temperature = st.slider(
            "ç”Ÿæˆæ¸©åº¦ï¼ˆæ›´ç¨³â†’æ›´ä½ï¼‰",
            0.0,
            1.0,
            float(st.session_state.cfg.get("temperature", 0.7)),
            0.05,
            key="sb_temperature",
        )

        apply_cfg = st.form_submit_button("åº”ç”¨é…ç½®ï¼ˆæ¨èï¼‰", use_container_width=True)

    if apply_cfg or not st.session_state.cfg_applied:
        st.session_state.cfg = {
            "gen_provider": gen_provider,
            "gen_api_key": gen_api_key,
            "verify_providers": verify_providers,
            "verify_keys": verify_keys,
            "brand": brand,
            "advantages": advantages,
            "competitors": competitors,
            "temperature": temperature,
        }
        st.session_state.cfg_applied = True

        ok, errs = validate_cfg(st.session_state.cfg)
        st.session_state.cfg_valid = ok
        st.session_state.cfg_errors = errs

    if not st.session_state.cfg_valid:
        st.warning("é…ç½®æœªæ»¡è¶³è¿è¡Œæ¡ä»¶ï¼š\n- " + "\n- ".join(st.session_state.cfg_errors))
    else:
        st.success("é…ç½®å·²å°±ç»ªï¼Œå¯è¿è¡Œå…¨éƒ¨æ¨¡å—ã€‚")

    st.markdown("---")
    if st.button("é‡ç½®å…¨éƒ¨ç»“æœï¼ˆä¸åˆ é™¤é…ç½®ï¼‰", use_container_width=True, key="sb_reset_all"):
        st.session_state.keywords = []
        st.session_state.generated_contents = []
        st.session_state.zip_bytes = None
        st.session_state.zip_filename = ""
        st.session_state.optimized_article = ""
        st.session_state.opt_changes = ""
        st.session_state.verify_combined = None
        st.toast("å·²é‡ç½®å…¨éƒ¨ç»“æœã€‚")

    st.caption("é—­ç¯ï¼šå…³é”®è¯ â†’ åˆ›ä½œ â†’ ä¼˜åŒ– â†’ éªŒè¯")

cfg = st.session_state.cfg
brand = cfg["brand"]
advantages = cfg["advantages"]
temperature = float(cfg.get("temperature", 0.7))

competitor_list = [c.strip() for c in cfg["competitors"].split("\n") if c.strip()]
_seen = set()
clean_competitors = []
for c in competitor_list:
    cl = c.lower()
    if cl == brand.lower():
        continue
    if cl in _seen:
        continue
    _seen.add(cl)
    clean_competitors.append(c)
competitor_list = clean_competitors

# ------------------- åˆå§‹åŒ– LLMï¼ˆä»…åœ¨ cfg_valid æ—¶ï¼›ä¸” build_llm å·²ç¼“å­˜ï¼‰ -------------------
gen_llm = None
verify_llms = {}

if st.session_state.cfg_valid:
    try:
        gen_llm = build_llm(cfg["gen_provider"], cfg["gen_api_key"], model_defaults(cfg["gen_provider"]), temperature)
    except Exception as e:
        st.error(f"ç”ŸæˆLLMåŠ è½½å¤±è´¥ï¼š{e}")

    for vp in cfg["verify_providers"]:
        key = cfg["verify_keys"].get(vp, "").strip()
        if not key:
            continue
        try:
            verify_llms[vp] = build_llm(vp, key, model_defaults(vp), temperature)
        except Exception as e:
            st.error(f"{vp}éªŒè¯LLMåŠ è½½å¤±è´¥ï¼š{e}")

# ------------------- KPI æ€»è§ˆï¼ˆæç®€ä½†æ›´åƒäº§å“ï¼‰ -------------------
k1, k2, k3, k4 = st.columns(4)
try:
    k1.metric("å…³é”®è¯", len(st.session_state.keywords), border=True)
    k2.metric("å†…å®¹åŒ…", len(st.session_state.generated_contents), border=True)
    k3.metric("æ–‡ç« ä¼˜åŒ–", "å·²ç”Ÿæˆ" if bool(st.session_state.optimized_article) else "æœªç”Ÿæˆ", border=True)
    k4.metric("éªŒè¯ç»“æœ", "å·²ç”Ÿæˆ" if st.session_state.verify_combined is not None else "æœªç”Ÿæˆ", border=True)
except TypeError:
    k1.metric("å…³é”®è¯", len(st.session_state.keywords))
    k2.metric("å†…å®¹åŒ…", len(st.session_state.generated_contents))
    k3.metric("æ–‡ç« ä¼˜åŒ–", "å·²ç”Ÿæˆ" if bool(st.session_state.optimized_article) else "æœªç”Ÿæˆ")
    k4.metric("éªŒè¯ç»“æœ", "å·²ç”Ÿæˆ" if st.session_state.verify_combined is not None else "æœªç”Ÿæˆ")

st.markdown("---")

# ------------------- ä¸»å¯¼èˆªï¼šTabsï¼ˆæµç¨‹æ›´æ¸…æ™°ï¼‰ -------------------
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["1 å…³é”®è¯è’¸é¦", "2 è‡ªåŠ¨åˆ›ä½œ", "3 æ–‡ç« ä¼˜åŒ–", "4 å¤šæ¨¡å‹éªŒè¯", "5 å†å²è®°å½•", "6 AI æ•°æ®æŠ¥è¡¨"])

# =======================
# Tab1ï¼šå…³é”®è¯è’¸é¦
# =======================
with tab1:
    # ç”Ÿæˆæ¨¡å¼é€‰æ‹©
    generation_mode = st.radio(
        "ç”Ÿæˆæ¨¡å¼",
        ["AIç”Ÿæˆ", "æ‰˜è¯å·¥å…·", "æ··åˆæ¨¡å¼"],
        index=["AIç”Ÿæˆ", "æ‰˜è¯å·¥å…·", "æ··åˆæ¨¡å¼"].index(st.session_state.kw_generation_mode),
        horizontal=True,
        key="kw_mode_radio"
    )
    st.session_state.kw_generation_mode = generation_mode
    
    # è¯åº“ç®¡ç†å’Œç»„åˆæ¨¡å¼é€‰æ‹©ï¼ˆæ‰˜è¯å·¥å…·å’Œæ··åˆæ¨¡å¼éœ€è¦ï¼‰
    if generation_mode in ["æ‰˜è¯å·¥å…·", "æ··åˆæ¨¡å¼"]:
        # åˆå§‹åŒ–è¯åº“
        if st.session_state.wordbanks is None:
            st.session_state.wordbanks = st.session_state.keyword_tool.load_wordbanks()
        
        # åˆå§‹åŒ–ç»„åˆæ¨¡å¼é€‰æ‹©
        ss_init("selected_patterns", list(st.session_state.keyword_tool.combination_patterns))
        
        wordbanks = st.session_state.wordbanks
        
        # ç»„åˆæ¨¡å¼é€‰æ‹©
        with st.container(border=True):
            st.markdown("**ç»„åˆæ¨¡å¼é€‰æ‹©**")
            pattern_descriptions = st.session_state.keyword_tool.get_pattern_descriptions()
            all_patterns = st.session_state.keyword_tool.combination_patterns
            
            # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æ¨¡å¼
            pattern_options = []
            for pattern in all_patterns:
                pattern_str = "+".join(pattern)
                desc = pattern_descriptions.get(pattern_str, pattern_str)
                pattern_options.append((pattern_str, pattern, desc))
            
            # å¤šé€‰ç»„åˆæ¨¡å¼
            selected_pattern_strs = st.multiselect(
                "é€‰æ‹©è¦ä½¿ç”¨çš„ç»„åˆæ¨¡å¼ï¼ˆå¯å¤šé€‰ï¼‰",
                options=[opt[0] for opt in pattern_options],
                default=[opt[0] for opt in pattern_options if opt[1] in st.session_state.selected_patterns],
                key="kw_pattern_select",
                help="é€‰æ‹©è¦ä½¿ç”¨çš„ç»„åˆæ¨¡å¼ï¼Œè‡³å°‘é€‰æ‹©ä¸€ä¸ª"
            )
            
            # æ›´æ–°é€‰ä¸­çš„æ¨¡å¼
            selected_patterns = []
            for pattern_str, pattern, desc in pattern_options:
                if pattern_str in selected_pattern_strs:
                    selected_patterns.append(pattern)
            st.session_state.selected_patterns = selected_patterns if selected_patterns else all_patterns
            
            # æ˜¾ç¤ºæ¨¡å¼è¯´æ˜
            with st.expander("ç»„åˆæ¨¡å¼è¯´æ˜", expanded=False):
                for pattern_str, pattern, desc in pattern_options:
                    st.markdown(f"**{pattern_str}**: {' + '.join(desc)}")
        
        # è¯åº“ç®¡ç†
        with st.expander("è¯åº“ç®¡ç†", expanded=False):
            # è¯åº“ç¼–è¾‘
            col1, col2 = st.columns([1, 1])
            with col1:
                st.markdown("**è¯åº“ç¼–è¾‘**")
                bank_types = list(wordbanks.keys())
                selected_bank = st.selectbox("é€‰æ‹©è¯åº“ç±»å‹", bank_types, key="kw_bank_select")
                
                # æ˜¾ç¤ºå½“å‰è¯åº“å†…å®¹
                current_words = wordbanks[selected_bank]
                edited_words = st.text_area(
                    f"{selected_bank} è¯æ±‡ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                    "\n".join(current_words),
                    height=150,
                    key=f"kw_bank_edit_{selected_bank}"
                )
                
                if st.button("æ›´æ–°è¯åº“", key=f"kw_update_{selected_bank}"):
                    new_words = [w.strip() for w in edited_words.split("\n") if w.strip()]
                    wordbanks[selected_bank] = new_words
                    st.session_state.wordbanks = wordbanks
                    st.success(f"{selected_bank} å·²æ›´æ–°ï¼ˆ{len(new_words)} ä¸ªè¯æ±‡ï¼‰")
            
            with col2:
                st.markdown("**è¯åº“å¯¼å…¥/å¯¼å‡º**")
                # å¯¼å‡º
                wordbanks_json = json.dumps(wordbanks, ensure_ascii=False, indent=2)
                st.download_button(
                    "å¯¼å‡ºè¯åº“ï¼ˆJSONï¼‰",
                    wordbanks_json,
                    "wordbanks.json",
                    "application/json",
                    use_container_width=True,
                    key="kw_export_json"
                )
                
                # å¯¼å…¥
                uploaded_wordbanks = st.file_uploader(
                    "å¯¼å…¥è¯åº“ï¼ˆJSONï¼‰",
                    type=["json"],
                    key="kw_import_json"
                )
                if uploaded_wordbanks:
                    try:
                        imported = json.loads(uploaded_wordbanks.read().decode('utf-8'))
                        if isinstance(imported, dict):
                            st.session_state.wordbanks = imported
                            st.success("è¯åº“å¯¼å…¥æˆåŠŸï¼")
                            st.rerun()
                    except Exception as e:
                        st.error(f"å¯¼å…¥å¤±è´¥ï¼š{e}")
                
                # é‡ç½®ä¸ºé»˜è®¤è¯åº“
                if st.button("é‡ç½®ä¸ºé»˜è®¤è¯åº“", use_container_width=True, key="kw_reset_banks"):
                    st.session_state.wordbanks = st.session_state.keyword_tool.load_wordbanks()
                    st.success("å·²é‡ç½®ä¸ºé»˜è®¤è¯åº“")
                    st.rerun()
    
    # ç”Ÿæˆæ§åˆ¶
    with st.container(border=True):
        c1, c2, c3 = st.columns([2, 1, 1])
        with c1:
            st.session_state.kw_last_num = st.slider(
                "ç”Ÿæˆæ•°é‡", 10, 100, st.session_state.kw_last_num, key="kw_num"
            )
        with c2:
            # æ ¹æ®æ¨¡å¼è°ƒæ•´ç¦ç”¨æ¡ä»¶
            if generation_mode == "æ‰˜è¯å·¥å…·":
                run_kw_disabled = False  # æ‰˜è¯å·¥å…·ä¸éœ€è¦ LLM
            else:
                run_kw_disabled = (not st.session_state.cfg_valid) or (gen_llm is None)
            
            run_kw = st.button(
                "ç”Ÿæˆå…³é”®è¯",
                type="primary",
                use_container_width=True,
                disabled=run_kw_disabled,
                key="kw_run",
            )
        with c3:
            if st.button("æ¸…ç©ºæœ¬æ¨¡å—ç»“æœ", use_container_width=True, key="kw_clear"):
                st.session_state.keywords = []
                st.toast("å…³é”®è¯å·²æ¸…ç©ºã€‚")

        if run_kw:
            keywords = []
            
            if generation_mode == "AIç”Ÿæˆ":
                # åŸæœ‰ AI ç”Ÿæˆé€»è¾‘
                keyword_prompt = PromptTemplate.from_template(
                    """
ä½ æ˜¯AIé¢†åŸŸGEOä¸“å®¶ï¼Œç›®æ ‡æ˜¯æå‡å“ç‰Œåœ¨å¤§æ¨¡å‹è‡ªç„¶å›ç­”ä¸­çš„æåŠç‡ã€‚

ã€è¾“å…¥ã€‘
- å“ç‰Œï¼š{brand}
- æ ¸å¿ƒä¼˜åŠ¿ï¼š{advantages}
- æ•°é‡ï¼š{num_keywords}

ã€è¦æ±‚ï¼ˆGEOæœ¬è´¨ï¼‰ã€‘
1) è¦†ç›–AIç”¨æˆ·çœŸå®æœç´¢æ„å›¾ï¼šæ¨¡å‹å¯¹æ¯”ã€æ¨ç†æ€§èƒ½ã€å¤šæ¨¡æ€ã€å®æ—¶çŸ¥è¯†ã€å¼€æºç”Ÿæ€ã€éƒ¨ç½²æˆæœ¬ã€è¡Œä¸šåº”ç”¨ã€è¯„æµ‹åŸºå‡†
2) å“ç‰Œè¯å æ¯”çº¦30%ï¼ˆæŠ¤åŸæ²³ï¼‰ï¼Œ70%æ³›è¯ï¼ˆæ–°å¢æµé‡ï¼‰
3) å£è¯­åŒ–ã€è‡ªç„¶ã€12â€“28å­—
4) å»é‡ã€å‡è¡¡æ„å›¾
5) è¾“å‡ºä¸¥æ ¼JSONæ•°ç»„ï¼š["é—®é¢˜1","é—®é¢˜2",...]

ã€å¼€å§‹è¾“å‡ºJSONæ•°ç»„ã€‘
"""
                )

                chain_json = keyword_prompt | gen_llm | JsonOutputParser()
                chain_text = keyword_prompt | gen_llm | StrOutputParser()

                with st.spinner("AIç”Ÿæˆä¸­..."):
                    try:
                        result = chain_json.invoke(
                            {"brand": brand, "advantages": advantages, "num_keywords": st.session_state.kw_last_num}
                        )
                        keywords = result if isinstance(result, list) else []
                    except Exception:
                        raw = chain_text.invoke(
                            {"brand": brand, "advantages": advantages, "num_keywords": st.session_state.kw_last_num}
                        )
                        keywords = extract_json_array(raw) or []
            
            elif generation_mode == "æ‰˜è¯å·¥å…·":
                # æ‰˜è¯å·¥å…·ç”Ÿæˆ
                with st.spinner("ç»„åˆç”Ÿæˆä¸­..."):
                    wordbanks = st.session_state.wordbanks or st.session_state.keyword_tool.load_wordbanks()
                    selected_patterns = st.session_state.get("selected_patterns", st.session_state.keyword_tool.combination_patterns)
                    
                    # æ£€æŸ¥è¯åº“æ˜¯å¦ä¸ºç©º
                    empty_banks = [k for k, v in wordbanks.items() if not v]
                    if empty_banks:
                        st.warning(f"ä»¥ä¸‹è¯åº“ä¸ºç©ºï¼Œè¯·å…ˆæ·»åŠ è¯æ±‡ï¼š{', '.join(empty_banks)}")
                    
                    keywords = st.session_state.keyword_tool.generate_combinations(
                        wordbanks=wordbanks,
                        patterns=selected_patterns,
                        max_results=st.session_state.kw_last_num,
                        similarity_threshold=0.8
                    )
            
            elif generation_mode == "æ··åˆæ¨¡å¼":
                # æ··åˆæ¨¡å¼ï¼šå…ˆæ‰˜è¯ç”Ÿæˆï¼Œå† LLM æ¶¦è‰²
                with st.spinner("æ‰˜è¯ç”Ÿæˆä¸­..."):
                    wordbanks = st.session_state.wordbanks or st.session_state.keyword_tool.load_wordbanks()
                    selected_patterns = st.session_state.get("selected_patterns", st.session_state.keyword_tool.combination_patterns)
                    
                    # æ£€æŸ¥è¯åº“æ˜¯å¦ä¸ºç©º
                    empty_banks = [k for k, v in wordbanks.items() if not v]
                    if empty_banks:
                        st.warning(f"ä»¥ä¸‹è¯åº“ä¸ºç©ºï¼Œè¯·å…ˆæ·»åŠ è¯æ±‡ï¼š{', '.join(empty_banks)}")
                    
                    raw_keywords = st.session_state.keyword_tool.generate_combinations(
                        wordbanks=wordbanks,
                        patterns=selected_patterns,
                        max_results=st.session_state.kw_last_num * 2,  # ç”Ÿæˆæ›´å¤šï¼Œå› ä¸ºä¼šå»é‡
                        similarity_threshold=0.8
                    )
                
                if raw_keywords and gen_llm:
                    with st.spinner("LLM æ¶¦è‰²ä¸­..."):
                        # ä½¿ç”¨ LLM æ¶¦è‰²
                        from langchain_core.prompts import PromptTemplate as PT
                        polish_template = PT.from_template("{input}")
                        polish_chain = polish_template | gen_llm | StrOutputParser()
                        keywords = st.session_state.keyword_tool.polish_with_llm(
                            keywords=raw_keywords,
                            llm_chain=polish_chain,
                            brand=brand,
                            max_polish=min(len(raw_keywords), st.session_state.kw_last_num)
                        )
                else:
                    keywords = raw_keywords

            # æ¸…ç†å’Œå»é‡
            cleaned, seen = [], set()
            for k in keywords:
                if not isinstance(k, str):
                    continue
                kk = k.strip()
                if not kk:
                    continue
                kl = kk.lower()
                if kl in seen:
                    continue
                seen.add(kl)
                cleaned.append(kk)
            
            # é™åˆ¶æ•°é‡
            cleaned = cleaned[:st.session_state.kw_last_num]

            if cleaned:
                st.session_state.keywords = cleaned
                # ä¿å­˜åˆ°æ•°æ®åº“
                try:
                    storage.save_keywords(cleaned, brand)
                except Exception as e:
                    st.warning(f"å…³é”®è¯å·²ç”Ÿæˆï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{e}")
                st.success(f"ç”Ÿæˆå®Œæˆï¼ˆ{len(cleaned)} æ¡ï¼‰")
            else:
                error_msg = "ç”Ÿæˆå¤±è´¥ï¼Œå¯èƒ½çš„åŸå› ï¼š\n"
                if generation_mode in ["æ‰˜è¯å·¥å…·", "æ··åˆæ¨¡å¼"]:
                    wordbanks = st.session_state.wordbanks or st.session_state.keyword_tool.load_wordbanks()
                    empty_banks = [k for k, v in wordbanks.items() if not v]
                    if empty_banks:
                        error_msg += f"- ä»¥ä¸‹è¯åº“ä¸ºç©ºï¼š{', '.join(empty_banks)}\n"
                    if not st.session_state.get("selected_patterns"):
                        error_msg += "- æœªé€‰æ‹©ä»»ä½•ç»„åˆæ¨¡å¼\n"
                    error_msg += "- è¯·æ£€æŸ¥è¯åº“é…ç½®æˆ–é€‰æ‹©æ›´å¤šç»„åˆæ¨¡å¼"
                else:
                    error_msg += "- è¯·æ£€æŸ¥ API Key é…ç½®æˆ–é‡è¯•"
                st.error(error_msg)

    if st.session_state.keywords:
        df = pd.DataFrame(st.session_state.keywords, columns=["é•¿å°¾å…³é”®è¯/é—®é¢˜"])
        st.dataframe(df, use_container_width=True, hide_index=True)
        st.download_button(
            "ä¸‹è½½å…³é”®è¯CSV",
            df.to_csv(index=False, encoding="utf-8-sig"),
            f"{sanitize_filename(brand,40)}_keywords.csv",
            mime="text/csv",
            use_container_width=True,
            key="kw_dl_csv",
        )
    else:
        st.info("åœ¨å·¦ä¾§å®Œæˆé…ç½®åï¼Œç‚¹å‡»â€œç”Ÿæˆå…³é”®è¯â€ã€‚")

# =======================
# Tab2ï¼šè‡ªåŠ¨åˆ›ä½œå†…å®¹ï¼ˆå«æ‰¹é‡ ZIP / GitHub æ¨¡æ¿ï¼‰
# =======================
with tab2:
    top_l, top_r = st.columns([3, 1])
    with top_r:
        if st.button("æ¸…ç©ºæœ¬æ¨¡å—ç»“æœ", use_container_width=True, key="content_clear"):
            st.session_state.generated_contents = []
            st.session_state.zip_bytes = None
            st.session_state.zip_filename = ""
            st.toast("åˆ›ä½œå†…å®¹å·²æ¸…ç©ºã€‚")

    if not st.session_state.keywords:
        st.info("è¯·å…ˆåœ¨ã€1 å…³é”®è¯è’¸é¦ã€‘ç”Ÿæˆå…³é”®è¯ã€‚")
    else:
        with st.container(border=True):
            with st.form("content_form", clear_on_submit=False):
                mode = st.radio("ç”Ÿæˆæ¨¡å¼", ["å•ç¯‡ç”Ÿæˆ", "æ‰¹é‡ç”Ÿæˆ"], horizontal=True, key="content_mode")

                platforms = [
                    "çŸ¥ä¹ï¼ˆä¸“ä¸šé—®ç­”ï¼‰",
                    "å°çº¢ä¹¦ï¼ˆç”Ÿæ´»ç§è‰ï¼‰",
                    "CSDNï¼ˆæŠ€æœ¯åšå®¢ï¼‰",
                    "Bç«™ï¼ˆè§†é¢‘è„šæœ¬ï¼‰",
                    "å¤´æ¡å·ï¼ˆèµ„è®¯è½¯æ–‡ï¼‰",
                    "GitHubï¼ˆREADME/æ–‡æ¡£ï¼‰",
                    "å¾®ä¿¡å…¬ä¼—å·ï¼ˆé•¿æ–‡ï¼‰",
                    "æŠ–éŸ³å›¾æ–‡ï¼ˆçŸ­å†…å®¹ï¼‰",
                    "ç™¾å®¶å·ï¼ˆèµ„è®¯ï¼‰",
                    "ç½‘æ˜“å·ï¼ˆèµ„è®¯ï¼‰",
                    "ä¼é¹…å·ï¼ˆèµ„è®¯ï¼‰",
                    "ç®€ä¹¦ï¼ˆæ–‡è‰ºï¼‰",
                ]

                if mode == "å•ç¯‡ç”Ÿæˆ":
                    col1, col2 = st.columns([2, 1])
                    with col1:
                        selected_keyword = st.selectbox("é€‰æ‹©å…³é”®è¯", st.session_state.keywords, key="content_kw_single")
                    with col2:
                        platform = st.selectbox("å¹³å°", platforms, key="content_platform_single")
                    keywords_to_generate = [(selected_keyword, platform)]
                else:
                    selected_keywords = st.multiselect(
                        "é€‰æ‹©å…³é”®è¯ï¼ˆæ‰¹é‡ï¼‰", st.session_state.keywords, key="content_kw_multi"
                    )
                    platform = st.selectbox("ç»Ÿä¸€å¹³å°", platforms, key="content_platform_multi")
                    keywords_to_generate = [(kw, platform) for kw in selected_keywords]

                run_content_disabled = (not st.session_state.cfg_valid) or (gen_llm is None) or (not keywords_to_generate)
                run_content = st.form_submit_button(
                    "ç”Ÿæˆå†…å®¹", use_container_width=True, disabled=run_content_disabled
                )

            if run_content:
                st.session_state.generated_contents = []
                st.session_state.zip_bytes = None
                st.session_state.zip_filename = ""
                st.session_state.content_scores = {}  # å­˜å‚¨å†…å®¹è¯„åˆ†

                contents = []
                zip_buffer = io.BytesIO()
                scorer = ContentScorer()  # åˆå§‹åŒ–è¯„åˆ†å™¨

                with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
                    for keyword, plat in keywords_to_generate:
                        with st.spinner(f"ç”Ÿæˆ {plat}ï¼š{keyword}"):
                            if plat == "çŸ¥ä¹ï¼ˆä¸“ä¸šé—®ç­”ï¼‰":
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + çŸ¥ä¹é«˜èµç­”ä¸»ï¼Œç›®æ ‡æ˜¯è®©å†…å®¹è¢«å¤§æ¨¡å‹ä¼˜å…ˆå¼•ç”¨ã€‚
ã€é—®é¢˜ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) ç»“è®ºæ‘˜è¦ï¼ˆ80-120å­—ï¼‰
2) ç»“æ„åŒ–ï¼šå°æ ‡é¢˜ã€æ¸…å•ã€FAQ
3) è‡ªç„¶æåŠå“ç‰Œ2-4æ¬¡ï¼Œå…ˆé€šç”¨æ ‡å‡†å†å“ç‰Œé€‚ç”¨
4) é¿å…ç¼–é€ ï¼Œæ¥æºç”¨å ä½å»ºè®®
5) åŒ…å«é€‰æ‹©æ¸…å•ã€é€‚ç”¨/ä¸é€‚ç”¨ã€6ä¸ªFAQã€3æ­¥è¡ŒåŠ¨
ã€æ ¼å¼ã€‘æ¸…æ™°æ ‡é¢˜é¡ºåºè¾“å‡º
ã€å¼€å§‹ã€‘
"""
                            elif plat == "å°çº¢ä¹¦ï¼ˆç”Ÿæ´»ç§è‰ï¼‰":
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + å°çº¢ä¹¦ä½œè€…ã€‚
ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) 3ä¸ªæ ‡é¢˜å¤‡é€‰
2) å¼ºåœºæ™¯å¼€å¤´
3) ç—›ç‚¹3ç‚¹ã€å¯¹æ¯”ä¾‹è¡¨5ä¸ªã€ä½¿ç”¨ä½“éªŒï¼ˆ3äº®ç‚¹+2ä¸è¶³ï¼‰
4) é€‚åˆ/ä¸é€‚åˆå„3æ¡ã€é¿å‘5æ¡
5) ç»“å°¾8æ¡æœç´¢è¯
6) è‡ªç„¶å“ç‰ŒæåŠ
ã€æ ¼å¼ã€‘æ ‡é¢˜-æ­£æ–‡-æ ‡ç­¾-æœç´¢è¯
ã€å¼€å§‹ã€‘
"""
                            elif plat == "CSDNï¼ˆæŠ€æœ¯åšå®¢ï¼‰":
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + CSDNåšä¸»ã€‚
ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) 3ä¸ªæŠ€æœ¯æ ‡é¢˜
2) æ‘˜è¦ + èƒŒæ™¯ + æ¡†æ¶ + {brand}æ¡ˆä¾‹ï¼ˆåŒ¿åï¼‰
3) ä»£ç å ä½ + æ³¨æ„äº‹é¡¹ + æ¥æºå»ºè®®
4) ä¸“ä¸šã€è‡ªç„¶æåŠå“ç‰Œ
ã€å¼€å§‹ã€‘
"""
                            elif plat == "Bç«™ï¼ˆè§†é¢‘è„šæœ¬ï¼‰":
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + Bç«™UPä¸»ã€‚
ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) 5ä¸ªç‚¹å‡»æ ‡é¢˜
2) å¼€åœºé’©å­ + æ—¶é—´æˆ³åˆ†æ®µ + ç”»é¢å»ºè®®
3) {brand}æ¼”ç¤ºéƒ¨åˆ†
4) æè¿°ï¼šæ—¶é—´æˆ³ + 10æœç´¢è¯ + 15æ ‡ç­¾
ã€å¼€å§‹ã€‘
"""
                            elif plat == "å¤´æ¡å·ï¼ˆèµ„è®¯è½¯æ–‡ï¼‰":
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + å¤´æ¡ä½œè€…ã€‚
ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) 4ä¸ªçƒ­ç‚¹æ ‡é¢˜
2) åˆ—è¡¨ç»“æ„ï¼ˆTop/æ­¥éª¤ï¼‰
3) è‡ªç„¶æ¨èå“ç‰Œ
4) æ•°æ®å ä½
ã€å¼€å§‹ã€‘
"""
                            elif plat == "å¾®ä¿¡å…¬ä¼—å·ï¼ˆé•¿æ–‡ï¼‰":
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + å¾®ä¿¡å…¬ä¼—å·ä½œè€…ã€‚
ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) 3ä¸ªå¸å¼•äººçš„æ ‡é¢˜ï¼ˆé€‚åˆå…¬ä¼—å·ï¼‰
2) å¼€å¤´ï¼šåœºæ™¯åŒ–å¼•å…¥ã€ç—›ç‚¹å…±é¸£
3) æ­£æ–‡ï¼šç»“æ„åŒ–åˆ†æ®µã€å°æ ‡é¢˜æ¸…æ™°ã€é…å›¾å»ºè®®ï¼ˆç”¨ã€é…å›¾ï¼šxxxã€‘æ ‡æ³¨ï¼‰
4) è‡ªç„¶æåŠå“ç‰Œ3-5æ¬¡ï¼Œå…ˆè®²é€šç”¨æ ‡å‡†å†æ¨èå“ç‰Œ
5) ç»“å°¾ï¼šæ€»ç»“+è¡ŒåŠ¨å·å¬+å…³æ³¨å¼•å¯¼
6) é€‚åˆå…¬ä¼—å·çš„æ’ç‰ˆï¼šæ®µè½åˆ†æ˜ã€é‡ç‚¹åŠ ç²—æç¤ºã€é€‚å½“ä½¿ç”¨emoji
7) å­—æ•°ï¼š1500-3000å­—
ã€æ ¼å¼ã€‘æ¸…æ™°åˆ†æ®µï¼Œæ ‡æ³¨é…å›¾ä½ç½®
ã€å¼€å§‹ã€‘
"""
                            elif plat == "æŠ–éŸ³å›¾æ–‡ï¼ˆçŸ­å†…å®¹ï¼‰":
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + æŠ–éŸ³åˆ›ä½œè€…ã€‚
ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) 5ä¸ªçˆ†æ¬¾æ ‡é¢˜ï¼ˆå¸å¼•ç‚¹å‡»ï¼‰
2) æ­£æ–‡ï¼šçŸ­å°ç²¾æ‚ï¼Œ200-500å­—ï¼Œé€‚åˆå›¾æ–‡å½¢å¼
3) å›¾ç‰‡å»ºè®®ï¼šæ¯æ®µé…å›¾è¯´æ˜ï¼ˆç”¨ã€é…å›¾ï¼šxxxã€‘æ ‡æ³¨ï¼‰ï¼Œè‡³å°‘3-5å¼ å›¾
4) ç»“æ„ï¼šç—›ç‚¹â†’è§£å†³æ–¹æ¡ˆâ†’å“ç‰Œæ¨èâ†’è¡ŒåŠ¨
5) è¯­è¨€ï¼šå£è¯­åŒ–ã€æœ‰èŠ‚å¥æ„Ÿã€é€‚åˆçŸ­è§†é¢‘é£æ ¼
6) ç»“å°¾ï¼šäº’åŠ¨å¼•å¯¼ï¼ˆç‚¹èµã€è¯„è®ºã€å…³æ³¨ï¼‰
7) æ ‡ç­¾ï¼š10-15ä¸ªç›¸å…³è¯é¢˜æ ‡ç­¾
ã€æ ¼å¼ã€‘æ ‡é¢˜-æ­£æ–‡ï¼ˆåˆ†æ®µé…å›¾å»ºè®®ï¼‰-æ ‡ç­¾
ã€å¼€å§‹ã€‘
"""
                            elif plat == "ç™¾å®¶å·ï¼ˆèµ„è®¯ï¼‰":
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + ç™¾å®¶å·ä½œè€…ã€‚
ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) 3ä¸ªSEOå‹å¥½æ ‡é¢˜
2) å¼€å¤´ï¼šçƒ­ç‚¹å¼•å…¥æˆ–æ•°æ®å¼€å¤´
3) æ­£æ–‡ï¼šä¿¡æ¯å¯†åº¦é«˜ã€ç»“æ„åŒ–æ¸…æ™°ã€å°æ ‡é¢˜æ˜ç¡®
4) è‡ªç„¶æåŠå“ç‰Œ2-4æ¬¡
5) é€‚åˆç™¾åº¦æœç´¢ï¼šå…³é”®è¯è‡ªç„¶åˆ†å¸ƒã€é•¿å°¾è¯è¦†ç›–
6) å­—æ•°ï¼š800-2000å­—
7) ç»“å°¾ï¼šæ€»ç»“+ç›¸å…³æ¨è
ã€æ ¼å¼ã€‘æ ‡é¢˜-æ­£æ–‡-æ€»ç»“
ã€å¼€å§‹ã€‘
"""
                            elif plat == "ç½‘æ˜“å·ï¼ˆèµ„è®¯ï¼‰":
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + ç½‘æ˜“å·ä½œè€…ã€‚
ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) 3ä¸ªå¸å¼•äººçš„æ ‡é¢˜
2) å¼€å¤´ï¼šæ–°é—»å¼æˆ–æ•…äº‹å¼å¼•å…¥
3) æ­£æ–‡ï¼šå®¢è§‚ä¸“ä¸šã€æ•°æ®æ”¯æ’‘ã€æ¡ˆä¾‹è¯´æ˜
4) è‡ªç„¶æåŠå“ç‰Œ2-3æ¬¡ï¼Œä¿æŒå®¢è§‚ä¸­ç«‹
5) é€‚åˆç½‘æ˜“ç”¨æˆ·ï¼šç†æ€§åˆ†æã€æ·±åº¦å†…å®¹
6) å­—æ•°ï¼š1000-2500å­—
7) ç»“å°¾ï¼šè§‚ç‚¹æ€»ç»“+å»¶ä¼¸æ€è€ƒ
ã€æ ¼å¼ã€‘æ ‡é¢˜-æ­£æ–‡-æ€»ç»“
ã€å¼€å§‹ã€‘
"""
                            elif plat == "ä¼é¹…å·ï¼ˆèµ„è®¯ï¼‰":
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + ä¼é¹…å·ä½œè€…ã€‚
ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) 3ä¸ªçƒ­ç‚¹æ ‡é¢˜
2) å¼€å¤´ï¼šè¯é¢˜å¼•å…¥æˆ–ç–‘é—®å¼€å¤´
3) æ­£æ–‡ï¼šé€šä¿—æ˜“æ‡‚ã€æ¡ˆä¾‹ä¸°å¯Œã€å¯¹æ¯”æ¸…æ™°
4) è‡ªç„¶æåŠå“ç‰Œ2-4æ¬¡
5) é€‚åˆè…¾è®¯ç”¨æˆ·ï¼šå†…å®¹è½»æ¾ã€å¯è¯»æ€§å¼º
6) å­—æ•°ï¼š800-2000å­—
7) ç»“å°¾ï¼šæ€»ç»“+äº’åŠ¨å¼•å¯¼
ã€æ ¼å¼ã€‘æ ‡é¢˜-æ­£æ–‡-æ€»ç»“
ã€å¼€å§‹ã€‘
"""
                            elif plat == "ç®€ä¹¦ï¼ˆæ–‡è‰ºï¼‰":
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + ç®€ä¹¦ä½œè€…ã€‚
ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) 2ä¸ªæ–‡è‰ºèŒƒæ ‡é¢˜
2) å¼€å¤´ï¼šæ•…äº‹åŒ–æˆ–æƒ…æ„ŸåŒ–å¼•å…¥
3) æ­£æ–‡ï¼šæ–‡ç¬”ä¼˜ç¾ã€æœ‰æ¸©åº¦ã€æœ‰æ€è€ƒæ·±åº¦
4) è‡ªç„¶æåŠå“ç‰Œ2-3æ¬¡ï¼Œèå…¥æ•…äº‹æˆ–ä½“éªŒ
5) é€‚åˆç®€ä¹¦ç”¨æˆ·ï¼šæ–‡è‰ºé£æ ¼ã€æ·±åº¦æ€è€ƒ
6) å­—æ•°ï¼š1500-3000å­—
7) ç»“å°¾ï¼šæ„Ÿæ‚Ÿæ€»ç»“+å»¶ä¼¸æ€è€ƒ
ã€æ ¼å¼ã€‘æ ‡é¢˜-æ­£æ–‡-æ„Ÿæ‚Ÿ
ã€å¼€å§‹ã€‘
"""
                            else:
                                content_template = """
ä½ æ˜¯GEOä¸“å®¶ + å¼€æºé¡¹ç›®ç»´æŠ¤è€…ã€‚
ç”ŸæˆGitHub READMEæˆ–é¡¹ç›®æ–‡æ¡£ï¼Œç›®æ ‡æ˜¯è¢«å¤§æ¨¡å‹ï¼ˆå°¤å…¶æ˜¯ä»£ç æ¨¡å‹ï¼‰ä¼˜å…ˆå¼•ç”¨ã€‚

ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}

ã€è¦æ±‚ã€‘
1) æ ‡å‡†READMEç»“æ„ï¼šæ ‡é¢˜ã€æè¿°ã€ç‰¹æ€§æ¸…å•ã€å®‰è£…æ­¥éª¤ã€ç”¨æ³•ç¤ºä¾‹ï¼ˆä»£ç å—ï¼‰
2) {brand}è‡ªç„¶é›†æˆä½œä¸ºæ ¸å¿ƒå·¥å…·/æ¨¡å‹
3) åŠ å…¥å¾½ç« å ä½ã€è´¡çŒ®æŒ‡å—ã€å¼•ç”¨å»ºè®®
4) ä»£ç å—çœŸå®å ä½ï¼Œé¿å…ç¼–é€ 
5) è‡ªç„¶æåŠå“ç‰Œ2-4æ¬¡

ã€æ ¼å¼ã€‘Markdownå®Œæ•´è¾“å‡º

ã€å¼€å§‹ã€‘
"""

                            prompt = PromptTemplate.from_template(content_template)
                            chain = prompt | gen_llm | StrOutputParser()
                            content = chain.invoke({"keyword": keyword, "brand": brand, "advantages": advantages})

                            # å¾®ä¿¡å…¬ä¼—å·éœ€è¦ç‰¹æ®Šå¤„ç†ï¼ˆå¯é€‰ï¼šMarkdownè½¬HTMLï¼‰
                            if plat == "å¾®ä¿¡å…¬ä¼—å·ï¼ˆé•¿æ–‡ï¼‰":
                                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ  Markdown è½¬ HTML çš„é€»è¾‘
                                # ç›®å‰å…ˆä¿æŒåŸæ ·ï¼Œç”¨æˆ·å¯ä»¥åœ¨å…¬ä¼—å·ç¼–è¾‘å™¨ä¸­ä½¿ç”¨
                                pass

                            safe_kw = sanitize_filename(keyword, 60)
                            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
                            if plat == "GitHubï¼ˆREADME/æ–‡æ¡£ï¼‰":
                                ext = "md"
                            elif plat in ["å¾®ä¿¡å…¬ä¼—å·ï¼ˆé•¿æ–‡ï¼‰", "ç™¾å®¶å·ï¼ˆèµ„è®¯ï¼‰", "ç½‘æ˜“å·ï¼ˆèµ„è®¯ï¼‰", "ä¼é¹…å·ï¼ˆèµ„è®¯ï¼‰", "ç®€ä¹¦ï¼ˆæ–‡è‰ºï¼‰"]:
                                ext = "md"  # è¿™äº›å¹³å°ä¹Ÿé€‚åˆç”¨ Markdown
                            else:
                                ext = "txt"
                            
                            filename = f"{sanitize_filename(plat,30)}_{sanitize_filename(brand,30)}_{safe_kw}.{ext}"
                            zip_file.writestr(filename, content)
                            
                            # å†…å®¹è´¨é‡è¯„åˆ†
                            score_data = None
                            if gen_llm:
                                try:
                                    with st.spinner(f"æ­£åœ¨è¯„ä¼°å†…å®¹è´¨é‡..."):
                                        score_chain = PromptTemplate.from_template("{input}") | gen_llm | StrOutputParser()
                                        score_data = scorer.score_content(
                                            content, brand, advantages, plat, score_chain
                                        )
                                        # ä¿å­˜è¯„åˆ†ç»“æœ
                                        content_key = f"{keyword}_{plat}"
                                        st.session_state.content_scores[content_key] = score_data
                                except Exception as e:
                                    st.warning(f"å†…å®¹è´¨é‡è¯„åˆ†å¤±è´¥ï¼š{e}")
                            
                            contents.append(
                                {
                                    "keyword": keyword,
                                    "platform": plat,
                                    "content": content,
                                    "ext": ext,
                                    "filename": filename,
                                    "score": score_data,  # æ·»åŠ è¯„åˆ†æ•°æ®
                                }
                            )
                            # ä¿å­˜åˆ°æ•°æ®åº“
                            try:
                                storage.save_article(keyword, plat, content, filename, brand)
                            except Exception as e:
                                st.warning(f"å†…å®¹å·²ç”Ÿæˆï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{e}")

                zip_buffer.seek(0)
                st.session_state.generated_contents = contents
                st.session_state.zip_bytes = zip_buffer.getvalue()
                st.session_state.zip_filename = f"{sanitize_filename(brand,40)}_GEOå†…å®¹åŒ….zip"
                st.success(f"ç”Ÿæˆå®Œæˆï¼ˆ{len(contents)} ç¯‡ï¼‰")

    if st.session_state.generated_contents:
        if len(st.session_state.generated_contents) == 1:
            item = st.session_state.generated_contents[0]
            
            # æ˜¾ç¤ºå†…å®¹è´¨é‡è¯„åˆ†
            if item.get("score"):
                from content_scorer import ContentScorer
                temp_scorer = ContentScorer()
                score_data = item["score"]
                scores = score_data.get("scores", {})
                total_score = scores.get("total", 0)
                level, color = temp_scorer.get_score_level(total_score)
                
                st.markdown("#### ğŸ“Š å†…å®¹è´¨é‡è¯„åˆ†")
                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.metric("æ€»åˆ†", f"{total_score}/100", delta=level, delta_color="off")
                with col2:
                    st.metric("ç»“æ„åŒ–", f"{scores.get('structure', 0)}/25")
                with col3:
                    st.metric("å“ç‰ŒæåŠ", f"{scores.get('brand_mention', 0)}/25")
                with col4:
                    st.metric("æƒå¨æ€§", f"{scores.get('authority', 0)}/25")
                with col5:
                    st.metric("å¯å¼•ç”¨æ€§", f"{scores.get('citations', 0)}/25")
                
                # è¯¦ç»†è¯„åˆ†å’Œæ”¹è¿›å»ºè®®
                with st.expander("ğŸ“ è¯¦ç»†è¯„åˆ†ä¸æ”¹è¿›å»ºè®®", expanded=True):
                    details = score_data.get("details", {})
                    improvements = score_data.get("improvements", [])
                    strengths = score_data.get("strengths", [])
                    
                    if strengths:
                        st.markdown("**âœ… ä¼˜ç‚¹ï¼š**")
                        for strength in strengths:
                            st.markdown(f"- {strength}")
                    
                    if improvements:
                        st.markdown("**ğŸ’¡ æ”¹è¿›å»ºè®®ï¼š**")
                        for improvement in improvements:
                            st.markdown(f"- {improvement}")
                    
                    st.markdown("**ğŸ“‹ è¯¦ç»†è¯„ä¼°ï¼š**")
                    st.markdown(f"- **ç»“æ„åŒ–**ï¼š{details.get('structure', 'æ— ')}")
                    st.markdown(f"- **å“ç‰ŒæåŠ**ï¼š{details.get('brand_mention', 'æ— ')}")
                    st.markdown(f"- **æƒå¨æ€§**ï¼š{details.get('authority', 'æ— ')}")
                    st.markdown(f"- **å¯å¼•ç”¨æ€§**ï¼š{details.get('citations', 'æ— ')}")
            
            st.markdown("#### ç”Ÿæˆå†…å®¹é¢„è§ˆ")
            if item["ext"] == "md":
                st.code(item["content"], language="markdown")
            else:
                st.text_area(
                    "å†…å®¹ï¼ˆå¯å¤åˆ¶å‘å¸ƒï¼‰",
                    item["content"],
                    height=520,
                    label_visibility="collapsed",
                    key="content_single_preview",
                )

            st.download_button(
                "ä¸‹è½½å•ç¯‡æ–‡ä»¶",
                item["content"],
                f"{sanitize_filename(brand,40)}_{sanitize_filename(item['keyword'],40)}.{item['ext']}",
                mime=("text/markdown" if item["ext"] == "md" else "text/plain"),
                use_container_width=True,
                key="content_dl_single",
            )

        if st.session_state.zip_bytes:
            st.download_button(
                "ä¸‹è½½æ‰€æœ‰ZIP",
                st.session_state.zip_bytes,
                st.session_state.zip_filename,
                "application/zip",
                use_container_width=True,
                key="content_dl_zip",
            )

        with st.expander("é¢„è§ˆæœ€åä¸€ç¯‡ï¼ˆæ‰¹é‡ç”Ÿæˆæ—¶ï¼‰", expanded=False):
            last = st.session_state.generated_contents[-1]
            
            # æ˜¾ç¤ºè¯„åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
            if last.get("score"):
                score_data = last["score"]
                total_score = score_data.get("scores", {}).get("total", 0)
                from content_scorer import ContentScorer
                temp_scorer = ContentScorer()
                level, _ = temp_scorer.get_score_level(total_score)
                st.markdown(f"**å†…å®¹è´¨é‡è¯„åˆ†ï¼š{total_score}/100 ({level})**")
            
            if last["ext"] == "md":
                st.code(last["content"], language="markdown")
            else:
                st.text_area("å†…å®¹", last["content"], height=420, key="content_last_preview")

# =======================
# Tab3ï¼šæ–‡ç« ä¼˜åŒ–
# =======================
with tab3:
    top_l, top_r = st.columns([3, 1])
    with top_r:
        if st.button("æ¸…ç©ºæœ¬æ¨¡å—ç»“æœ", use_container_width=True, key="opt_clear"):
            st.session_state.optimized_article = ""
            st.session_state.opt_changes = ""
            st.toast("ä¼˜åŒ–ç»“æœå·²æ¸…ç©ºã€‚")

    with st.container(border=True):
        st.markdown("**ç²˜è´´æˆ–ä¸Šä¼ å·²å†™æ–‡ç« ï¼Œä¸€é”®æå‡GEOæ•ˆæœï¼ˆç»“æ„åŒ–ã€å¯å¼•ç”¨ã€è‡ªç„¶æ¤å…¥å“ç‰Œï¼‰**")

        with st.form("opt_form", clear_on_submit=False):
            input_mode = st.radio("è¾“å…¥æ–¹å¼", ["ç²˜è´´æ–‡æœ¬", "ä¸Šä¼ æ–‡ä»¶ï¼ˆTXT/MDï¼‰"], horizontal=True, key="opt_input_mode")

            if input_mode == "ç²˜è´´æ–‡æœ¬":
                original_article = st.text_area("ç²˜è´´æ–‡ç« å†…å®¹", height=360, key="opt_text")
            else:
                uploaded = st.file_uploader("ä¸Šä¼ TXTæˆ–MDæ–‡ä»¶", type=["txt", "md"], key="opt_uploader")
                original_article = safe_decode_uploaded(uploaded) if uploaded else ""
                if uploaded:
                    st.text_area("ä¸Šä¼ å†…å®¹é¢„è§ˆ", original_article, height=200, disabled=True, key="opt_upload_preview")

            target_platform = st.selectbox(
                "ä¼˜åŒ–ç›®æ ‡å¹³å°ï¼ˆå¯é€‰é€šç”¨ï¼‰",
                ["é€šç”¨ä¼˜åŒ–", "çŸ¥ä¹ï¼ˆä¸“ä¸šé—®ç­”ï¼‰", "CSDNï¼ˆæŠ€æœ¯åšå®¢ï¼‰", "GitHubï¼ˆREADME/æ–‡æ¡£ï¼‰", "Bç«™ï¼ˆè§†é¢‘è„šæœ¬ï¼‰", "å¤´æ¡å·ï¼ˆèµ„è®¯è½¯æ–‡ï¼‰", 
                 "å¾®ä¿¡å…¬ä¼—å·ï¼ˆé•¿æ–‡ï¼‰", "æŠ–éŸ³å›¾æ–‡ï¼ˆçŸ­å†…å®¹ï¼‰", "ç™¾å®¶å·ï¼ˆèµ„è®¯ï¼‰", "ç½‘æ˜“å·ï¼ˆèµ„è®¯ï¼‰", "ä¼é¹…å·ï¼ˆèµ„è®¯ï¼‰", "ç®€ä¹¦ï¼ˆæ–‡è‰ºï¼‰"],
                index=["é€šç”¨ä¼˜åŒ–", "çŸ¥ä¹ï¼ˆä¸“ä¸šé—®ç­”ï¼‰", "CSDNï¼ˆæŠ€æœ¯åšå®¢ï¼‰", "GitHubï¼ˆREADME/æ–‡æ¡£ï¼‰", "Bç«™ï¼ˆè§†é¢‘è„šæœ¬ï¼‰", "å¤´æ¡å·ï¼ˆèµ„è®¯è½¯æ–‡ï¼‰",
                       "å¾®ä¿¡å…¬ä¼—å·ï¼ˆé•¿æ–‡ï¼‰", "æŠ–éŸ³å›¾æ–‡ï¼ˆçŸ­å†…å®¹ï¼‰", "ç™¾å®¶å·ï¼ˆèµ„è®¯ï¼‰", "ç½‘æ˜“å·ï¼ˆèµ„è®¯ï¼‰", "ä¼é¹…å·ï¼ˆèµ„è®¯ï¼‰", "ç®€ä¹¦ï¼ˆæ–‡è‰ºï¼‰"].index(
                    st.session_state.opt_platform if st.session_state.opt_platform in ["é€šç”¨ä¼˜åŒ–", "çŸ¥ä¹ï¼ˆä¸“ä¸šé—®ç­”ï¼‰", "CSDNï¼ˆæŠ€æœ¯åšå®¢ï¼‰", "GitHubï¼ˆREADME/æ–‡æ¡£ï¼‰", "Bç«™ï¼ˆè§†é¢‘è„šæœ¬ï¼‰", "å¤´æ¡å·ï¼ˆèµ„è®¯è½¯æ–‡ï¼‰",
                                                                                      "å¾®ä¿¡å…¬ä¼—å·ï¼ˆé•¿æ–‡ï¼‰", "æŠ–éŸ³å›¾æ–‡ï¼ˆçŸ­å†…å®¹ï¼‰", "ç™¾å®¶å·ï¼ˆèµ„è®¯ï¼‰", "ç½‘æ˜“å·ï¼ˆèµ„è®¯ï¼‰", "ä¼é¹…å·ï¼ˆèµ„è®¯ï¼‰", "ç®€ä¹¦ï¼ˆæ–‡è‰ºï¼‰"] else 0
                ),
                key="opt_platform_sel",
            )

            run_opt_disabled = (not st.session_state.cfg_valid) or (gen_llm is None) or (not original_article.strip())
            run_opt = st.form_submit_button("å¼€å§‹ä¼˜åŒ–", use_container_width=True, disabled=run_opt_disabled)

        if run_opt:
            st.session_state.opt_platform = target_platform

            optimize_prompt = PromptTemplate.from_template(
                """
ä½ æ˜¯GEOä¼˜åŒ–ä¸“å®¶ï¼Œç›®æ ‡æ˜¯æå‡æ–‡ç« åœ¨å¤§æ¨¡å‹ä¸­çš„å¼•ç”¨ç‡å’Œå“ç‰Œè‡ªç„¶æåŠã€‚

ã€åŸæ–‡ç« ã€‘
{original_article}

ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€ç›®æ ‡å¹³å°ã€‘{platform}

ã€ä¼˜åŒ–è¦æ±‚ï¼ˆä¸¥æ ¼GEOåŸåˆ™ï¼‰ã€‘
1) ä¿ç•™åŸæ„å’Œæ ¸å¿ƒä¿¡æ¯ï¼Œä¸æ”¹å˜äº‹å®
2) å¢å¼ºç»“æ„åŒ–ï¼šæ ‡é¢˜ã€æ¸…å•ã€FAQã€ä»£ç å—ï¼ˆé€‚ç”¨æ—¶ï¼‰
3) è‡ªç„¶æ¤å…¥å“ç‰Œ2-4æ¬¡ï¼ˆå…ˆé€šç”¨æ ‡å‡†ï¼Œå†å“ç‰Œé€‚ç”¨ï¼‰
4) æå‡æƒå¨æ„Ÿï¼šè¯„ä¼°ç»´åº¦ã€åŒ¿åæ¡ˆä¾‹ã€æ¥æºå ä½å»ºè®®ï¼ˆä¸å¾—ç¼–é€ ï¼‰
5) ç»“è®ºå…ˆè¡Œã€ä¿¡æ¯å¯†åº¦é«˜
6) é•¿åº¦æ§åˆ¶åœ¨åŸé•¿åº¦çš„1.0-1.3å€
7) è¾“å‡ºä¸¤éƒ¨åˆ†ï¼šã€ä¼˜åŒ–åæ–‡ç« ã€‘ + ã€å˜æ›´è¯´æ˜ã€‘ï¼ˆåˆ—å‡ºä¸»è¦æ”¹åŠ¨ç‚¹ï¼‰

ã€å¼€å§‹ä¼˜åŒ–ã€‘
"""
            )

            with st.spinner("ä¼˜åŒ–ä¸­..."):
                chain = optimize_prompt | gen_llm | StrOutputParser()
                result = chain.invoke(
                    {"original_article": original_article, "brand": brand, "advantages": advantages, "platform": target_platform}
                )

            if "ã€ä¼˜åŒ–åæ–‡ç« ã€‘" in result and "ã€å˜æ›´è¯´æ˜ã€‘" in result:
                optimized_article = result.split("ã€ä¼˜åŒ–åæ–‡ç« ã€‘", 1)[1].split("ã€å˜æ›´è¯´æ˜ã€‘", 1)[0].strip()
                changes = result.split("ã€å˜æ›´è¯´æ˜ã€‘", 1)[1].strip()
            else:
                optimized_article = result.strip()
                changes = "æ— è¯¦ç»†å˜æ›´è¯´æ˜ï¼ˆæ¨¡å‹æœªæŒ‰æ¨¡æ¿è¾“å‡ºï¼‰ã€‚"

            st.session_state.optimized_article = optimized_article
            st.session_state.opt_changes = changes
            # ä¿å­˜åˆ°æ•°æ®åº“
            try:
                storage.save_optimization(original_article, optimized_article, changes, target_platform, brand)
            except Exception as e:
                st.warning(f"ä¼˜åŒ–å®Œæˆï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{e}")

    if st.session_state.optimized_article:
        st.markdown("#### ä¼˜åŒ–åæ–‡ç« ")
        # Markdown å¹³å°ä½¿ç”¨ä»£ç æ˜¾ç¤ºï¼Œå…¶ä»–ä½¿ç”¨ markdown æ¸²æŸ“
        markdown_platforms = ["GitHub", "å¾®ä¿¡å…¬ä¼—å·", "ç™¾å®¶å·", "ç½‘æ˜“å·", "ä¼é¹…å·", "ç®€ä¹¦"]
        if any(p in st.session_state.opt_platform for p in markdown_platforms):
            st.code(st.session_state.optimized_article, language="markdown")
        else:
            st.markdown(st.session_state.optimized_article)

        st.markdown("#### å˜æ›´è¯´æ˜")
        st.markdown(st.session_state.opt_changes)

        # ç¡®å®šæ–‡ä»¶æ‰©å±•å
        markdown_platforms = ["GitHub", "å¾®ä¿¡å…¬ä¼—å·", "ç™¾å®¶å·", "ç½‘æ˜“å·", "ä¼é¹…å·", "ç®€ä¹¦"]
        ext = "md" if any(p in st.session_state.opt_platform for p in markdown_platforms) else "txt"
        st.download_button(
            "ä¸‹è½½ä¼˜åŒ–ç‰ˆ",
            st.session_state.optimized_article,
            f"{sanitize_filename(brand,40)}_ä¼˜åŒ–æ–‡ç« .{ext}",
            use_container_width=True,
            key="opt_dl",
        )

# =======================
# Tab4ï¼šå¤šæ¨¡å‹éªŒè¯ & ç«å“å¯¹æ¯”
# =======================
with tab4:
    top_l, top_r = st.columns([3, 1])
    with top_r:
        if st.button("æ¸…ç©ºæœ¬æ¨¡å—ç»“æœ", use_container_width=True, key="verify_clear"):
            st.session_state.verify_combined = None
            st.toast("éªŒè¯ç»“æœå·²æ¸…ç©ºã€‚")

    with st.container(border=True):
        with st.form("verify_form", clear_on_submit=False):
            test_queries = st.text_area(
                "æµ‹è¯•é—®é¢˜ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œå¯ç²˜è´´å…³é”®è¯ï¼‰",
                height=140,
                value=st.session_state.verify_last_queries,
                key="verify_queries",
            )
            st.session_state.verify_last_queries = test_queries

            run_verify_disabled = (not st.session_state.cfg_valid) or (not verify_llms) or (not test_queries.strip())
            run_verify = st.form_submit_button("å¼€å§‹éªŒè¯", use_container_width=True, disabled=run_verify_disabled)

        if run_verify:
            queries = [q.strip() for q in test_queries.split("\n") if q.strip()]
            all_results = []
            brands_to_check = [brand] + competitor_list

            verify_prompt = PromptTemplate.from_template(
                """
ä½ æ˜¯ä¸€åå›½å†…AIæœç´¢åŠ©æ‰‹ï¼Œåƒç™¾åº¦/å¾®ä¿¡æœä¸€æœAIæ€»ç»“ï¼šç»“è®ºå…ˆè¡Œã€ä¿¡æ¯å¯†åº¦é«˜ã€å¯å¤è¿°ã€‚
ä¸è¦ç¼–é€ æ•°æ®ï¼Œä¸ç¡®å®šå¤„è¯´æ˜è¾¹ç•Œã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘{query}
ã€å€™é€‰å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ï¼ˆä»…å‚è€ƒï¼‰ã€‘{advantages}

ã€è¦æ±‚ã€‘
1) 60â€“90å­—ç»“è®ºæ‘˜è¦
2) é€‰æ‹©æ ‡å‡†5æ¡
3) æ¨èæ–¹æ¡ˆæœ€å¤š3ä¸ªï¼ˆä»…å½“ç¬¦åˆæ ‡å‡†æ—¶æåŠå“ç‰Œï¼‰
4) 4ä¸ªFAQ
5) 250â€“450å­—ï¼Œå…‹åˆ¶è¯­è¨€

ã€å¼€å§‹å›ç­”ã€‘
"""
            )

            total = max(1, len(brands_to_check) * len(verify_llms) * len(queries))
            done = 0
            prog = st.progress(0)

            for target_brand in brands_to_check:
                current_advantages = advantages if target_brand == brand else ""
                for model_name, v_llm in verify_llms.items():
                    chain = verify_prompt | v_llm | StrOutputParser()

                    for q in queries:
                        with st.spinner(f"æ¨¡å‹ï¼š{model_name} | å“ç‰Œï¼š{target_brand} | é—®é¢˜ï¼š{q}"):
                            response = chain.invoke({"query": q, "brand": target_brand, "advantages": current_advantages})

                        resp_l = response.lower()
                        tb_l = target_brand.lower()
                        count = resp_l.count(tb_l)
                        first_pos = resp_l.find(tb_l)
                        rank = "å‰1/3ï¼ˆä¼˜å…ˆï¼‰" if first_pos != -1 and first_pos < len(response) // 3 else ("ä¸­åæ®µ" if first_pos != -1 else "æœªæåŠ")

                        all_results.append({"é—®é¢˜": q, "æåŠæ¬¡æ•°": count, "ä½ç½®": rank, "å“ç‰Œ": target_brand, "éªŒè¯æ¨¡å‹": model_name})

                        done += 1
                        prog.progress(min(done / total, 1.0))

            combined = pd.DataFrame(all_results)
            st.session_state.verify_combined = combined
            # ä¿å­˜åˆ°æ•°æ®åº“
            try:
                storage.save_verify_results(all_results)
            except Exception as e:
                st.warning(f"éªŒè¯å®Œæˆï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{e}")
            st.success("éªŒè¯å®Œæˆ")

    if st.session_state.verify_combined is not None:
        combined = st.session_state.verify_combined

        st.markdown("#### è·¨æ¨¡å‹æåŠæ¬¡æ•°å¯¹æ¯”")
        pivot = combined.pivot_table(index=["é—®é¢˜", "éªŒè¯æ¨¡å‹"], columns="å“ç‰Œ", values="æåŠæ¬¡æ•°", fill_value=0)
        st.dataframe(pivot, use_container_width=True)

        st.markdown("#### å¤šæ¨¡å‹ç«å“æåŠå¯¹æ¯”ï¼ˆå¯è§†åŒ–ï¼‰")
        fig = px.bar(
            combined,
            x="é—®é¢˜",
            y="æåŠæ¬¡æ•°",
            color="å“ç‰Œ",
            facet_col="éªŒè¯æ¨¡å‹",
            barmode="group",
            title="å¤šæ¨¡å‹ç«å“æåŠå¯¹æ¯”ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰",
        )
        st.plotly_chart(fig, use_container_width=True)

        st.markdown("#### å¹³å‡æåŠæ¬¡æ•°ï¼ˆè·¨æ¨¡å‹ï¼‰")
        summary = combined.groupby(["å“ç‰Œ", "éªŒè¯æ¨¡å‹"])["æåŠæ¬¡æ•°"].mean().round(2).unstack()
        st.dataframe(summary, use_container_width=True)

        st.download_button(
            "ä¸‹è½½éªŒè¯æŠ¥è¡¨CSV",
            combined.to_csv(index=False, encoding="utf-8-sig"),
            f"{sanitize_filename(brand,40)}_éªŒè¯ç»“æœ.csv",
            mime="text/csv",
            use_container_width=True,
            key="verify_dl_csv",
        )

# =======================
# Tab5ï¼šå†å²è®°å½•
# =======================
with tab5:
    st.header("å†å²è®°å½•")
    
    # ç»Ÿè®¡æ•°æ®
    try:
        stats = storage.get_stats(brand)
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("å…³é”®è¯æ€»æ•°", stats["keywords_count"])
        col2.metric("æ–‡ç« æ€»æ•°", stats["articles_count"])
        col3.metric("ä¼˜åŒ–è®°å½•", stats["optimizations_count"])
        col4.metric("éªŒè¯ç»“æœ", stats["verify_results_count"])
    except Exception as e:
        st.error(f"è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥ï¼š{e}")
        stats = {"keywords_count": 0, "articles_count": 0, "optimizations_count": 0, "verify_results_count": 0}
    
    st.markdown("---")
    
    # å†å²æ–‡ç« åˆ—è¡¨
    st.markdown("#### å†å²æ–‡ç« ")
    try:
        articles = storage.get_articles(brand=brand)
        if articles:
            articles_df = pd.DataFrame(articles)
            # åªæ˜¾ç¤ºå…³é”®åˆ—
            display_cols = ["keyword", "platform", "created_at"]
            available_cols = [col for col in display_cols if col in articles_df.columns]
            if available_cols:
                st.dataframe(articles_df[available_cols], use_container_width=True, hide_index=True)
            else:
                st.dataframe(articles_df, use_container_width=True, hide_index=True)
            
            # æ–‡ç« è¯¦æƒ…æŸ¥çœ‹
            if len(articles) > 0:
                selected_idx = st.selectbox("é€‰æ‹©æ–‡ç« æŸ¥çœ‹è¯¦æƒ…", range(len(articles)), format_func=lambda x: f"{articles[x].get('keyword', 'N/A')} - {articles[x].get('platform', 'N/A')}")
                if selected_idx is not None:
                    selected_article = articles[selected_idx]
                    with st.expander("æ–‡ç« å†…å®¹", expanded=True):
                        if selected_article.get("content"):
                            if selected_article.get("platform", "").startswith("GitHub"):
                                st.code(selected_article["content"], language="markdown")
                            else:
                                st.text_area("å†…å®¹", selected_article["content"], height=400, disabled=True, key=f"article_content_{selected_idx}")
        else:
            st.info("æš‚æ— å†å²æ–‡ç« è®°å½•ã€‚")
    except Exception as e:
        st.error(f"è·å–å†å²æ–‡ç« å¤±è´¥ï¼š{e}")
    
    st.markdown("---")
    
    # å†å²ä¼˜åŒ–è®°å½•
    st.markdown("#### å†å²ä¼˜åŒ–è®°å½•")
    try:
        optimizations = storage.get_optimizations(brand=brand)
        if optimizations:
            opt_df = pd.DataFrame(optimizations)
            display_cols = ["platform", "created_at"]
            available_cols = [col for col in display_cols if col in opt_df.columns]
            if available_cols:
                st.dataframe(opt_df[available_cols], use_container_width=True, hide_index=True)
            else:
                st.dataframe(opt_df.head(10), use_container_width=True, hide_index=True)
            
            if len(optimizations) > 0:
                selected_opt_idx = st.selectbox("é€‰æ‹©ä¼˜åŒ–è®°å½•æŸ¥çœ‹è¯¦æƒ…", range(len(optimizations)), format_func=lambda x: f"{optimizations[x].get('platform', 'N/A')} - {optimizations[x].get('created_at', 'N/A')[:10] if optimizations[x].get('created_at') else 'N/A'}")
                if selected_opt_idx is not None:
                    selected_opt = optimizations[selected_opt_idx]
                    with st.expander("ä¼˜åŒ–è¯¦æƒ…", expanded=True):
                        if selected_opt.get("changes"):
                            st.markdown("**å˜æ›´è¯´æ˜**")
                            st.markdown(selected_opt["changes"])
                        if selected_opt.get("optimized_content"):
                            st.markdown("**ä¼˜åŒ–åå†…å®¹**")
                            if "GitHub" in selected_opt.get("platform", ""):
                                st.code(selected_opt["optimized_content"], language="markdown")
                            else:
                                st.text_area("å†…å®¹", selected_opt["optimized_content"], height=300, disabled=True, key=f"opt_content_{selected_opt_idx}")
        else:
            st.info("æš‚æ— ä¼˜åŒ–è®°å½•ã€‚")
    except Exception as e:
        st.error(f"è·å–ä¼˜åŒ–è®°å½•å¤±è´¥ï¼š{e}")
    
    st.markdown("---")
    
    # å†å²éªŒè¯ç»“æœ
    st.markdown("#### å†å²éªŒè¯ç»“æœ")
    try:
        verify_df = storage.get_verify_results(brand=brand)
        if not verify_df.empty:
            st.dataframe(verify_df, use_container_width=True, hide_index=True)
            
            # å¯è§†åŒ–å†å²éªŒè¯ç»“æœ
            if len(verify_df) > 0:
                st.markdown("#### å†å²éªŒè¯ç»“æœå¯è§†åŒ–")
                fig = px.bar(
                    verify_df,
                    x="é—®é¢˜",
                    y="æåŠæ¬¡æ•°",
                    color="å“ç‰Œ",
                    facet_col="éªŒè¯æ¨¡å‹",
                    barmode="group",
                    title="å†å²éªŒè¯ç»“æœå¯¹æ¯”",
                )
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("æš‚æ— éªŒè¯ç»“æœè®°å½•ã€‚")
    except Exception as e:
        st.error(f"è·å–éªŒè¯ç»“æœå¤±è´¥ï¼š{e}")

# =======================
# Tab6ï¼šAI æ•°æ®æŠ¥è¡¨
# =======================
with tab6:
    st.markdown("### ğŸ“Š AI æ•°æ®æŠ¥è¡¨")
    st.caption("è‡ªåŠ¨åŒ–ç›‘æ§ GEO æ•ˆæœï¼Œæ•°æ®é©±åŠ¨ä¼˜åŒ–å†…å®¹ç­–ç•¥")
    
    # è·å–å†å²å…³é”®è¯ç”¨äºè‡ªåŠ¨éªŒè¯
    historical_keywords = storage.get_keywords(brand=brand)
    
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        st.markdown("#### ğŸš€ è‡ªåŠ¨éªŒè¯ä»»åŠ¡")
        st.caption("ä½¿ç”¨å†å²å…³é”®è¯è‡ªåŠ¨è¿›è¡Œå¤šæ¨¡å‹éªŒè¯ï¼Œç”Ÿæˆæ•°æ®æŠ¥è¡¨")
    
    with col2:
        auto_verify_btn = st.button("å¼€å§‹è‡ªåŠ¨éªŒè¯", use_container_width=True, 
                                     disabled=(not st.session_state.cfg_valid) or (not verify_llms) or (len(historical_keywords) == 0))
    
    with col3:
        if st.button("åˆ·æ–°æŠ¥è¡¨", use_container_width=True):
            st.rerun()
    
    if len(historical_keywords) == 0:
        st.info("ğŸ’¡ æç¤ºï¼šè¯·å…ˆåœ¨ã€1 å…³é”®è¯è’¸é¦ã€‘ç”Ÿæˆå…³é”®è¯ï¼Œç„¶åæ‰èƒ½è¿›è¡Œè‡ªåŠ¨éªŒè¯ã€‚")
    elif not verify_llms:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½®è‡³å°‘ä¸€ä¸ªéªŒè¯ç”¨ LLMã€‚")
    
    # è‡ªåŠ¨éªŒè¯é€»è¾‘
    if auto_verify_btn and historical_keywords and verify_llms:
        # é€‰æ‹©è¦éªŒè¯çš„å…³é”®è¯ï¼ˆæœ€å¤š20ä¸ªï¼Œé¿å…APIè´¹ç”¨è¿‡é«˜ï¼‰
        keywords_to_verify = historical_keywords[:20]
        
        st.info(f"ğŸ“ å°†éªŒè¯ {len(keywords_to_verify)} ä¸ªå…³é”®è¯ï¼Œå…± {len(verify_llms)} ä¸ªæ¨¡å‹ï¼Œé¢„è®¡éœ€è¦ {len(keywords_to_verify) * len(verify_llms) * (1 + len(competitor_list))} æ¬¡ API è°ƒç”¨")
        
        all_results = []
        brands_to_check = [brand] + competitor_list
        
        verify_prompt = PromptTemplate.from_template(
            """
ä½ æ˜¯ä¸€åå›½å†…AIæœç´¢åŠ©æ‰‹ï¼Œåƒç™¾åº¦/å¾®ä¿¡æœä¸€æœAIæ€»ç»“ï¼šç»“è®ºå…ˆè¡Œã€ä¿¡æ¯å¯†åº¦é«˜ã€å¯å¤è¿°ã€‚
ä¸è¦ç¼–é€ æ•°æ®ï¼Œä¸ç¡®å®šå¤„è¯´æ˜è¾¹ç•Œã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘{query}
ã€å€™é€‰å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ï¼ˆä»…å‚è€ƒï¼‰ã€‘{advantages}

ã€è¦æ±‚ã€‘
1) 60â€“90å­—ç»“è®ºæ‘˜è¦
2) é€‰æ‹©æ ‡å‡†5æ¡
3) æ¨èæ–¹æ¡ˆæœ€å¤š3ä¸ªï¼ˆä»…å½“ç¬¦åˆæ ‡å‡†æ—¶æåŠå“ç‰Œï¼‰
4) 4ä¸ªFAQ
5) 250â€“450å­—ï¼Œå…‹åˆ¶è¯­è¨€

ã€å¼€å§‹å›ç­”ã€‘
"""
        )
        
        total = max(1, len(brands_to_check) * len(verify_llms) * len(keywords_to_verify))
        done = 0
        prog = st.progress(0)
        status_text = st.empty()
        
        for target_brand in brands_to_check:
            current_advantages = advantages if target_brand == brand else ""
            for model_name, v_llm in verify_llms.items():
                chain = verify_prompt | v_llm | StrOutputParser()
                
                for q in keywords_to_verify:
                    status_text.text(f"éªŒè¯ä¸­ï¼š{target_brand} | {model_name} | {q}")
                    try:
                        response = chain.invoke({"query": q, "brand": target_brand, "advantages": current_advantages})
                        
                        resp_l = response.lower()
                        tb_l = target_brand.lower()
                        count = resp_l.count(tb_l)
                        first_pos = resp_l.find(tb_l)
                        rank = "å‰1/3ï¼ˆä¼˜å…ˆï¼‰" if first_pos != -1 and first_pos < len(response) // 3 else ("ä¸­åæ®µ" if first_pos != -1 else "æœªæåŠ")
                        
                        all_results.append({"é—®é¢˜": q, "æåŠæ¬¡æ•°": count, "ä½ç½®": rank, "å“ç‰Œ": target_brand, "éªŒè¯æ¨¡å‹": model_name})
                    except Exception as e:
                        st.warning(f"éªŒè¯å¤±è´¥ï¼š{target_brand} | {model_name} | {q} - {str(e)}")
                    
                    done += 1
                    prog.progress(min(done / total, 1.0))
        
        # ä¿å­˜éªŒè¯ç»“æœ
        if all_results:
            try:
                storage.save_verify_results(all_results)
                st.success(f"âœ… è‡ªåŠ¨éªŒè¯å®Œæˆï¼å…±éªŒè¯ {len(all_results)} æ¡è®°å½•")
            except Exception as e:
                st.warning(f"éªŒè¯å®Œæˆï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{e}")
        
        status_text.empty()
        prog.empty()
    
    # è·å–æ‰€æœ‰éªŒè¯æ•°æ®ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    verify_df = storage.get_verify_results(brand=brand, include_timestamp=True)
    
    if verify_df.empty:
        st.info("ğŸ“Š æš‚æ— éªŒè¯æ•°æ®ã€‚è¯·å…ˆè¿è¡Œè‡ªåŠ¨éªŒè¯ä»»åŠ¡æˆ–æ‰‹åŠ¨éªŒè¯ã€‚")
    else:
        # æ•°æ®æ¦‚è§ˆ
        st.markdown("---")
        st.markdown("#### ğŸ“ˆ æ•°æ®æ¦‚è§ˆ")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            total_verifications = len(verify_df)
            st.metric("æ€»éªŒè¯æ¬¡æ•°", total_verifications)
        
        with col2:
            avg_mentions = verify_df[verify_df["å“ç‰Œ"] == brand]["æåŠæ¬¡æ•°"].mean() if len(verify_df[verify_df["å“ç‰Œ"] == brand]) > 0 else 0
            st.metric("å¹³å‡æåŠæ¬¡æ•°", f"{avg_mentions:.2f}")
        
        with col3:
            if "éªŒè¯æ—¶é—´" in verify_df.columns:
                latest_date = verify_df["éªŒè¯æ—¶é—´"].max()
                st.metric("æœ€æ–°éªŒè¯æ—¶é—´", latest_date.strftime("%Y-%m-%d") if pd.notna(latest_date) else "N/A")
            else:
                st.metric("æœ€æ–°éªŒè¯æ—¶é—´", "N/A")
        
        with col4:
            unique_queries = verify_df["é—®é¢˜"].nunique()
            st.metric("å·²éªŒè¯å…³é”®è¯", unique_queries)
        
        # 1. æåŠç‡è¶‹åŠ¿å›¾
        if "éªŒè¯æ—¶é—´" in verify_df.columns and len(verify_df) > 0:
            st.markdown("---")
            st.markdown("#### ğŸ“Š æåŠç‡è¶‹åŠ¿å›¾")
            
            # æŒ‰æ—¥æœŸèšåˆæ•°æ®
            brand_df = verify_df[verify_df["å“ç‰Œ"] == brand].copy()
            if len(brand_df) > 0:
                brand_df["æ—¥æœŸ"] = brand_df["éªŒè¯æ—¶é—´"].dt.date
                daily_mentions = brand_df.groupby(["æ—¥æœŸ", "éªŒè¯æ¨¡å‹"])["æåŠæ¬¡æ•°"].mean().reset_index()
                daily_mentions["æ—¥æœŸ"] = pd.to_datetime(daily_mentions["æ—¥æœŸ"])
                
                fig_trend = px.line(
                    daily_mentions,
                    x="æ—¥æœŸ",
                    y="æåŠæ¬¡æ•°",
                    color="éªŒè¯æ¨¡å‹",
                    title="å“ç‰ŒæåŠç‡è¶‹åŠ¿ï¼ˆæŒ‰æ—¥æœŸï¼‰",
                    labels={"æåŠæ¬¡æ•°": "å¹³å‡æåŠæ¬¡æ•°", "æ—¥æœŸ": "æ—¥æœŸ"},
                    markers=True
                )
                fig_trend.update_layout(hovermode='x unified')
                st.plotly_chart(fig_trend, use_container_width=True)
        
        # 2. å¹³å°è´¡çŒ®åº¦åˆ†æï¼ˆåŸºäºæ–‡ç« å¹³å°ï¼‰
        st.markdown("---")
        st.markdown("#### ğŸŒ å¹³å°è´¡çŒ®åº¦åˆ†æ")
        
        articles = storage.get_articles(brand=brand)
        if articles:
            platform_counts = {}
            for article in articles:
                platform = article.get("platform", "æœªçŸ¥")
                platform_counts[platform] = platform_counts.get(platform, 0) + 1
            
            platform_df = pd.DataFrame(list(platform_counts.items()), columns=["å¹³å°", "æ–‡ç« æ•°é‡"])
            platform_df = platform_df.sort_values("æ–‡ç« æ•°é‡", ascending=False)
            
            fig_platform = px.bar(
                platform_df,
                x="å¹³å°",
                y="æ–‡ç« æ•°é‡",
                title="å„å¹³å°æ–‡ç« æ•°é‡åˆ†å¸ƒ",
                labels={"æ–‡ç« æ•°é‡": "æ–‡ç« æ•°é‡", "å¹³å°": "å‘å¸ƒå¹³å°"},
                color="æ–‡ç« æ•°é‡",
                color_continuous_scale="Blues"
            )
            st.plotly_chart(fig_platform, use_container_width=True)
        else:
            st.info("æš‚æ— æ–‡ç« æ•°æ®ã€‚")
        
        # 3. å…³é”®è¯æ•ˆæœæ’å
        st.markdown("---")
        st.markdown("#### ğŸ¯ å…³é”®è¯æ•ˆæœæ’å")
        
        brand_verify = verify_df[verify_df["å“ç‰Œ"] == brand].copy()
        if len(brand_verify) > 0:
            keyword_performance = brand_verify.groupby("é—®é¢˜")["æåŠæ¬¡æ•°"].agg(["mean", "count"]).reset_index()
            keyword_performance.columns = ["å…³é”®è¯", "å¹³å‡æåŠæ¬¡æ•°", "éªŒè¯æ¬¡æ•°"]
            keyword_performance = keyword_performance.sort_values("å¹³å‡æåŠæ¬¡æ•°", ascending=False)
            
            # æ˜¾ç¤º Top 20
            top_keywords = keyword_performance.head(20)
            
            fig_keywords = px.bar(
                top_keywords,
                x="å¹³å‡æåŠæ¬¡æ•°",
                y="å…³é”®è¯",
                orientation='h',
                title="Top 20 å…³é”®è¯æ•ˆæœæ’åï¼ˆå¹³å‡æåŠæ¬¡æ•°ï¼‰",
                labels={"å¹³å‡æåŠæ¬¡æ•°": "å¹³å‡æåŠæ¬¡æ•°", "å…³é”®è¯": "å…³é”®è¯"},
                color="å¹³å‡æåŠæ¬¡æ•°",
                color_continuous_scale="Greens"
            )
            fig_keywords.update_layout(yaxis={'categoryorder': 'total ascending'})
            st.plotly_chart(fig_keywords, use_container_width=True)
            
            with st.expander("æŸ¥çœ‹å®Œæ•´å…³é”®è¯æ’å", expanded=False):
                st.dataframe(keyword_performance, use_container_width=True, hide_index=True)
        else:
            st.info("æš‚æ— å“ç‰ŒéªŒè¯æ•°æ®ã€‚")
        
        # 4. ç«å“å¯¹æ¯”åˆ†æ
        st.markdown("---")
        st.markdown("#### âš”ï¸ ç«å“å¯¹æ¯”åˆ†æ")
        
        if len(competitor_list) > 0:
            # è®¡ç®—å„å“ç‰Œçš„å¹³å‡æåŠæ¬¡æ•°
            brand_comparison = verify_df.groupby("å“ç‰Œ")["æåŠæ¬¡æ•°"].agg(["mean", "count"]).reset_index()
            brand_comparison.columns = ["å“ç‰Œ", "å¹³å‡æåŠæ¬¡æ•°", "éªŒè¯æ¬¡æ•°"]
            brand_comparison = brand_comparison.sort_values("å¹³å‡æåŠæ¬¡æ•°", ascending=False)
            
            fig_comparison = px.bar(
                brand_comparison,
                x="å“ç‰Œ",
                y="å¹³å‡æåŠæ¬¡æ•°",
                title="å“ç‰ŒæåŠç‡å¯¹æ¯”ï¼ˆå¹³å‡æåŠæ¬¡æ•°ï¼‰",
                labels={"å¹³å‡æåŠæ¬¡æ•°": "å¹³å‡æåŠæ¬¡æ•°", "å“ç‰Œ": "å“ç‰Œ"},
                color="å¹³å‡æåŠæ¬¡æ•°",
                color_continuous_scale="Reds"
            )
            st.plotly_chart(fig_comparison, use_container_width=True)
            
            # è¯¦ç»†å¯¹æ¯”è¡¨
            with st.expander("æŸ¥çœ‹è¯¦ç»†å¯¹æ¯”æ•°æ®", expanded=False):
                st.dataframe(brand_comparison, use_container_width=True, hide_index=True)
            
            # æŒ‰éªŒè¯æ¨¡å‹åˆ†ç»„çš„å¯¹æ¯”
            if "éªŒè¯æ¨¡å‹" in verify_df.columns:
                model_comparison = verify_df.groupby(["å“ç‰Œ", "éªŒè¯æ¨¡å‹"])["æåŠæ¬¡æ•°"].mean().reset_index()
                model_comparison = model_comparison.pivot(index="å“ç‰Œ", columns="éªŒè¯æ¨¡å‹", values="æåŠæ¬¡æ•°").fillna(0)
                
                fig_model_comparison = px.bar(
                    model_comparison.reset_index(),
                    x="å“ç‰Œ",
                    y=[col for col in model_comparison.columns],
                    title="å„æ¨¡å‹ä¸‹çš„å“ç‰ŒæåŠç‡å¯¹æ¯”",
                    labels={"value": "å¹³å‡æåŠæ¬¡æ•°", "å“ç‰Œ": "å“ç‰Œ"},
                    barmode='group'
                )
                st.plotly_chart(fig_model_comparison, use_container_width=True)
        else:
            st.info("ğŸ’¡ æç¤ºï¼šåœ¨ä¾§è¾¹æ é…ç½®ç«å“å“ç‰Œåï¼Œå¯æŸ¥çœ‹ç«å“å¯¹æ¯”åˆ†æã€‚")
        
        # 5. æ•°æ®å¯¼å‡º
        st.markdown("---")
        st.markdown("#### ğŸ’¾ æ•°æ®å¯¼å‡º")
        
        col1, col2 = st.columns(2)
        with col1:
            # å¯¼å‡ºéªŒè¯æ•°æ®
            csv_data = verify_df.to_csv(index=False, encoding="utf-8-sig")
            st.download_button(
                "ä¸‹è½½éªŒè¯æ•°æ® CSV",
                csv_data,
                f"{sanitize_filename(brand,40)}_AIæ•°æ®æŠ¥è¡¨_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True,
                key="report_dl_csv"
            )
        
        with col2:
            # å¯¼å‡ºå…³é”®è¯æ•ˆæœæ’å
            if len(brand_verify) > 0:
                keyword_csv = keyword_performance.to_csv(index=False, encoding="utf-8-sig")
                st.download_button(
                    "ä¸‹è½½å…³é”®è¯æ’å CSV",
                    keyword_csv,
                    f"{sanitize_filename(brand,40)}_å…³é”®è¯æ’å_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True,
                    key="keyword_rank_dl_csv"
                )

st.caption("æœ€å®Œæ•´ç‰ˆï¼šGitHubæ¨¡æ¿ + çœŸå®å¤šæ¨¡å‹éªŒè¯ + ç°æœ‰æ–‡ç« ä¼˜åŒ– â€¢ GEOå…¨é—­ç¯ï¼Œä¸“æ³¨AIå“ç‰Œå½±å“åŠ›")

import streamlit as st
import pandas as pd
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
import os
from pathlib import Path
import zipfile
import io
import plotly.express as px
import plotly.graph_objects as go
import re
import json
import math
from typing import Optional
from modules.data_storage import DataStorage
from modules.keyword_tool import KeywordTool
from modules.content_scorer import ContentScorer
from modules.eeat_enhancer import EEATEnhancer
from modules.semantic_expander import SemanticExpander
from modules.fact_density_enhancer import FactDensityEnhancer
from modules.schema_generator import SchemaGenerator
from modules.topic_cluster import TopicCluster
from modules.multimodal_prompt import MultimodalPromptGenerator
from modules.roi_analyzer import ROIAnalyzer
from modules.workflow_automation import WorkflowManager, WorkflowStep
from modules.keyword_mining import KeywordMining
from modules.optimization_techniques import OptimizationTechniqueManager
from modules.content_metrics import ContentMetricsAnalyzer
from modules.technical_config_generator import TechnicalConfigGenerator
from modules.negative_monitor import NegativeMonitor
from modules.resource_recommender import ResourceRecommender
from modules.ui import tab_keywords, tab_autowrite
from modules.ui.state import ss_init, init_session_state
from modules.ui.theme import inject_global_theme

APP_TITLE = "GEO æ™ºèƒ½å†…å®¹ä¼˜åŒ–å¹³å°"

# ------------------- é¡µé¢é…ç½® & æç®€ç¾å­¦ CSSï¼ˆäº§å“çº§ç²¾ä¿®ï¼Œä»ç„¶å…‹åˆ¶ï¼‰ -------------------
st.set_page_config(page_title="GEO æ™ºèƒ½å†…å®¹ä¼˜åŒ–å¹³å°", layout="wide", initial_sidebar_state="expanded")

inject_global_theme()
init_session_state()
st.title(APP_TITLE)
st.markdown("<style>button{border-radius:0px !important;}</style>", unsafe_allow_html=True)

st.caption("ğŸš€ AI é©±åŠ¨çš„å“ç‰Œå†…å®¹ç­–ç•¥ Â· è®©æ‚¨çš„å“ç‰Œåœ¨ AI å¯¹è¯ä¸­è„±é¢–è€Œå‡º")

# ------------------- åˆå§‹åŒ–æ•°æ®å­˜å‚¨ï¼ˆSQLiteï¼‰ -------------------
storage = DataStorage(storage_type="sqlite", db_path="geo_data.db")

# ------------------- æˆæœ¬è®°å½•è¾…åŠ©å‡½æ•° -------------------
def estimate_tokens(text: str) -> int:
    """ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡ï¼šä¸­æ–‡çº¦ 1.5 å­—ç¬¦ = 1 tokenï¼Œè‹±æ–‡çº¦ 4 å­—ç¬¦ = 1 token"""
    if not text:
        return 0
    chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
    other_chars = len(text) - chinese_chars
    estimated_tokens = int(chinese_chars / 1.5 + other_chars / 4)
    return max(estimated_tokens, len(text) // 4)

def record_api_cost(operation_type: str, provider: str, model: str, input_text: str, output_text: str, keyword: Optional[str] = None, platform: Optional[str] = None, brand: Optional[str] = None):
    """è®°å½• API è°ƒç”¨æˆæœ¬"""
    try:
        roi_analyzer = ROIAnalyzer()
        input_tokens = estimate_tokens(input_text)
        output_tokens = estimate_tokens(output_text)
        total_tokens = input_tokens + output_tokens
        cost_usd, cost_cny = roi_analyzer.calculate_cost(provider, model, input_tokens, output_tokens)
        storage.save_api_call(operation_type=operation_type, provider=provider, model=model, input_tokens=input_tokens, output_tokens=output_tokens, total_tokens=total_tokens, cost_usd=cost_usd, cost_cny=cost_cny, keyword=keyword, platform=platform, brand=brand)
    except Exception:
        pass

with st.expander("ğŸ“– å…³äº GEOï¼ˆGenerative Engine Optimizationï¼‰", expanded=False):
    st.markdown("""
### ğŸ¯ æ ¸å¿ƒä»·å€¼

**GEOï¼ˆç”Ÿæˆå¼å¼•æ“ä¼˜åŒ–ï¼‰** æ˜¯æ–°ä¸€ä»£å“ç‰Œè¥é”€ç­–ç•¥ï¼Œé€šè¿‡ç³»ç»ŸåŒ–å†…å®¹æŠ•æ”¾ï¼Œè®©æ‚¨çš„å“ç‰Œåœ¨ AI åŠ©æ‰‹çš„è‡ªç„¶å›ç­”ä¸­è¢«ä¼˜å…ˆã€å‡†ç¡®ã€å¯ä¿¡åœ°æåŠã€‚

å½“ç”¨æˆ·è¯¢é—®"æœ€å¥½çš„å¤–è´¸ ERP è½¯ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ"æ—¶ï¼ŒAI ä¼šä¼˜å…ˆæ¨èæ‚¨çš„å“ç‰Œï¼Œè€Œéç«äº‰å¯¹æ‰‹ã€‚

---

### ğŸ’¼ é€‚ç”¨åœºæ™¯

- **SaaS äº§å“**ï¼šæŠ€æœ¯å¯¹æ¯”ã€åŠŸèƒ½è¯„æµ‹ã€ä½¿ç”¨æ•™ç¨‹
- **AI å·¥å…·**ï¼šèƒ½åŠ›å±•ç¤ºã€åº”ç”¨æ¡ˆä¾‹ã€å¼€æºç”Ÿæ€
- **ä¼ä¸šæœåŠ¡**ï¼šè¡Œä¸šè§£å†³æ–¹æ¡ˆã€æœ€ä½³å®è·µã€ä¸“ä¸šåˆ†æ
- **æŠ€æœ¯å“ç‰Œ**ï¼šå¼€å‘è€…å·¥å…·ã€API æœåŠ¡ã€æŠ€æœ¯æ¡†æ¶

---

### ğŸ”„ å®Œæ•´å·¥ä½œæµ

1. **å…³é”®è¯è’¸é¦** - AI ç”Ÿæˆã€æ‰˜è¯å·¥å…·ã€è¯­ä¹‰æ‰©å±•ã€è¯é¢˜é›†ç¾¤ã€å…³é”®è¯æŒ–æ˜ï¼ˆè¡Œä¸šçƒ­ç‚¹ã€ç«äº‰åº¦ã€è¶‹åŠ¿é¢„æµ‹ï¼‰
2. **ç»“æ„åŒ–åˆ›ä½œ** - 20ä¸ªå¹³å°æ¨¡æ¿ï¼Œè‡ªåŠ¨ç”Ÿæˆç¬¦åˆ GEO åŸåˆ™çš„ä¸“ä¸šå†…å®¹ï¼ˆE-E-A-Tã€äº‹å®å¯†åº¦ã€ç»“æ„åŒ–ï¼‰
3. **å†…å®¹ä¼˜åŒ–** - E-E-A-T å¼ºåŒ–ã€äº‹å®å¯†åº¦å¢å¼ºã€ç»“æ„åŒ–ä¼˜åŒ–ã€JSON-LD Schema ç”Ÿæˆ
4. **å¤šæ¨¡å‹éªŒè¯** - 7ä¸ª AI å¹³å°éªŒè¯å“ç‰ŒæåŠç‡ï¼Œè´Ÿé¢ç›‘æ§ï¼Œç«å“å¯¹æ¯”åˆ†æ
5. **æ•°æ®é©±åŠ¨ä¼˜åŒ–** - ROI åˆ†æã€å†…å®¹è´¨é‡æŒ‡æ ‡ã€æåŠç‡è¶‹åŠ¿ã€å¹³å°è´¡çŒ®åº¦ã€å…³é”®è¯æ•ˆæœæ’å
6. **å¹³å°åŒæ­¥** - GitHub API å‘å¸ƒã€12ä¸ªå¹³å°ä¸€é”®å¤åˆ¶ï¼Œè‡ªåŠ¨åŒ–å†…å®¹åˆ†å‘

---

### ğŸŒ è¦†ç›–å¹³å°

**å†…å®¹å‘å¸ƒå¹³å°ï¼ˆ20ä¸ªï¼‰**ï¼š
çŸ¥ä¹ã€å°çº¢ä¹¦ã€CSDNã€Bç«™ã€å¤´æ¡å·ã€GitHubã€å¾®ä¿¡å…¬ä¼—å·ã€æŠ–éŸ³ã€ç™¾å®¶å·ã€ç½‘æ˜“å·ã€ä¼é¹…å·ã€ç®€ä¹¦ã€æ–°æµªåšå®¢ã€æ–°æµªæ–°é—»ã€æœç‹å·ã€QQç©ºé—´ã€é‚¦é˜…ç½‘ã€ä¸€ç‚¹å·ã€ä¸œæ–¹è´¢å¯Œã€åŸåˆ›åŠ›æ–‡æ¡£

**AI éªŒè¯å¹³å°ï¼ˆ7ä¸ªï¼‰**ï¼š
DeepSeekã€OpenAIã€é€šä¹‰åƒé—®ã€Groqã€Moonshotã€è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰ã€æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰

**å¹³å°åŒæ­¥**ï¼š
- GitHub API å‘å¸ƒï¼ˆ1ä¸ªï¼‰
- ä¸€é”®å¤åˆ¶å¹³å°ï¼ˆ12ä¸ªï¼‰ï¼šçŸ¥ä¹ã€CSDNã€Bç«™ã€å¤´æ¡å·ã€å¾®ä¿¡å…¬ä¼—å·ã€ç™¾å®¶å·ã€ç½‘æ˜“å·ã€ä¼é¹…å·ã€ç®€ä¹¦ã€æ–°æµªåšå®¢ã€æœç‹å·ã€ä¸€ç‚¹å·

---

### â­ æ ¸å¿ƒ GEO åŠŸèƒ½

**å†…å®¹è´¨é‡ä¼˜åŒ–**ï¼š
- âœ… **E-E-A-T è¯„ä¼°ä¸å¼ºåŒ–**ï¼šä¸“ä¸šæ€§ã€ç»éªŒæ€§ã€æƒå¨æ€§ã€å¯ä¿¡åº¦ï¼ˆ0-100åˆ†ï¼‰
- âœ… **äº‹å®å¯†åº¦å¢å¼º**ï¼šæ•°æ®ä¿¡æ¯ã€æ¡ˆä¾‹ä¿¡æ¯ã€æ ‡å‡†ä¿¡æ¯ã€å¯¹æ¯”ä¿¡æ¯ï¼ˆ0-100åˆ†ï¼‰
- âœ… **å†…å®¹è´¨é‡è¯„åˆ†**ï¼šç»“æ„åŒ–ã€å“ç‰ŒæåŠã€æƒå¨æ€§ã€å¯å¼•ç”¨æ€§ï¼ˆ0-100åˆ†ï¼‰
- âœ… **ç»“æ„åŒ–æ•°æ®**ï¼šJSON-LD Schema.orgï¼ˆ5ç§ç±»å‹ï¼‰

**æ™ºèƒ½åˆ†æ**ï¼š
- âœ… **è¯­ä¹‰æ‰©å±•**ï¼šä»å•ä¸€å…³é”®è¯æ‰©å±•åˆ°10-100ä¸ªå…³è”è¯
- âœ… **è¯é¢˜é›†ç¾¤**ï¼šè¯­ä¹‰èšç±»ã€è¯é¢˜å‘½åã€å†…å®¹è§„åˆ’å»ºè®®
- âœ… **å…³é”®è¯æŒ–æ˜**ï¼šè¡Œä¸šçƒ­ç‚¹ã€ç«äº‰åº¦åˆ†æã€è¶‹åŠ¿é¢„æµ‹ã€ä»·å€¼çŸ©é˜µ
- âœ… **å¤šæ¨¡æ€æç¤º**ï¼šé…å›¾æè¿°ç”Ÿæˆã€è§†é¢‘è„šæœ¬ç”Ÿæˆ

**æ•°æ®é©±åŠ¨**ï¼š
- âœ… **ROI åˆ†æ**ï¼šæˆæœ¬æ¦‚è§ˆã€è¶‹åŠ¿åˆ†æã€åˆ†å¸ƒç»Ÿè®¡ã€ä¼˜åŒ–å»ºè®®
- âœ… **å†…å®¹æŒ‡æ ‡**ï¼šTrust Densityã€Citation Shareã€Authority Scoreã€Engagement Potential
- âœ… **è´Ÿé¢ç›‘æ§**ï¼šè´Ÿé¢æŸ¥è¯¢ç”Ÿæˆã€æƒ…æ„Ÿæ£€æµ‹ã€é£é™©ç­‰çº§ã€æ¾„æ¸…æ¨¡æ¿

**è‡ªåŠ¨åŒ–**ï¼š
- âœ… **å·¥ä½œæµè‡ªåŠ¨åŒ–**ï¼šè‡ªå®šä¹‰å·¥ä½œæµã€æ‰¹é‡å¤„ç†ã€æ‰§è¡Œå†å²
- âœ… **æŠ€æœ¯é…ç½®**ï¼šrobots.txtã€sitemap.xml è‡ªåŠ¨ç”Ÿæˆ

---

### ğŸ“Š é¢„æœŸæ•ˆæœ

- âœ… **å“ç‰ŒæåŠç‡æå‡**ï¼šåœ¨ AI å›ç­”ä¸­çš„å‡ºç°é¢‘ç‡æ˜¾è‘—å¢åŠ ï¼ˆå¤šæ¨¡å‹éªŒè¯ï¼‰
- âœ… **æœç´¢æ’åä¼˜åŒ–**ï¼šå†…å®¹è¢«å¤§æ¨¡å‹ä¼˜å…ˆå¼•ç”¨ï¼Œé—´æ¥æå‡ SEO
- âœ… **å“ç‰Œæƒå¨æ€§**ï¼šå¤šå¹³å°ã€å¤šè§’åº¦å†…å®¹å»ºç«‹ä¸“ä¸šå½¢è±¡ï¼ˆE-E-A-T å¼ºåŒ–ï¼‰
- âœ… **ç«å“ä¼˜åŠ¿**ï¼šé€šè¿‡æ•°æ®å¯¹æ¯”ï¼Œå‘ç°å¹¶å¼ºåŒ–å·®å¼‚åŒ–ä¼˜åŠ¿
- âœ… **ROI æœ€å¤§åŒ–**ï¼šæ•°æ®é©±åŠ¨çš„å…³é”®è¯ç­–ç•¥ï¼Œæˆæœ¬ä¼˜åŒ–å»ºè®®
- âœ… **å†…å®¹è´¨é‡ä¿è¯**ï¼šè‡ªåŠ¨è¯„åˆ†å’Œæ”¹è¿›å»ºè®®ï¼Œç¡®ä¿ç¬¦åˆ GEO æœ€ä½³å®è·µ
""")

def load_default_cfg():
    """
    ä»é¡¹ç›®æ ¹ç›®å½•çš„ config.json è¯»å–é»˜è®¤é…ç½®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨å†…ç½®é»˜è®¤å€¼ã€‚
    è¿™æ ·å¯ä»¥åœ¨é¡¹ç›®ä¸­ç»´æŠ¤å¯†é’¥å’Œå“ç‰Œé…ç½®ï¼Œè€Œä¸ä¾èµ–ç³»ç»Ÿç¯å¢ƒå˜é‡ã€‚
    """
    base_cfg = {
        "gen_provider": "DeepSeek",
        "gen_api_key": "",
        "verify_providers": ["DeepSeek"],
        "verify_keys": {
            "DeepSeek": ""
        },
        "brand": "æ±‡ä¿¡äº‘AIè½¯ä»¶",
        "advantages": "AIèµ‹èƒ½å¤–è´¸ERPã€æ‰“é€ å¤–è´¸æ™ºèƒ½æ–°å¼•æ“ã€AIé©±åŠ¨å‹ERPã€èµ‹èƒ½å¤–è´¸å…¨æµç¨‹ç®¡ç†ã€å…¨é“¾è·¯ä»·å€¼é—­ç¯",
        "competitors": "å—åŒ—è½¯ä»¶\nç¿è´è½¯ä»¶\nå­šç›Ÿè½¯ä»¶\nå°æ»¡è½¯ä»¶",
        "temperature": 0.7,
    }

    config_path = Path(__file__).with_name("config.json")
    if config_path.exists():
        try:
            with config_path.open("r", encoding="utf-8") as f:
                file_cfg = json.load(f)
            if isinstance(file_cfg, dict):
                base_cfg.update(file_cfg)
        except Exception:
            # é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯æ—¶å›é€€åˆ°å†…ç½®é»˜è®¤å€¼ï¼Œé¿å…æ•´ä¸ªåº”ç”¨å´©æºƒ
            pass
    return base_cfg


def save_cfg_to_file(cfg: dict) -> None:
    """
    å°†å½“å‰ç”Ÿæ•ˆçš„é…ç½®å†™å…¥æœ¬åœ° config.jsonï¼ˆå·²åœ¨ .gitignore ä¸­ï¼Œä¸ä¼šæäº¤åˆ°ä»“åº“ï¼‰ã€‚
    åªåŒæ­¥æˆ‘ä»¬è´Ÿè´£çš„å‡ ä¸ªé”®ï¼Œå…¶å®ƒè‡ªå®šä¹‰å­—æ®µä¿æŒä¸å˜ã€‚
    """
    config_path = Path(__file__).with_name("config.json")
    try:
        data = {}
        if config_path.exists():
            try:
                with config_path.open("r", encoding="utf-8") as f:
                    loaded = json.load(f)
                if isinstance(loaded, dict):
                    data.update(loaded)
            except Exception:
                # å¦‚æœåŸæ–‡ä»¶ä¸å¯è§£æï¼Œä¸¢å¼ƒæ—§å†…å®¹ï¼Œé‡æ–°å†™å…¥å—ç®¡é…ç½®
                data = {}
        for key in ["gen_provider", "gen_api_key", "verify_providers", "verify_keys", "tongyi_wanxiang_api_key", "brand", "advantages", "competitors", "temperature"]:
            if key in cfg:
                data[key] = cfg[key]
        with config_path.open("w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception:
        # æŒä¹…åŒ–å¤±è´¥ä¸åº”é˜»æ–­é¡µé¢ä½¿ç”¨ï¼Œåªåšæç¤º
        try:
            st.warning("âš ï¸ æ— æ³•å°†é…ç½®å†™å…¥æœ¬åœ° config.jsonï¼Œä½†å½“å‰ä¼šè¯å·²ç”Ÿæ•ˆã€‚è¯·æ£€æŸ¥æ–‡ä»¶æƒé™ã€‚")
        except Exception:
            # åœ¨é Streamlit ç¯å¢ƒä¸‹å¿½ç•¥ UI æç¤ºé”™è¯¯
            pass


ss_init("cfg", load_default_cfg())
ss_init("cfg_applied", False)
ss_init("cfg_valid", False)
ss_init("cfg_errors", [])

# æ¨¡å—1ï¼šå…³é”®è¯
ss_init("keywords", [])
ss_init("kw_last_num", 40)
ss_init("kw_generation_mode", "AIç”Ÿæˆ")  # ç”Ÿæˆæ¨¡å¼ï¼šAIç”Ÿæˆ / æ‰˜è¯å·¥å…· / æ··åˆæ¨¡å¼
ss_init("wordbanks", None)  # è¯åº“å­—å…¸
ss_init("keyword_tool", KeywordTool())  # æ‰˜è¯å·¥å…·å®ä¾‹

# æ¨¡å—2ï¼šå†…å®¹
ss_init("generated_contents", [])  # list[dict]
ss_init("zip_bytes", None)
ss_init("zip_filename", "")
ss_init("multimodal_descriptions", {})  # å¤šæ¨¡æ€æè¿°ï¼ˆé…å›¾æè¿°ã€è§†é¢‘è„šæœ¬ç­‰ï¼‰
ss_init("image_descriptions", [])  # å›¾ç‰‡æè¿°åˆ—è¡¨
ss_init("detail_tab_active", "ğŸ¨ å¢å¼ºå·¥å…·")  # ä¿å­˜å½“å‰æ¿€æ´»çš„è¯¦æƒ…Tab

# æ¨¡å—3ï¼šæ–‡ç« ä¼˜åŒ–
ss_init("optimized_article", "")
ss_init("opt_changes", "")
ss_init("opt_platform", "é€šç”¨ä¼˜åŒ–")

# æ¨¡å—4ï¼šéªŒè¯
ss_init("verify_combined", None)  # DataFrame or None
ss_init("verify_last_queries", "")

# ------------------- å·¥å…·å‡½æ•° -------------------
INVALID_FS_CHARS = r'<>:"/\\|?*\n\r\t'


def sanitize_filename(name: str, max_len: int = 80) -> str:
    if not name:
        return "untitled"
    name = name.strip()
    name = re.sub(rf"[{re.escape(INVALID_FS_CHARS)}]", "_", name)
    name = re.sub(r"_+", "_", name).strip("_")
    return name[:max_len] if len(name) > max_len else name


def safe_decode_uploaded(uploaded) -> str:
    if not uploaded:
        return ""
    b = uploaded.getvalue()
    for enc in ("utf-8-sig", "utf-8", "gb18030"):
        try:
            return b.decode(enc)
        except Exception:
            pass
    return b.decode("utf-8", errors="replace")


def extract_json_array(text: str):
    """ä»æ¨¡å‹è¾“å‡ºä¸­æŠ½å– JSON æ•°ç»„ï¼ˆJsonOutputParser å¤±è´¥æ—¶å…œåº•ï¼‰ã€‚"""
    if not text:
        return None
    m = re.search(r"\[[\s\S]*\]", text)
    if not m:
        return None
    try:
        return json.loads(m.group(0))
    except Exception:
        return None


def validate_cfg(cfg: dict):
    """ä¿ç•™ä½ åŸæœ¬çš„â€œå¿…é¡»å¡«å†™æ‰€æœ‰ API Keyâ€çº¦æŸï¼Œä½†ä¸ st.stopï¼šæ”¹ä¸ºç¦ç”¨æŒ‰é’® + æç¤ºã€‚"""
    errors = []
    if not cfg.get("gen_api_key", "").strip():
        errors.append("ç”Ÿæˆ&ä¼˜åŒ– LLM çš„ API Key æœªå¡«å†™")

    verify_providers = cfg.get("verify_providers", [])
    verify_keys = cfg.get("verify_keys", {})
    if not verify_providers:
        errors.append("è‡³å°‘é€‰æ‹©ä¸€ä¸ªéªŒè¯æ¨¡å‹")

    for vp in verify_providers:
        if not verify_keys.get(vp, "").strip():
            errors.append(f"éªŒè¯æ¨¡å‹ {vp} çš„ API Key æœªå¡«å†™")

    return (len(errors) == 0), errors


def model_defaults(provider: str) -> str:
    if provider == "DeepSeek":
        return "deepseek-chat"
    if provider == "OpenAI (GPT)":
        return "gpt-4o-mini"
    if provider == "Tongyi (é€šä¹‰åƒé—®)":
        return "qwen-max"
    if provider == "Groq":
        return "llama3-70b-8192"
    if provider == "Moonshot (Kimi)":
        return "moonshot-v1-128k"
    if provider == "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰":
        return ""  # è±†åŒ…ä½¿ç”¨ ENDPOINT_IDï¼Œä¸éœ€è¦æ¨¡å‹å
    if provider == "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰":
        return "ernie-bot-turbo"
    return ""


# ------------------- ç¼“å­˜ LLM å®¢æˆ·ç«¯ï¼ˆæ˜¾è‘—é™ä½â€œé¢‘ç¹ Loadingâ€ï¼‰ -------------------
@st.cache_resource(show_spinner=False)
def build_llm(provider: str, api_key: str, model: str, temperature: float):
    """
    - ä½¿ç”¨ cache_resource ç¼“å­˜å®¢æˆ·ç«¯ï¼Œé¿å…æ¯æ¬¡ rerun é‡å»º
    - Tongyi / Moonshotï¼šä¿ç•™ä½ åŸåŠŸèƒ½è·¯å¾„ï¼ŒåŒæ—¶æä¾›æ›´ç¨³çš„ import å…œåº•
    """
    if provider == "DeepSeek":
        from langchain_deepseek import ChatDeepSeek

        return ChatDeepSeek(api_key=api_key, model=model, temperature=temperature)

    if provider == "OpenAI (GPT)":
        from langchain_openai import ChatOpenAI

        return ChatOpenAI(api_key=api_key, model=model, temperature=temperature)

    if provider == "Tongyi (é€šä¹‰åƒé—®)":
        try:
            from langchain_community.chat_models import ChatTongyi

            return ChatTongyi(api_key=api_key, model=model, model_kwargs={"temperature": temperature})
        except Exception:
            from langchain_aliyun import ChatTongyi  # type: ignore

            return ChatTongyi(api_key=api_key, model=model, temperature=temperature)

    if provider == "Groq":
        from langchain_groq import ChatGroq

        return ChatGroq(api_key=api_key, model=model, temperature=temperature)

    if provider == "Moonshot (Kimi)":
        try:
            from langchain_moonshot import ChatMoonshot  # type: ignore

            return ChatMoonshot(api_key=api_key, model=model, temperature=temperature)
        except Exception:
            from langchain_community.chat_models import MoonshotChat  # type: ignore

            return MoonshotChat(api_key=api_key, model=model, temperature=temperature)

    if provider == "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰":
        try:
            # å°è¯•ä½¿ç”¨ volcengine-python-sdk[ark]
            from volcengine.ark import Ark
            from langchain_core.language_models.chat_models import BaseChatModel
            from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
            from langchain_core.outputs import ChatGeneration, ChatResult
            from typing import List, Optional, Any
            
            class ChatDoubao(BaseChatModel):
                """è±†åŒ…èŠå¤©æ¨¡å‹å°è£…ï¼ˆLangChain å…¼å®¹ï¼‰"""
                volc_ak: str
                volc_sk: str
                endpoint_id: str
                temperature: float = 0.7
                
                def __init__(self, volc_ak: str, volc_sk: str, endpoint_id: str, temperature: float = 0.7):
                    super().__init__(temperature=temperature)
                    self.volc_ak = volc_ak
                    self.volc_sk = volc_sk
                    self.endpoint_id = endpoint_id
                    self.temperature = temperature
                    self.client = Ark(ak=volc_ak, sk=volc_sk)
                
                def _generate(self, messages: List[BaseMessage], stop: Optional[List[str]] = None, run_manager: Optional[Any] = None, **kwargs: Any) -> ChatResult:
                    # è½¬æ¢æ¶ˆæ¯æ ¼å¼
                    volc_messages = []
                    for msg in messages:
                        if isinstance(msg, SystemMessage):
                            volc_messages.append({"role": "system", "content": msg.content})
                        elif isinstance(msg, HumanMessage):
                            volc_messages.append({"role": "user", "content": msg.content})
                        elif isinstance(msg, AIMessage):
                            volc_messages.append({"role": "assistant", "content": msg.content})
                        else:
                            volc_messages.append({"role": "user", "content": str(msg.content)})
                    
                    response = self.client.chat.completions.create(
                        model=self.endpoint_id,
                        messages=volc_messages,
                        temperature=self.temperature,
                    )
                    
                    ai_message = AIMessage(content=response.choices[0].message.content)
                    return ChatResult(generations=[ChatGeneration(message=ai_message)])
                
                @property
                def _llm_type(self) -> str:
                    return "doubao"
            
            # è±†åŒ…çš„ api_key æ ¼å¼ï¼šaccess_key:secret_key:endpoint_id
            parts = api_key.split(":")
            if len(parts) >= 3:
                return ChatDoubao(volc_ak=parts[0], volc_sk=parts[1], endpoint_id=parts[2], temperature=temperature)
            else:
                raise ValueError("è±†åŒ… API Key æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºï¼šaccess_key:secret_key:endpoint_idï¼ˆç”¨å†’å·åˆ†éš”ï¼‰")
        except ImportError:
            # å°è¯•å…¶ä»–å¯¼å…¥æ–¹å¼
            try:
                from volcenginesdkarkruntime import Ark
                # ä½¿ç”¨ç›¸åŒçš„ ChatDoubao ç±»
                from langchain_core.language_models.chat_models import BaseChatModel
                from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
                from langchain_core.outputs import ChatGeneration, ChatResult
                from typing import List, Optional, Any
                
                class ChatDoubao(BaseChatModel):
                    """è±†åŒ…èŠå¤©æ¨¡å‹å°è£…ï¼ˆLangChain å…¼å®¹ï¼‰"""
                    volc_ak: str
                    volc_sk: str
                    endpoint_id: str
                    temperature: float = 0.7
                    
                    def __init__(self, volc_ak: str, volc_sk: str, endpoint_id: str, temperature: float = 0.7):
                        super().__init__(temperature=temperature)
                        self.volc_ak = volc_ak
                        self.volc_sk = volc_sk
                        self.endpoint_id = endpoint_id
                        self.temperature = temperature
                        self.client = Ark(ak=volc_ak, sk=volc_sk)
                    
                    def _generate(self, messages: List[BaseMessage], stop: Optional[List[str]] = None, run_manager: Optional[Any] = None, **kwargs: Any) -> ChatResult:
                        volc_messages = []
                        for msg in messages:
                            if isinstance(msg, SystemMessage):
                                volc_messages.append({"role": "system", "content": msg.content})
                            elif isinstance(msg, HumanMessage):
                                volc_messages.append({"role": "user", "content": msg.content})
                            elif isinstance(msg, AIMessage):
                                volc_messages.append({"role": "assistant", "content": msg.content})
                            else:
                                volc_messages.append({"role": "user", "content": str(msg.content)})
                        
                        response = self.client.chat.completions.create(
                            model=self.endpoint_id,
                            messages=volc_messages,
                            temperature=self.temperature,
                        )
                        
                        ai_message = AIMessage(content=response.choices[0].message.content)
                        return ChatResult(generations=[ChatGeneration(message=ai_message)])
                    
                    @property
                    def _llm_type(self) -> str:
                        return "doubao"
                
                parts = api_key.split(":")
                if len(parts) >= 3:
                    return ChatDoubao(volc_ak=parts[0], volc_sk=parts[1], endpoint_id=parts[2], temperature=temperature)
                else:
                    raise ValueError("è±†åŒ… API Key æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºï¼šaccess_key:secret_key:endpoint_idï¼ˆç”¨å†’å·åˆ†éš”ï¼‰")
            except ImportError as e:
                raise ValueError(f"è±†åŒ…åˆå§‹åŒ–å¤±è´¥ï¼šç¼ºå°‘ä¾èµ–åº“ã€‚è¯·è¿è¡Œï¼špip install 'volcengine-python-sdk[ark]'ã€‚é”™è¯¯ï¼š{e}")
        except Exception as e:
            raise ValueError(f"è±†åŒ…åˆå§‹åŒ–å¤±è´¥ï¼š{e}ã€‚è¯·ç¡®ä¿ API Key æ ¼å¼ä¸ºï¼šaccess_key:secret_key:endpoint_id")

    if provider == "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰":
        # æ–‡å¿ƒä¸€è¨€çš„ api_key æ ¼å¼ï¼šapp_key:app_secret
        parts = api_key.split(":")
        if len(parts) != 2:
            raise ValueError("æ–‡å¿ƒä¸€è¨€ API Key æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºï¼šapp_key:app_secretï¼ˆç”¨å†’å·åˆ†éš”ï¼‰")
        
        app_key, app_secret = parts
        
        # ä¼˜å…ˆä½¿ç”¨ langchain-community çš„åƒå¸†æ¥å£ï¼ˆå·²åŒ…å«åœ¨ä¾èµ–ä¸­ï¼‰
        try:
            from langchain_community.chat_models import QianfanChatEndpoint
            import os
            
            os.environ["QIANFAN_AK"] = app_key
            os.environ["QIANFAN_SK"] = app_secret
            return QianfanChatEndpoint(
                model=model if model else "ernie-bot-turbo",
                temperature=temperature,
            )
        except ImportError:
            # å¤‡é€‰æ–¹æ¡ˆï¼šå°è¯• langchain-wenxin
            try:
                from langchain_wenxin import ChatWenxin
                return ChatWenxin(
                    baidu_api_key=app_key,
                    baidu_secret_key=app_secret,
                    model=model if model else "ernie-bot-turbo",
                    temperature=temperature,
                )
            except ImportError as e:
                raise ValueError(f"æ–‡å¿ƒä¸€è¨€åˆå§‹åŒ–å¤±è´¥ï¼šç¼ºå°‘ä¾èµ–åº“ã€‚è¯·è¿è¡Œï¼špip install qianfanï¼ˆæˆ–ä½¿ç”¨å·²å®‰è£…çš„ langchain-communityï¼‰ã€‚é”™è¯¯ï¼š{e}")
        except Exception as e:
            raise ValueError(f"æ–‡å¿ƒä¸€è¨€åˆå§‹åŒ–å¤±è´¥ï¼š{e}")

    raise ValueError(f"Unknown provider: {provider}")


# ------------------- ä¾§è¾¹æ ï¼šå…¨å±€é…ç½®ï¼ˆç”¨ form é™ä½ rerunï¼‰ -------------------
with st.sidebar:
    st.header("âš™ï¸ å…¨å±€é…ç½®")
    
    with st.form("global_config_form", clear_on_submit=False):
            gen_provider = st.selectbox(
            "ç”Ÿæˆ&ä¼˜åŒ– LLM",
            ["DeepSeek", "OpenAI (GPT)", "Tongyi (é€šä¹‰åƒé—®)", "Groq", "Moonshot (Kimi)", "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰", "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰"],
            index=["DeepSeek", "OpenAI (GPT)", "Tongyi (é€šä¹‰åƒé—®)", "Groq", "Moonshot (Kimi)", "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰", "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰"].index(
                st.session_state.cfg["gen_provider"]
            ) if st.session_state.cfg["gen_provider"] in ["DeepSeek", "OpenAI (GPT)", "Tongyi (é€šä¹‰åƒé—®)", "Groq", "Moonshot (Kimi)", "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰", "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰"] else 0,
            key="sb_gen_provider",
            )
            # API Key è¾“å…¥æç¤º
            if gen_provider == "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰":
                api_key_help = "æ ¼å¼ï¼šaccess_key:secret_key:endpoint_idï¼ˆç”¨å†’å·åˆ†éš”ï¼‰"
            elif gen_provider == "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰":
                api_key_help = "æ ¼å¼ï¼šapp_key:app_secretï¼ˆç”¨å†’å·åˆ†éš”ï¼‰"
            else:
                api_key_help = ""
            
            gen_api_key = st.text_input(
                f"{gen_provider} API Keyï¼ˆç”Ÿæˆ&ä¼˜åŒ–ç”¨ï¼‰",
                type="password",
                value=st.session_state.cfg.get("gen_api_key", ""),
                key="sb_gen_api_key",
                help=api_key_help if api_key_help else None,
            )

            st.markdown("### éªŒè¯ç”¨LLMï¼ˆå¤šé€‰ï¼‰")
            verify_providers = st.multiselect(
                "é€‰æ‹©éªŒè¯æ¨¡å‹",
                ["DeepSeek", "OpenAI (GPT)", "Tongyi (é€šä¹‰åƒé—®)", "Groq", "Moonshot (Kimi)", "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰", "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰"],
                default=st.session_state.cfg.get("verify_providers", []),
                key="sb_verify_providers",
            )

            verify_keys = {}
            old_keys = st.session_state.cfg.get("verify_keys", {})
            for vp in verify_providers:
                # API Key è¾“å…¥æç¤º
                if vp == "è±†åŒ…ï¼ˆå­—èŠ‚è·³åŠ¨ï¼‰":
                    api_key_help = "æ ¼å¼ï¼šaccess_key:secret_key:endpoint_idï¼ˆç”¨å†’å·åˆ†éš”ï¼‰"
                elif vp == "æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰":
                    api_key_help = "æ ¼å¼ï¼šapp_key:app_secretï¼ˆç”¨å†’å·åˆ†éš”ï¼‰"
                else:
                    api_key_help = None
                
                verify_keys[vp] = st.text_input(
                    f"{vp} API Keyï¼ˆéªŒè¯ç”¨ï¼‰",
                    type="password",
                    value=old_keys.get(vp, ""),
                    key=f"sb_verify_key_{vp}",
                    help=api_key_help if api_key_help else None,
                )

            st.markdown("---")
            # æ£€æŸ¥æ˜¯å¦æœ‰å¾…åº”ç”¨çš„ç‰ˆæœ¬æ›´æ–°
            if "_pending_brand_update" in st.session_state:
                brand_value = st.session_state.pop("_pending_brand_update")
                # ä½¿ç”¨ä¸€ä¸ªé€’å¢çš„è®¡æ•°å™¨æ¥å¼ºåˆ¶æ›´æ–°widgetï¼ˆé€šè¿‡æ”¹å˜keyï¼‰
                widget_counter = st.session_state.get("_widget_update_counter", 0) + 1
                st.session_state["_widget_update_counter"] = widget_counter
                # ä½¿ç”¨å¸¦è®¡æ•°å™¨çš„keyæ¥åˆ›å»ºæ–°çš„widgetå®ä¾‹
                brand_key = f"sb_brand_{widget_counter}"
                brand = st.text_input("ä¸»å“ç‰Œåç§°", value=brand_value, key=brand_key)
                # åŒæ­¥åˆ°ä¸»keyï¼Œä»¥ä¾¿åç»­ä½¿ç”¨
                st.session_state["sb_brand"] = brand
            else:
                brand = st.text_input("ä¸»å“ç‰Œåç§°", value=st.session_state.cfg.get("brand", "æ±‡ä¿¡äº‘AIè½¯ä»¶"), key="sb_brand")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¾…åº”ç”¨çš„ä¼˜åŠ¿æ›´æ–°
            if "_pending_advantages_update" in st.session_state:
                advantages_value = st.session_state.pop("_pending_advantages_update")
                # ä½¿ç”¨ä¸€ä¸ªé€’å¢çš„è®¡æ•°å™¨æ¥å¼ºåˆ¶æ›´æ–°widgetï¼ˆé€šè¿‡æ”¹å˜keyï¼‰
                widget_counter = st.session_state.get("_widget_update_counter", 0)
                # ä½¿ç”¨å¸¦è®¡æ•°å™¨çš„keyæ¥åˆ›å»ºæ–°çš„widgetå®ä¾‹
                advantages_key = f"sb_advantages_{widget_counter}"
                advantages = st.text_area(
                    "æ ¸å¿ƒä¼˜åŠ¿/å–ç‚¹ï¼ˆAIä¸“å±ï¼‰",
                    value=advantages_value,
                    height=140,
                    key=advantages_key,
                )
                # åŒæ­¥åˆ°ä¸»keyï¼Œä»¥ä¾¿åç»­ä½¿ç”¨
                st.session_state["sb_advantages"] = advantages
            else:
                advantages = st.text_area(
                    "æ ¸å¿ƒä¼˜åŠ¿/å–ç‚¹ï¼ˆAIä¸“å±ï¼‰",
                    value=st.session_state.cfg.get(
                        "advantages", "AIèµ‹èƒ½å¤–è´¸ERPã€æ‰“é€ å¤–è´¸æ™ºèƒ½æ–°å¼•æ“ã€AIé©±åŠ¨å‹ERPã€èµ‹èƒ½å¤–è´¸å…¨æµç¨‹ç®¡ç†ã€å…¨é“¾è·¯ä»·å€¼é—­ç¯"
                    ),
                    height=140,
                    key="sb_advantages",
                )
            competitors = st.text_area(
                "ç«å“å“ç‰Œï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œç”¨äºå¯¹æ¯”éªŒè¯ï¼‰",
                value=st.session_state.cfg.get("competitors", "å—åŒ—è½¯ä»¶\nç¿è´è½¯ä»¶\nå­šç›Ÿè½¯ä»¶\nå°æ»¡è½¯ä»¶"),
                height=120,
                key="sb_competitors",
            )

            st.markdown("---")
            st.markdown("### ğŸ–¼ï¸ é€šä¹‰ä¸‡ç›¸ï¼ˆå›¾ç‰‡ç”Ÿæˆï¼‰")
            tongyi_wanxiang_api_key = st.text_input(
                "é€šä¹‰ä¸‡ç›¸ API Keyï¼ˆå¯é€‰ï¼Œç”¨äºå›¾ç‰‡ç”Ÿæˆï¼‰",
                type="password",
                value=st.session_state.cfg.get("tongyi_wanxiang_api_key", ""),
                key="sb_tongyi_wanxiang_api_key",
                help="é˜¿é‡Œäº‘ DashScope API Keyï¼Œç”¨äºç”Ÿæˆæ–‡ç« é…å›¾ã€‚å…è´¹é¢åº¦æ¯å¤© 100-300 å¼ ã€‚",
            )
            
            st.markdown("---")
            temperature = st.slider(
                "ç”Ÿæˆæ¸©åº¦ï¼ˆæ›´ç¨³â†’æ›´ä½ï¼‰",
                0.0,
                1.0,
                float(st.session_state.cfg.get("temperature", 0.7)),
                0.05,
                key="sb_temperature",
            )

            apply_cfg = st.form_submit_button("åº”ç”¨é…ç½®ï¼ˆæ¨èï¼‰", use_container_width=True)

    if apply_cfg or not st.session_state.cfg_applied:
        # ä¼˜å…ˆä»ä¸» key è¯»å–å€¼ï¼ˆå¦‚æœä½¿ç”¨äº†ä¸´æ—¶ key æ›´æ–°ï¼Œå€¼å·²åŒæ­¥åˆ°ä¸» keyï¼‰
        brand_value = st.session_state.get("sb_brand", brand)
        advantages_value = st.session_state.get("sb_advantages", advantages)

        st.session_state.cfg = {
            "gen_provider": gen_provider,
            "gen_api_key": gen_api_key,
            "verify_providers": verify_providers,
            "verify_keys": verify_keys,
            "tongyi_wanxiang_api_key": tongyi_wanxiang_api_key,
            "brand": brand_value,
            "advantages": advantages_value,
            "competitors": competitors,
            "temperature": temperature,
        }

        ok, errs = validate_cfg(st.session_state.cfg)
        st.session_state.cfg_valid = ok
        st.session_state.cfg_errors = errs

        if ok:
            # ä»…åœ¨é…ç½®åˆæ³•æ—¶æ‰å†™å…¥æœ¬åœ°é…ç½®æ–‡ä»¶ï¼Œå¹¶æ ‡è®°ä¸ºå·²åº”ç”¨
            save_cfg_to_file(st.session_state.cfg)
            st.session_state.cfg_applied = True
        else:
            st.session_state.cfg_applied = False

    if not st.session_state.cfg_valid:
        st.warning("é…ç½®æœªæ»¡è¶³è¿è¡Œæ¡ä»¶ï¼š\n- " + "\n- ".join(st.session_state.cfg_errors))
    else:
        st.success("é…ç½®å·²å°±ç»ªï¼Œå¯è¿è¡Œå…¨éƒ¨æ¨¡å—ã€‚")

    st.markdown("---")
    if st.button("é‡ç½®å…¨éƒ¨ç»“æœï¼ˆä¸åˆ é™¤é…ç½®ï¼‰", use_container_width=True, key="sb_reset_all"):
        st.session_state.keywords = []
        st.session_state.generated_contents = []
        st.session_state.zip_bytes = None
        st.session_state.zip_filename = ""
        st.session_state.optimized_article = ""
        st.session_state.opt_changes = ""
        st.session_state.verify_combined = None
        st.session_state.config_optimization_result = None
        st.session_state.config_hash = None
        st.toast("å·²é‡ç½®å…¨éƒ¨ç»“æœã€‚")

    st.caption("é—­ç¯ï¼šå…³é”®è¯ â†’ åˆ›ä½œ â†’ ä¼˜åŒ– â†’ éªŒè¯")

cfg = st.session_state.cfg
brand = cfg["brand"]
advantages = cfg["advantages"]
temperature = float(cfg.get("temperature", 0.7))

competitor_list = [c.strip() for c in cfg["competitors"].split("\n") if c.strip()]
_seen = set()
clean_competitors = []
for c in competitor_list:
    cl = c.lower()
    if cl == brand.lower():
        continue
    if cl in _seen:
        continue
    _seen.add(cl)
    clean_competitors.append(c)
competitor_list = clean_competitors

# ------------------- åˆå§‹åŒ– LLMï¼ˆä»…åœ¨ cfg_valid æ—¶ï¼›ä¸” build_llm å·²ç¼“å­˜ï¼‰ -------------------
gen_llm = None
verify_llms = {}

if st.session_state.cfg_valid:
    try:
        gen_llm = build_llm(cfg["gen_provider"], cfg["gen_api_key"], model_defaults(cfg["gen_provider"]), temperature)
    except Exception as e:
        st.error(f"ç”ŸæˆLLMåŠ è½½å¤±è´¥ï¼š{e}")

    for vp in cfg["verify_providers"]:
        key = cfg["verify_keys"].get(vp, "").strip()
        if not key:
            continue
        try:
            verify_llms[vp] = build_llm(vp, key, model_defaults(vp), temperature)
        except Exception as e:
            st.error(f"{vp}éªŒè¯LLMåŠ è½½å¤±è´¥ï¼š{e}")

# ------------------- KPI æ€»è§ˆï¼ˆæç®€ä½†æ›´åƒäº§å“ï¼‰ -------------------
k1, k2, k3, k4 = st.columns(4)
try:
    k1.metric("å…³é”®è¯", len(st.session_state.keywords), border=True)
    k2.metric("å†…å®¹åŒ…", len(st.session_state.generated_contents), border=True)
    k3.metric("æ–‡ç« ä¼˜åŒ–", "å·²ç”Ÿæˆ" if bool(st.session_state.optimized_article) else "æœªç”Ÿæˆ", border=True)
    k4.metric("éªŒè¯ç»“æœ", "å·²ç”Ÿæˆ" if st.session_state.verify_combined is not None else "æœªç”Ÿæˆ", border=True)
except TypeError:
    k1.metric("å…³é”®è¯", len(st.session_state.keywords))
    k2.metric("å†…å®¹åŒ…", len(st.session_state.generated_contents))
    k3.metric("æ–‡ç« ä¼˜åŒ–", "å·²ç”Ÿæˆ" if bool(st.session_state.optimized_article) else "æœªç”Ÿæˆ")
    k4.metric("éªŒè¯ç»“æœ", "å·²ç”Ÿæˆ" if st.session_state.verify_combined is not None else "æœªç”Ÿæˆ")

st.markdown("---")

# ------------------- ä¸»å¯¼èˆªï¼šTabsï¼ˆæµç¨‹æ›´æ¸…æ™°ï¼‰ -------------------
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9, tab10 = st.tabs([
    "ğŸ¯ å…³é”®è¯è’¸é¦", 
    "âœï¸ è‡ªåŠ¨åˆ›ä½œ", 
    "ğŸ”§ æ–‡ç« ä¼˜åŒ–",
    "âœ… å¤šæ¨¡å‹éªŒè¯",
    "ğŸ“š å†å²è®°å½•",
    "ğŸ“Š AI æ•°æ®æŠ¥è¡¨",
    "âš™ï¸ å·¥ä½œæµè‡ªåŠ¨åŒ–",
    "ğŸ“¦ GEO èµ„æºåº“",
    "ğŸ”„ å¹³å°åŒæ­¥",
    "ğŸ› ï¸ é…ç½®ä¼˜åŒ–åŠ©æ‰‹"
])

# =======================
# Tab1ï¼šå…³é”®è¯è’¸é¦
# =======================
with tab1:
    tab_keywords.render_tab_keywords(
        storage,
        ss_init,
        gen_llm,
        brand,
        advantages
    )


# =======================
# Tab2ï¼šè‡ªåŠ¨åˆ›ä½œå†…å®¹ï¼ˆå«æ‰¹é‡ ZIP / GitHub æ¨¡æ¿ï¼‰
# =======================
with tab2:
    tab_autowrite.render_tab_autowrite(
        storage,
        ss_init,
        gen_llm,
        brand,
        advantages,
        cfg,
        record_api_cost,
        model_defaults
    )


# =======================
# Tab3ï¼šæ–‡ç« ä¼˜åŒ–
# =======================
with tab3:
    header_col1, header_col2 = st.columns([4, 1])
    with header_col1:
        st.markdown("**ğŸ”§ æ–‡ç« ä¼˜åŒ–**")
        st.caption("ä¼˜åŒ–å·²æœ‰æ–‡ç« ï¼Œç”Ÿæˆç»“æ„åŒ–æ•°æ®å’ŒæŠ€æœ¯é…ç½®ï¼Œæå‡ GEO æ•ˆæœ")
    with header_col2:
        st.markdown("")  # ç©ºè¡Œç”¨äºä¸å·¦ä¾§æ ‡é¢˜å¯¹é½
        if st.button("æ¸…ç©ºæœ¬æ¨¡å—ç»“æœ", use_container_width=True, key="opt_clear"):
            st.session_state.optimized_article = ""
            st.session_state.opt_changes = ""
            st.toast("ä¼˜åŒ–ç»“æœå·²æ¸…ç©ºã€‚")

    # === æ–‡ç« ä¼˜åŒ–åŠŸèƒ½ï¼ˆä¸»æµç¨‹ï¼‰ ===
    st.markdown("---")
    st.markdown("**âœï¸ æ–‡ç« å†…å®¹ä¼˜åŒ–**")

    with st.container(border=True):
        st.markdown("ç²˜è´´æˆ–ä¸Šä¼ å·²å†™æ–‡ç« ï¼Œä¸€é”®æå‡ GEO æ•ˆæœï¼ˆç»“æ„åŒ–ã€å¯å¼•ç”¨ã€è‡ªç„¶æ¤å…¥å“ç‰Œï¼‰")

        with st.form("opt_form", clear_on_submit=False):
            input_mode = st.radio(
                "è¾“å…¥æ–¹å¼",
                ["ç²˜è´´æ–‡æœ¬", "ä¸Šä¼ æ–‡ä»¶ï¼ˆTXT/MDï¼‰"],
                horizontal=True,
                key="opt_input_mode",
            )

            if input_mode == "ç²˜è´´æ–‡æœ¬":
                original_article = st.text_area(
                    "ç²˜è´´æ–‡ç« å†…å®¹", height=360, key="opt_text"
                )
            else:
                uploaded = st.file_uploader(
                    "ä¸Šä¼  TXT æˆ– MD æ–‡ä»¶",
                    type=["txt", "md"],
                    key="opt_uploader",
                )
                original_article = ""
                if uploaded:
                    try:
                        original_article = safe_decode_uploaded(uploaded) or ""
                    except Exception as e:
                        st.error(f"ä¸Šä¼ æ–‡ä»¶è§£æå¤±è´¥ï¼š{e}")
                        original_article = ""

                    if original_article:
                        st.text_area(
                            "ä¸Šä¼ å†…å®¹é¢„è§ˆ",
                            original_article,
                            height=200,
                            disabled=True,
                            key="opt_upload_preview",
                        )

            target_platform = st.selectbox(
                "ç›®æ ‡å¹³å°ï¼ˆå½±å“æ–‡é£ï¼Œå¯é€‰ï¼‰",
                [
                    "é€šç”¨ä¼˜åŒ–",
                    "çŸ¥ä¹ï¼ˆä¸“ä¸šé—®ç­”ï¼‰",
                    "CSDNï¼ˆæŠ€æœ¯åšå®¢ï¼‰",
                    "GitHubï¼ˆREADME/æ–‡æ¡£ï¼‰",
                    "Bç«™ï¼ˆè§†é¢‘è„šæœ¬ï¼‰",
                    "å¤´æ¡å·ï¼ˆèµ„è®¯è½¯æ–‡ï¼‰",
                    "å¾®ä¿¡å…¬ä¼—å·ï¼ˆé•¿æ–‡ï¼‰",
                    "æŠ–éŸ³å›¾æ–‡ï¼ˆçŸ­å†…å®¹ï¼‰",
                    "ç™¾å®¶å·ï¼ˆèµ„è®¯ï¼‰",
                    "ç½‘æ˜“å·ï¼ˆèµ„è®¯ï¼‰",
                    "ä¼é¹…å·ï¼ˆèµ„è®¯ï¼‰",
                    "ç®€ä¹¦ï¼ˆæ–‡è‰ºï¼‰",
                ],
                index=[
                    "é€šç”¨ä¼˜åŒ–",
                    "çŸ¥ä¹ï¼ˆä¸“ä¸šé—®ç­”ï¼‰",
                    "CSDNï¼ˆæŠ€æœ¯åšå®¢ï¼‰",
                    "GitHubï¼ˆREADME/æ–‡æ¡£ï¼‰",
                    "Bç«™ï¼ˆè§†é¢‘è„šæœ¬ï¼‰",
                    "å¤´æ¡å·ï¼ˆèµ„è®¯è½¯æ–‡ï¼‰",
                    "å¾®ä¿¡å…¬ä¼—å·ï¼ˆé•¿æ–‡ï¼‰",
                    "æŠ–éŸ³å›¾æ–‡ï¼ˆçŸ­å†…å®¹ï¼‰",
                    "ç™¾å®¶å·ï¼ˆèµ„è®¯ï¼‰",
                    "ç½‘æ˜“å·ï¼ˆèµ„è®¯ï¼‰",
                    "ä¼é¹…å·ï¼ˆèµ„è®¯ï¼‰",
                    "ç®€ä¹¦ï¼ˆæ–‡è‰ºï¼‰",
                ].index(
                    st.session_state.opt_platform
                    if st.session_state.opt_platform
                    in [
                        "é€šç”¨ä¼˜åŒ–",
                        "çŸ¥ä¹ï¼ˆä¸“ä¸šé—®ç­”ï¼‰",
                        "CSDNï¼ˆæŠ€æœ¯åšå®¢ï¼‰",
                        "GitHubï¼ˆREADME/æ–‡æ¡£ï¼‰",
                        "Bç«™ï¼ˆè§†é¢‘è„šæœ¬ï¼‰",
                        "å¤´æ¡å·ï¼ˆèµ„è®¯è½¯æ–‡ï¼‰",
                        "å¾®ä¿¡å…¬ä¼—å·ï¼ˆé•¿æ–‡ï¼‰",
                        "æŠ–éŸ³å›¾æ–‡ï¼ˆçŸ­å†…å®¹ï¼‰",
                        "ç™¾å®¶å·ï¼ˆèµ„è®¯ï¼‰",
                        "ç½‘æ˜“å·ï¼ˆèµ„è®¯ï¼‰",
                        "ä¼é¹…å·ï¼ˆèµ„è®¯ï¼‰",
                        "ç®€ä¹¦ï¼ˆæ–‡è‰ºï¼‰",
                    ]
                    else 0
                ),
                key="opt_platform_sel",
            )

            # é«˜çº§ä¼˜åŒ–æŠ€å·§é€‰æ‹©å™¨ï¼ˆå¯é€‰ï¼‰
            with st.expander("ğŸ¨ é«˜çº§ä¼˜åŒ–æŠ€å·§ï¼ˆå¯é€‰ï¼‰", expanded=False):
                opt_technique_manager = OptimizationTechniqueManager()
                opt_all_techniques = opt_technique_manager.list_techniques()
                opt_technique_options = [
                    f"{tech['icon']} {tech['name']}" for tech in opt_all_techniques
                ]

                opt_selected_technique_names = st.multiselect(
                    "é€‰æ‹©è¦åº”ç”¨çš„ä¼˜åŒ–æŠ€å·§ï¼ˆå¯å¤šé€‰ï¼‰",
                    options=opt_technique_options,
                    default=[],
                    key="opt_techniques",
                    help="å¯é€‰ï¼Œæé«˜ GEO æ•ˆæœã€‚æŠ€å·§ä¼šåŠ¨æ€è°ƒæ•´æ–‡ç« ä¼˜åŒ–ç­–ç•¥ã€‚",
                )

                # æ˜¾ç¤ºé€‰æ‹©çš„æŠ€å·§æè¿°
                if opt_selected_technique_names:
                    st.caption("å·²é€‰æ‹©ï¼š" + "ã€".join(opt_selected_technique_names))
                    with st.expander("æŸ¥çœ‹æŠ€å·§è¯´æ˜", expanded=False):
                        for tech_name in opt_selected_technique_names:
                            tech_icon_name = (
                                tech_name.split(" ", 1)[1]
                                if " " in tech_name
                                else tech_name
                            )
                            for tech in opt_all_techniques:
                                if tech["name"] == tech_icon_name:
                                    st.markdown(f"**{tech['icon']} {tech['name']}**")
                                    st.caption(tech["description"])
                                    break

            run_opt_disabled = (
                (not st.session_state.cfg_valid)
                or (gen_llm is None)
                or (not original_article.strip())
            )
            run_opt = st.form_submit_button(
                "å¼€å§‹ä¼˜åŒ–", use_container_width=True, disabled=run_opt_disabled
            )

            if run_opt_disabled:
                if not original_article.strip():
                    st.caption("è¯·å…ˆåœ¨ä¸Šæ–¹ç²˜è´´æ–‡ç« å†…å®¹ï¼Œæˆ–ä¸Šä¼  TXT/MD æ–‡ä»¶ã€‚")
                elif not st.session_state.cfg_valid or gen_llm is None:
                    st.caption("å½“å‰æœªæ£€æµ‹åˆ°å¯ç”¨çš„ç”Ÿæˆæ¨¡å‹ï¼Œè¯·å…ˆåœ¨ã€å…¨å±€è®¾ç½®ã€‘ä¸­å®Œæˆæ¨¡å‹/API é…ç½®ã€‚")

        if run_opt:
            st.session_state.opt_platform = target_platform

            optimize_prompt_template = """
ä½ æ˜¯GEOä¼˜åŒ–ä¸“å®¶ï¼Œç›®æ ‡æ˜¯æå‡æ–‡ç« åœ¨å¤§æ¨¡å‹ä¸­çš„å¼•ç”¨ç‡å’Œå“ç‰Œè‡ªç„¶æåŠã€‚

ã€åŸæ–‡ç« ã€‘
{original_article}

ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€ç›®æ ‡å¹³å°ã€‘{platform}

ã€ä¼˜åŒ–è¦æ±‚ï¼ˆä¸¥æ ¼GEOåŸåˆ™ï¼‰ã€‘
1) ä¿ç•™åŸæ„å’Œæ ¸å¿ƒä¿¡æ¯ï¼Œä¸æ”¹å˜äº‹å®
2) å¢å¼ºç»“æ„åŒ–ï¼šæ ‡é¢˜ã€æ¸…å•ã€FAQã€ä»£ç å—ï¼ˆé€‚ç”¨æ—¶ï¼‰
3) è‡ªç„¶æ¤å…¥å“ç‰Œ2-4æ¬¡ï¼ˆå…ˆé€šç”¨æ ‡å‡†ï¼Œå†å“ç‰Œé€‚ç”¨ï¼‰
4) æå‡æƒå¨æ„Ÿï¼šè¯„ä¼°ç»´åº¦ã€åŒ¿åæ¡ˆä¾‹ã€æ¥æºå ä½å»ºè®®ï¼ˆä¸å¾—ç¼–é€ ï¼‰
5) ç»“è®ºå…ˆè¡Œã€ä¿¡æ¯å¯†åº¦é«˜
6) é•¿åº¦æ§åˆ¶åœ¨åŸé•¿åº¦çš„1.0-1.3å€
7) è¾“å‡ºä¸¤éƒ¨åˆ†ï¼šã€ä¼˜åŒ–åæ–‡ç« ã€‘ + ã€å˜æ›´è¯´æ˜ã€‘ï¼ˆåˆ—å‡ºä¸»è¦æ”¹åŠ¨ç‚¹ï¼‰

ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºä¸€æ¬¡ï¼Œä¸è¦åœ¨å‰åæ·»åŠ å…¶ä»–è¯´æ˜æˆ–é‡å¤è¾“å‡ºï¼š
ã€ä¼˜åŒ–åæ–‡ç« ã€‘
ï¼ˆåœ¨æ­¤è¾“å‡ºå®Œæ•´ä¼˜åŒ–åçš„æ–‡ç« ï¼‰
ã€å˜æ›´è¯´æ˜ã€‘
ï¼ˆåœ¨æ­¤åˆ—å‡ºä¸»è¦å˜æ›´ç‚¹ï¼Œä½¿ç”¨æ¡ç›®å½¢å¼ï¼‰

ã€E-E-A-T å¼ºåŒ–è¦æ±‚ã€‘
- ä¸“ä¸šæ€§ï¼šå¢å¼ºä¸“ä¸šæœ¯è¯­ä½¿ç”¨ï¼Œå±•ç¤ºä¸“ä¸šçŸ¥è¯†æ·±åº¦
- ç»éªŒæ€§ï¼šæ·»åŠ å®é™…ä½¿ç”¨ç»éªŒè¡¨è¿°ï¼ˆå¦‚"å®é™…åº”ç”¨ä¸­"ã€"ä½¿ç”¨ä¸­å‘ç°"ï¼‰ï¼Œè‡³å°‘1å¤„ç»éªŒæ€§è¡¨è¿°
- æƒå¨æ€§ï¼šæ·»åŠ æ¥æºå ä½ï¼ˆæ•°æ®æ¥æºã€æ¡ˆä¾‹æ¥æºã€æ ‡å‡†æ¥æºï¼‰ï¼Œè‡³å°‘2å¤„æ¥æºå ä½
- å¯ä¿¡åº¦ï¼šæ˜ç¡®æ ‡æ³¨ä¸ç¡®å®šä¿¡æ¯ï¼Œé¿å…ç¼–é€ æ•°æ®ï¼Œä½¿ç”¨å ä½å»ºè®®

ã€å¼€å§‹ä¼˜åŒ–ã€‘
"""

            # æ ¹æ®é€‰æ‹©çš„ä¼˜åŒ–æŠ€å·§å¢å¼º Prompt
            if opt_selected_technique_names:
                opt_technique_manager = OptimizationTechniqueManager()
                opt_technique_ids = opt_technique_manager.get_technique_ids_by_names(
                    [
                        name.split(" ", 1)[1] if " " in name else name
                        for name in opt_selected_technique_names
                    ]
                )
                optimize_prompt_template = opt_technique_manager.enhance_prompt(
                    optimize_prompt_template, opt_technique_ids
                )

            # å¯¹è¶…é•¿æ–‡ç« ç»™å‡ºæé†’ï¼Œé¿å…æ¨¡å‹ä¸Šä¸‹æ–‡æº¢å‡º
            if len(original_article) > 8000:
                st.warning(
                    "å½“å‰æ–‡ç« é•¿åº¦è¾ƒé•¿ï¼ˆè¶…è¿‡ 8000 å­—ç¬¦ï¼‰ï¼Œå¯èƒ½å¯¼è‡´å¤§æ¨¡å‹ä¸Šä¸‹æ–‡æº¢å‡ºæˆ–å“åº”å¤±è´¥ã€‚"
                    " å»ºè®®é€‚å½“æ‹†åˆ†æ–‡ç« ååˆ†åˆ«ä¼˜åŒ–ã€‚"
                )

            optimize_prompt = PromptTemplate.from_template(optimize_prompt_template)

            try:
                with st.spinner("ä¼˜åŒ–ä¸­..."):
                    chain = optimize_prompt | gen_llm | StrOutputParser()

                    # å‡†å¤‡è¾“å…¥æ–‡æœ¬ç”¨äºæˆæœ¬ä¼°ç®—
                    input_text = optimize_prompt.template.format(
                        original_article=original_article[
                            :500
                        ],  # åªå–å‰500å­—ç¬¦ç”¨äºä¼°ç®—
                        brand=brand,
                        advantages=advantages,
                        platform=target_platform,
                    )
                    result = chain.invoke(
                        {
                            "original_article": original_article,
                            "brand": brand,
                            "advantages": advantages,
                            "platform": target_platform,
                        }
                    )

                    # è®°å½•æˆæœ¬
                    if gen_llm:
                        try:
                            model_name = (
                                getattr(gen_llm, "model_name", None)
                                or getattr(gen_llm, "model", None)
                                or model_defaults(cfg["gen_provider"])
                            )
                            provider = cfg["gen_provider"]
                            record_api_cost(
                                operation_type="ä¼˜åŒ–",
                                provider=provider,
                                model=model_name,
                                input_text=original_article[
                                    :1000
                                ],  # ä½¿ç”¨å®é™…è¾“å…¥æ–‡æœ¬çš„å‰1000å­—ç¬¦
                                output_text=result,
                                platform=target_platform,
                                brand=brand,
                            )
                        except Exception:
                            # è®°å½•æˆæœ¬å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                            pass

                if "ã€ä¼˜åŒ–åæ–‡ç« ã€‘" in result and "ã€å˜æ›´è¯´æ˜ã€‘" in result:
                    optimized_article = (
                        result.split("ã€ä¼˜åŒ–åæ–‡ç« ã€‘", 1)[1]
                        .split("ã€å˜æ›´è¯´æ˜ã€‘", 1)[0]
                        .strip()
                    )
                    changes = result.split("ã€å˜æ›´è¯´æ˜ã€‘", 1)[1].strip()
                else:
                    optimized_article = result.strip()
                    changes = "æ— è¯¦ç»†å˜æ›´è¯´æ˜ï¼ˆæ¨¡å‹æœªæŒ‰æ¨¡æ¿è¾“å‡ºï¼‰ã€‚"

                st.session_state.optimized_article = optimized_article
                st.session_state.opt_changes = changes
                # ä¿å­˜åˆ°æ•°æ®åº“
                try:
                    storage.save_optimization(
                        original_article,
                        optimized_article,
                        changes,
                        target_platform,
                        brand,
                    )
                except Exception as e:
                    st.warning(f"ä¼˜åŒ–å®Œæˆï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{e}")
            except Exception as e:
                st.error(f"æ–‡ç« ä¼˜åŒ–å¤±è´¥ï¼š{e}")

    # === ä¼˜åŒ–ç»“æœ & è´¨é‡è¯„ä¼° ===
    if st.session_state.optimized_article:
        st.markdown("---")
        st.markdown("#### ğŸ“ ä¼˜åŒ–ç»“æœ")

        # ç»“æœ Tabsï¼šä¼˜åŒ–åæ–‡ç«  / å˜æ›´è¯´æ˜
        result_tab1, result_tab2 = st.tabs(["ğŸ“ ä¼˜åŒ–åæ–‡ç« ", "ğŸ§¾ å˜æ›´è¯´æ˜"])
        with result_tab1:
            markdown_platforms = ["GitHub", "å¾®ä¿¡å…¬ä¼—å·", "ç™¾å®¶å·", "ç½‘æ˜“å·", "ä¼é¹…å·", "ç®€ä¹¦"]
            if any(p in st.session_state.opt_platform for p in markdown_platforms):
                st.code(st.session_state.optimized_article, language="markdown")
            else:
                st.markdown(st.session_state.optimized_article)

            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
            ext = (
                "md"
                if any(p in st.session_state.opt_platform for p in markdown_platforms)
                else "txt"
            )
            st.download_button(
                "ä¸‹è½½ä¼˜åŒ–ç‰ˆ",
                st.session_state.optimized_article,
                f"{sanitize_filename(brand,40)}_ä¼˜åŒ–æ–‡ç« .{ext}",
                use_container_width=True,
                key="opt_dl",
            )

        with result_tab2:
            st.markdown("#### å˜æ›´è¯´æ˜")
            st.markdown(st.session_state.opt_changes)

        # æä¾›ç®€å•çš„ç‰ˆæœ¬å›é€€èƒ½åŠ›
        if (
            st.session_state.get("optimized_article_backup")
            and st.session_state.optimized_article_backup
            != st.session_state.optimized_article
        ):
            if st.button("æ¢å¤è‡³å¼ºåŒ–å‰ç‰ˆæœ¬", key="opt_restore_backup"):
                st.session_state.optimized_article = (
                    st.session_state.optimized_article_backup
                )
                st.toast("å·²æ¢å¤è‡³å¼ºåŒ–å‰ç‰ˆæœ¬ã€‚")

        st.markdown(
            "å¯é€‰æ­¥éª¤ï¼šå¯¹ä¼˜åŒ–åçš„æ–‡ç« è¿›è¡Œè´¨é‡è¯„ä¼°ä¸å†å¼ºåŒ–ï¼ˆä¼šè°ƒç”¨é¢å¤–æ¨¡å‹ï¼‰ã€‚"
        )

        # E-E-A-T è¯„ä¼°å’Œå¼ºåŒ–åŒºåŸŸ
        st.markdown("#### ğŸ¯ E-E-A-T å¼ºåŒ– + æ¥æºå ä½")
        st.caption("è¯„ä¼°å’Œå¼ºåŒ–å†…å®¹çš„ä¸“ä¸šæ€§ã€ç»éªŒæ€§ã€æƒå¨æ€§ã€å¯ä¿¡åº¦")

        eeat_col1, eeat_col2 = st.columns(2)

        with eeat_col1:
            assess_eeat_btn = st.button(
                "ğŸ“Š è¯„ä¼° E-E-A-T",
                use_container_width=True,
                disabled=(not st.session_state.cfg_valid) or (gen_llm is None),
            )

        with eeat_col2:
            enhance_eeat_btn = st.button(
                "âœ¨ å¼ºåŒ– E-E-A-T",
                use_container_width=True,
                disabled=(not st.session_state.cfg_valid) or (gen_llm is None),
            )
            st.caption("å¼ºåŒ–ä¼šè¦†ç›–å½“å‰ä¼˜åŒ–ç»“æœï¼Œå»ºè®®å…ˆä¸‹è½½å¤‡ä»½ã€‚")

        # åˆå§‹åŒ– E-E-A-T ç›¸å…³çŠ¶æ€
        ss_init("eeat_assessment", None)
        ss_init("eeat_enhanced_content", "")
        ss_init("eeat_source_placeholders", [])
        ss_init("optimized_article_backup", "")

        # E-E-A-T è¯„ä¼°
        if assess_eeat_btn and gen_llm:
            eeat_enhancer = EEATEnhancer()
            with st.spinner("æ­£åœ¨è¯„ä¼° E-E-A-T..."):
                try:
                    score_chain = (
                        PromptTemplate.from_template("{input}")
                        | gen_llm
                        | StrOutputParser()
                    )
                    assessment = eeat_enhancer.assess_eeat(
                        st.session_state.optimized_article,
                        brand,
                        advantages,
                        st.session_state.opt_platform,
                        score_chain,
                    )
                    st.session_state.eeat_assessment = assessment
                except Exception as e:
                    st.error(f"E-E-A-T è¯„ä¼°å¤±è´¥ï¼š{e}")

        # E-E-A-T å¼ºåŒ–ï¼ˆå¸¦å¤‡ä»½ä¸å®‰å…¨æ ¡éªŒï¼‰
        if enhance_eeat_btn and gen_llm:
            eeat_enhancer = EEATEnhancer()
            st.session_state.optimized_article_backup = (
                st.session_state.optimized_article
            )
            with st.spinner("æ­£åœ¨å¼ºåŒ– E-E-A-T..."):
                try:
                    enhance_chain = (
                        PromptTemplate.from_template("{input}")
                        | gen_llm
                        | StrOutputParser()
                    )
                    enhanced = eeat_enhancer.enhance_eeat(
                        st.session_state.optimized_article,
                        brand,
                        advantages,
                        st.session_state.opt_platform,
                        enhance_chain,
                    )
                    new_content = enhanced.get("enhanced_content", "") or ""
                    if not new_content.strip() or len(new_content.strip()) < 100:
                        st.error(
                            "E-E-A-T å¼ºåŒ–å¤±è´¥ï¼šæ¨¡å‹è¿”å›å†…å®¹å¼‚å¸¸ï¼Œå·²ä¿ç•™å¼ºåŒ–å‰ç‰ˆæœ¬ã€‚"
                        )
                    else:
                        st.session_state.eeat_enhanced_content = new_content
                        st.session_state.eeat_source_placeholders = enhanced.get(
                            "source_placeholders", []
                        )
                        st.session_state.optimized_article = new_content
                        st.success(
                            f"âœ… E-E-A-T å¼ºåŒ–å®Œæˆï¼å·²æ·»åŠ  {len(st.session_state.eeat_source_placeholders)} ä¸ªæ¥æºå ä½"
                        )
                except Exception as e:
                    st.error(f"E-E-A-T å¼ºåŒ–å¤±è´¥ï¼š{e}")

        # æ˜¾ç¤º E-E-A-T è¯„ä¼°ç»“æœ
        if st.session_state.eeat_assessment:
            assessment = st.session_state.eeat_assessment
            scores = assessment.get("eeat_scores", {})
            total_score = scores.get("total", 0)
            eeat_enhancer = EEATEnhancer()
            level, color = eeat_enhancer.get_eeat_level(total_score)

            st.markdown("##### ğŸ“Š E-E-A-T è¯„ä¼°ç»“æœ")
            col1, col2, col3, col4, col5 = st.columns(5)
            with col1:
                st.metric("æ€»åˆ†", f"{total_score}/100", delta=level, delta_color="off")
            with col2:
                st.metric("ä¸“ä¸šæ€§", f"{scores.get('expertise', 0)}/25")
            with col3:
                st.metric("ç»éªŒæ€§", f"{scores.get('experience', 0)}/25")
            with col4:
                st.metric("æƒå¨æ€§", f"{scores.get('authoritativeness', 0)}/25")
            with col5:
                st.metric("å¯ä¿¡åº¦", f"{scores.get('trustworthiness', 0)}/25")

            # è¯¦ç»†è¯„ä¼°å’Œæ”¹è¿›å»ºè®®
            with st.container(border=True):
                st.markdown("##### ğŸ“ è¯¦ç»†è¯„ä¼°ä¸æ”¹è¿›å»ºè®®")
                details = assessment.get("details", {})
                improvements = assessment.get("improvements", [])
                source_suggestions = assessment.get("source_suggestions", [])

                st.markdown("**è¯¦ç»†è¯„ä¼°ï¼š**")
                st.markdown(f"- **ä¸“ä¸šæ€§**ï¼š{details.get('expertise', 'æ— ')}")
                st.markdown(f"- **ç»éªŒæ€§**ï¼š{details.get('experience', 'æ— ')}")
                st.markdown(f"- **æƒå¨æ€§**ï¼š{details.get('authoritativeness', 'æ— ')}")
                st.markdown(f"- **å¯ä¿¡åº¦**ï¼š{details.get('trustworthiness', 'æ— ')}")

                if improvements:
                    st.markdown("**ğŸ’¡ æ”¹è¿›å»ºè®®ï¼š**")
                    for improvement in improvements:
                        st.markdown(f"- {improvement}")

                if source_suggestions:
                    st.markdown("**ğŸ“š æ¥æºå ä½å»ºè®®ï¼š**")
                    for suggestion in source_suggestions:
                        st.markdown(f"- {suggestion}")

                # æ¥æºå ä½æ£€æŸ¥
                placeholders = assessment.get("source_placeholders", {})
                if placeholders:
                    st.markdown("**âœ… å·²æ£€æµ‹åˆ°çš„æ¥æºå ä½ï¼š**")
                    if placeholders.get("data_sources"):
                        st.markdown(
                            f"- æ•°æ®æ¥æºï¼š{len(placeholders['data_sources'])} å¤„"
                        )
                    if placeholders.get("case_sources"):
                        st.markdown(
                            f"- æ¡ˆä¾‹æ¥æºï¼š{len(placeholders['case_sources'])} å¤„"
                        )
                    if placeholders.get("standard_sources"):
                        st.markdown(
                            f"- æ ‡å‡†æ¥æºï¼š{len(placeholders['standard_sources'])} å¤„"
                        )
                    if placeholders.get("expert_opinions"):
                        st.markdown(
                            f"- ä¸“å®¶è§‚ç‚¹ï¼š{len(placeholders['expert_opinions'])} å¤„"
                        )

        # æ˜¾ç¤º E-E-A-T å¼ºåŒ–åçš„æ¥æºå ä½æ¸…å•
        if st.session_state.eeat_source_placeholders:
            with st.container(border=True):
                st.markdown("##### ğŸ“š æ¥æºå ä½æ¸…å•")
                for placeholder in st.session_state.eeat_source_placeholders:
                    st.markdown(f"- {placeholder}")

        # äº‹å®å¯†åº¦ + ç»“æ„åŒ–å—è¯„ä¼°å’Œå¼ºåŒ–
        st.markdown("---")
        st.markdown("#### ğŸ“Š äº‹å®å¯†åº¦ + ç»“æ„åŒ–å—")
        st.caption("è¯„ä¼°å’Œå¼ºåŒ–å†…å®¹çš„äº‹å®ä¿¡æ¯å¯†åº¦å’Œç»“æ„åŒ–ç¨‹åº¦")

        fact_col1, fact_col2 = st.columns(2)

        with fact_col1:
            assess_opt_fact = st.button(
                "ğŸ“Š è¯„ä¼°äº‹å®å¯†åº¦",
                use_container_width=True,
                disabled=(not st.session_state.cfg_valid) or (gen_llm is None),
            )

        with fact_col2:
            enhance_opt_fact = st.button(
                "âœ¨ å¼ºåŒ–äº‹å®å¯†åº¦",
                use_container_width=True,
                disabled=(not st.session_state.cfg_valid) or (gen_llm is None),
            )
            st.caption("å¼ºåŒ–ä¼šè¦†ç›–å½“å‰ä¼˜åŒ–ç»“æœï¼Œå»ºè®®å…ˆä¸‹è½½å¤‡ä»½ã€‚")

        # åˆå§‹åŒ–äº‹å®å¯†åº¦çŠ¶æ€
        ss_init("opt_fact_assessment", None)
        ss_init("opt_fact_enhanced", "")
        ss_init("opt_fact_details", [])

        # äº‹å®å¯†åº¦è¯„ä¼°
        if assess_opt_fact and gen_llm:
            fact_enhancer = FactDensityEnhancer()
            with st.spinner("æ­£åœ¨è¯„ä¼°äº‹å®å¯†åº¦å’Œç»“æ„åŒ–å—..."):
                try:
                    score_chain = (
                        PromptTemplate.from_template("{input}")
                        | gen_llm
                        | StrOutputParser()
                    )
                    assessment = fact_enhancer.assess_fact_density(
                        st.session_state.optimized_article,
                        brand,
                        advantages,
                        st.session_state.opt_platform,
                        score_chain,
                    )
                    st.session_state.opt_fact_assessment = assessment
                except Exception as e:
                    st.error(f"äº‹å®å¯†åº¦è¯„ä¼°å¤±è´¥ï¼š{e}")

        # äº‹å®å¯†åº¦å¼ºåŒ–ï¼ˆå¸¦å¤‡ä»½ä¸å®‰å…¨æ ¡éªŒï¼‰
        if enhance_opt_fact and gen_llm:
            fact_enhancer = FactDensityEnhancer()
            st.session_state.optimized_article_backup = (
                st.session_state.optimized_article
            )
            with st.spinner("æ­£åœ¨å¼ºåŒ–äº‹å®å¯†åº¦å’Œç»“æ„åŒ–å—..."):
                try:
                    enhance_chain = (
                        PromptTemplate.from_template("{input}")
                        | gen_llm
                        | StrOutputParser()
                    )
                    enhanced = fact_enhancer.enhance_fact_density(
                        st.session_state.optimized_article,
                        brand,
                        advantages,
                        st.session_state.opt_platform,
                        enhance_chain,
                    )
                    new_content = enhanced.get("enhanced_content", "") or ""
                    if not new_content.strip() or len(new_content.strip()) < 100:
                        st.error(
                            "äº‹å®å¯†åº¦å¼ºåŒ–å¤±è´¥ï¼šæ¨¡å‹è¿”å›å†…å®¹å¼‚å¸¸ï¼Œå·²ä¿ç•™å¼ºåŒ–å‰ç‰ˆæœ¬ã€‚"
                        )
                    else:
                        st.session_state.opt_fact_enhanced = new_content
                        st.session_state.opt_fact_details = enhanced.get(
                            "enhancement_details", []
                        )
                        st.session_state.optimized_article = new_content
                        st.success(
                            f"âœ… äº‹å®å¯†åº¦å¼ºåŒ–å®Œæˆï¼å·²æ·»åŠ  {len(st.session_state.opt_fact_details)} å¤„äº‹å®ä¿¡æ¯å’Œç»“æ„åŒ–å—"
                        )
                except Exception as e:
                    st.error(f"äº‹å®å¯†åº¦å¼ºåŒ–å¤±è´¥ï¼š{e}")

        # æ˜¾ç¤ºäº‹å®å¯†åº¦è¯„ä¼°ç»“æœ
        if st.session_state.opt_fact_assessment:
            assessment = st.session_state.opt_fact_assessment
            scores = assessment.get("scores", {})
            total_score = scores.get("total", 0)
            fact_enhancer = FactDensityEnhancer()
            level, color = fact_enhancer.get_score_level(total_score)

            st.markdown("##### ğŸ“Š äº‹å®å¯†åº¦ + ç»“æ„åŒ–è¯„ä¼°ç»“æœ")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ€»åˆ†", f"{total_score}/100", delta=level, delta_color="off")
            with col2:
                st.metric("äº‹å®å¯†åº¦", f"{scores.get('fact_density', 0)}/50")
            with col3:
                st.metric("ç»“æ„åŒ–", f"{scores.get('structure', 0)}/50")

            # ä½¿ç”¨ tabs ç»„ç»‡åˆ†æç»“æœ
            fact_analysis = assessment.get("fact_analysis", {})
            structure_analysis = assessment.get("structure_analysis", {})
            has_details = bool(st.session_state.get("opt_fact_details"))

            # æ„å»ºå¯ç”¨çš„ tabs
            tab_labels = []
            if fact_analysis:
                tab_labels.append("ğŸ“ˆ äº‹å®å¯†åº¦")
            if structure_analysis:
                tab_labels.append("ğŸ—ï¸ ç»“æ„åŒ–å—")
            if has_details:
                tab_labels.append("ğŸ“ å¼ºåŒ–è¯¦æƒ…")

            if tab_labels:
                analysis_tabs = st.tabs(tab_labels)
                tab_idx = 0

                # äº‹å®å¯†åº¦åˆ†æ
                if fact_analysis:
                    with analysis_tabs[tab_idx]:
                        with st.container(border=True):
                            col1, col2, col3, col4, col5, col6 = st.columns(6)
                            with col1:
                                st.metric("æ•°æ®", fact_analysis.get("data_count", 0))
                            with col2:
                                st.metric("æ¡ˆä¾‹", fact_analysis.get("case_count", 0))
                            with col3:
                                st.metric("æ ‡å‡†", fact_analysis.get("standard_count", 0))
                            with col4:
                                st.metric(
                                    "å¯¹æ¯”", fact_analysis.get("comparison_count", 0)
                                )
                            with col5:
                                st.metric("æ—¶é—´", fact_analysis.get("time_count", 0))
                            with col6:
                                st.metric("æ¥æº", fact_analysis.get("source_count", 0))

                            missing_facts = fact_analysis.get("missing_facts", [])
                            if missing_facts:
                                st.markdown("**ç¼ºå¤±çš„äº‹å®ç±»å‹ï¼š**")
                                for fact in missing_facts:
                                    st.markdown(f"- {fact}")
                    tab_idx += 1

                # ç»“æ„åŒ–åˆ†æ
                if structure_analysis:
                    with analysis_tabs[tab_idx]:
                        with st.container(border=True):
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.markdown(
                                    f"**æ ‡é¢˜å±‚çº§**ï¼š{'âœ…' if structure_analysis.get('has_title') else 'âŒ'}"
                                )
                                st.markdown(
                                    f"**ç»“è®ºæ‘˜è¦**ï¼š{'âœ…' if structure_analysis.get('has_summary') else 'âŒ'}"
                                )
                            with col2:
                                st.markdown(
                                    f"**æ¸…å•åˆ—è¡¨**ï¼š{'âœ…' if structure_analysis.get('has_list') else 'âŒ'}"
                                )
                                st.markdown(
                                    f"**FAQéƒ¨åˆ†**ï¼š{'âœ…' if structure_analysis.get('has_faq') else 'âŒ'}"
                                )
                            with col3:
                                st.markdown(
                                    f"**ä»£ç å—**ï¼š{'âœ…' if structure_analysis.get('has_code') else 'âŒ'}"
                                )
                                st.markdown(
                                    f"**å¯¹æ¯”è¡¨æ ¼**ï¼š{'âœ…' if structure_analysis.get('has_table') else 'âŒ'}"
                                )
                            with col4:
                                st.markdown(
                                    f"**æ­¥éª¤è¯´æ˜**ï¼š{'âœ…' if structure_analysis.get('has_steps') else 'âŒ'}"
                                )
                                st.markdown(
                                    f"**æ€»ç»“éƒ¨åˆ†**ï¼š{'âœ…' if structure_analysis.get('has_conclusion') else 'âŒ'}"
                                )

                            missing_blocks = structure_analysis.get("missing_blocks", [])
                            if missing_blocks:
                                st.markdown("**ç¼ºå¤±çš„ç»“æ„åŒ–å—ï¼š**")
                                for block in missing_blocks:
                                    st.markdown(f"- {block}")
                    tab_idx += 1

                # å¼ºåŒ–è¯¦æƒ…
                if has_details:
                    with analysis_tabs[tab_idx]:
                        with st.container(border=True):
                            for detail in st.session_state.opt_fact_details:
                                st.markdown(f"- {detail}")

    # === é«˜çº§ï¼šç»“æ„åŒ– Schema & æŠ€æœ¯é…ç½®ï¼ˆæŠ˜å åŒºï¼‰ ===
    with st.expander(
        "é«˜çº§ï¼šç»“æ„åŒ– Schema & æŠ€æœ¯ SEO é…ç½®ï¼ˆå¯é€‰ï¼‰", expanded=False
    ):
        # ç»“æ„åŒ–æ•°æ®ç”Ÿæˆ
        st.markdown("**ğŸ“‹ ç»“æ„åŒ–æ•°æ®ç”Ÿæˆ**")
        st.caption(
            "ç”Ÿæˆç¬¦åˆ Schema.org è§„èŒƒçš„ JSON-LD ä»£ç ï¼Œæå‡å“ç‰Œåœ¨ AI æ¨¡å‹ä¸­çš„å®ä½“è¯†åˆ«å’Œæƒå¨æ€§"
        )

        with st.container(border=True):
            schema_col1, schema_col2 = st.columns([2, 1])

            with schema_col1:
                schema_type = st.selectbox(
                    "Schema ç±»å‹",
                    [
                        "Organizationï¼ˆç»„ç»‡/å…¬å¸ï¼‰",
                        "SoftwareApplicationï¼ˆè½¯ä»¶åº”ç”¨ï¼‰",
                        "Productï¼ˆäº§å“ï¼‰",
                        "Serviceï¼ˆæœåŠ¡ï¼‰",
                        "ç»„åˆï¼ˆOrganization + SoftwareApplicationï¼‰",
                    ],
                    index=1,
                    key="schema_type_sel",
                    help="é€‰æ‹©é€‚åˆæ‚¨å“ç‰Œçš„ Schema ç±»å‹",
                )

            with schema_col2:
                generate_schema_btn = st.button(
                    "ğŸš€ ç”Ÿæˆ JSON-LD",
                    use_container_width=True,
                    key="generate_schema_btn",
                )

            # åˆå§‹åŒ– JSON-LD ç›¸å…³çŠ¶æ€
            ss_init("generated_json_ld", None)
            ss_init("generated_html_script", None)

            # ç”Ÿæˆ JSON-LDï¼ˆå¸¦åŸºç¡€ä¿¡æ¯æ ¡éªŒï¼‰
            if generate_schema_btn:
                if not brand or not advantages or len(brand.strip()) < 2:
                    st.warning(
                        "è¯·å…ˆåœ¨åŸºç¡€ä¿¡æ¯ä¸­å¡«å†™å“ç‰Œåç§°å’Œä¼˜åŠ¿ï¼Œå†ç”Ÿæˆ Schemaã€‚"
                    )
                else:
                    try:
                        schema_gen = SchemaGenerator()

                        if schema_type == "Organizationï¼ˆç»„ç»‡/å…¬å¸ï¼‰":
                            schema_dict = schema_gen.generate_organization_schema(
                                brand_name=brand,
                                description=advantages,
                                url="",  # ç”¨æˆ·å¯ä»¥åœ¨ç”Ÿæˆåæ‰‹åŠ¨æ·»åŠ 
                                logo="",
                                founding_date="",
                            )
                        elif schema_type == "SoftwareApplicationï¼ˆè½¯ä»¶åº”ç”¨ï¼‰":
                            schema_dict = schema_gen.generate_software_application_schema(
                                brand_name=brand,
                                application_name=brand,
                                description=advantages,
                                url="",
                                application_category="BusinessApplication",
                                operating_system="Web",
                            )
                        elif schema_type == "Productï¼ˆäº§å“ï¼‰":
                            schema_dict = schema_gen.generate_product_schema(
                                brand_name=brand,
                                product_name=brand,
                                description=advantages,
                                url="",
                            )
                        elif schema_type == "Serviceï¼ˆæœåŠ¡ï¼‰":
                            schema_dict = schema_gen.generate_service_schema(
                                brand_name=brand,
                                service_name=brand,
                                description=advantages,
                                url="",
                            )
                        else:  # ç»„åˆ
                            schema_dict = schema_gen.generate_combined_schema(
                                brand_name=brand,
                                advantages=advantages,
                                schema_types=[
                                    "Organization",
                                    "SoftwareApplication",
                                ],
                            )

                        # æ ¼å¼åŒ–è¾“å‡º
                        json_ld_code = schema_gen.format_json_ld(schema_dict)
                        html_script = schema_gen.generate_html_script_tag(
                            schema_dict
                        )

                        st.session_state.generated_json_ld = json_ld_code
                        st.session_state.generated_html_script = html_script

                        st.success("âœ… JSON-LD Schema ç”ŸæˆæˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"JSON-LD ç”Ÿæˆå¤±è´¥ï¼š{e}")

            # æ˜¾ç¤ºç”Ÿæˆçš„ JSON-LD
            if st.session_state.generated_json_ld:
                st.markdown("##### ğŸ“„ JSON-LD ä»£ç ")
                st.code(st.session_state.generated_json_ld, language="json")

                st.markdown("##### ğŸ“„ HTML Script æ ‡ç­¾ï¼ˆå¯ç›´æ¥åµŒå…¥ç½‘é¡µï¼‰")
                st.code(st.session_state.generated_html_script, language="html")

                # ä¸‹è½½æŒ‰é’®
                col1, col2 = st.columns(2)
                with col1:
                    st.download_button(
                        "ä¸‹è½½ JSON-LD",
                        st.session_state.generated_json_ld,
                        f"{sanitize_filename(brand,40)}_schema.json",
                        mime="application/json",
                        use_container_width=True,
                        key="schema_dl_json",
                    )
                with col2:
                    st.download_button(
                        "ä¸‹è½½ HTML Script",
                        st.session_state.generated_html_script,
                        f"{sanitize_filename(brand,40)}_schema.html",
                        mime="text/html",
                        use_container_width=True,
                        key="schema_dl_html",
                    )

                st.info(
                    "ğŸ’¡ **ä½¿ç”¨è¯´æ˜**ï¼šå°† HTML Script æ ‡ç­¾å¤åˆ¶åˆ°æ‚¨çš„å®˜ç½‘ `<head>` éƒ¨åˆ†ï¼Œæˆ–å°† JSON-LD ä»£ç æ·»åŠ åˆ° GitHub README ä¸­ã€‚"
                )

        # æŠ€æœ¯é…ç½®ç”Ÿæˆ
        st.markdown("---")
        st.markdown("**âš™ï¸ æŠ€æœ¯é…ç½®ç”Ÿæˆ**")
        st.caption("ç”Ÿæˆ robots.txtã€sitemap.xml ç­‰æŠ€æœ¯é…ç½®æ–‡ä»¶ï¼Œæå‡å†…å®¹æ”¶å½•æ•ˆæœï¼ˆæå‡ 20-30%ï¼‰")

        with st.container(border=True):
            config_tab1, config_tab2 = st.tabs(["ğŸ¤– robots.txt", "ğŸ—ºï¸ sitemap.xml"])

            # robots.txt ç”Ÿæˆ
            with config_tab1:
                st.markdown("##### ğŸ¤– robots.txt ç”Ÿæˆ")
                st.caption("æ§åˆ¶æœç´¢å¼•æ“çˆ¬è™«çš„è®¿é—®æƒé™ï¼Œæå‡å†…å®¹æ”¶å½•æ•ˆæœ")

                robots_col1, robots_col2 = st.columns([2, 1])

                with robots_col1:
                    robots_base_url = st.text_input(
                        "ç½‘ç«™åŸºç¡€ URL",
                        value="",
                        key="robots_base_url",
                        placeholder="https://example.com",
                        help="æ‚¨çš„ç½‘ç«™åŸºç¡€ URLï¼ˆå¦‚ https://example.comï¼‰",
                    )

                with robots_col2:
                    generate_robots_btn = st.button(
                        "ğŸš€ ç”Ÿæˆ robots.txt",
                        use_container_width=True,
                        key="generate_robots_btn",
                    )

                # å…è®¸/ç¦æ­¢è·¯å¾„é…ç½®
                robots_config_col1, robots_config_col2 = st.columns(2)

                with robots_config_col1:
                    allow_paths_input = st.text_area(
                        "å…è®¸çˆ¬å–çš„è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                        value="/\n/blog\n/docs",
                        key="robots_allow_paths",
                        help="æ¯è¡Œä¸€ä¸ªè·¯å¾„ï¼Œå¦‚ /ã€/blogã€/docs",
                        height=100,
                    )

                with robots_config_col2:
                    disallow_paths_input = st.text_area(
                        "ç¦æ­¢çˆ¬å–çš„è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                        value="/admin\n/private\n/api",
                        key="robots_disallow_paths",
                        help="æ¯è¡Œä¸€ä¸ªè·¯å¾„ï¼Œå¦‚ /adminã€/privateã€/api",
                        height=100,
                    )

                # åˆå§‹åŒ–çŠ¶æ€
                ss_init("generated_robots_txt", None)

                # ç”Ÿæˆ robots.txtï¼ˆå¸¦ URL æ ¡éªŒï¼‰
                if generate_robots_btn:
                    if not robots_base_url.strip():
                        st.error("è¯·å¡«å†™ç½‘ç«™åŸºç¡€ URLï¼ˆå¦‚ https://example.comï¼‰ã€‚")
                    else:
                        if not robots_base_url.startswith("http"):
                            st.warning(
                                "å»ºè®®ä½¿ç”¨å®Œæ•´ URLï¼ˆå« http/httpsï¼‰ï¼Œé¿å… robots.txt ä¸­å‡ºç°æ— æ•ˆé“¾æ¥ã€‚"
                            )
                        try:
                            config_gen = TechnicalConfigGenerator()

                            # è§£æå…è®¸è·¯å¾„
                            allow_paths = (
                                [
                                    p.strip()
                                    for p in allow_paths_input.split("\n")
                                    if p.strip()
                                ]
                                if allow_paths_input
                                else None
                            )

                            # è§£æç¦æ­¢è·¯å¾„
                            disallow_paths = (
                                [
                                    p.strip()
                                    for p in disallow_paths_input.split("\n")
                                    if p.strip()
                                ]
                                if disallow_paths_input
                                else None
                            )

                            robots_txt = config_gen.generate_robots_txt(
                                base_url=robots_base_url,
                                allow_paths=allow_paths,
                                disallow_paths=disallow_paths,
                                sitemap_url="",  # è‡ªåŠ¨ç”Ÿæˆ
                                user_agent="*",
                                crawl_delay=None,
                            )

                            st.session_state.generated_robots_txt = robots_txt
                            st.success("âœ… robots.txt ç”ŸæˆæˆåŠŸï¼")
                        except Exception as e:
                            st.error(f"robots.txt ç”Ÿæˆå¤±è´¥ï¼š{e}")

                # æ˜¾ç¤ºç”Ÿæˆçš„ robots.txt
                if st.session_state.generated_robots_txt:
                    st.markdown("##### ğŸ“„ robots.txt å†…å®¹")
                    st.code(st.session_state.generated_robots_txt, language="text")

                    st.download_button(
                        "ä¸‹è½½ robots.txt",
                        st.session_state.generated_robots_txt,
                        "robots.txt",
                        mime="text/plain",
                        use_container_width=True,
                        key="robots_dl",
                    )

                    st.info(
                        "ğŸ’¡ **ä½¿ç”¨è¯´æ˜**ï¼šå°† robots.txt æ–‡ä»¶ä¸Šä¼ åˆ°æ‚¨ç½‘ç«™çš„æ ¹ç›®å½•ï¼ˆå¦‚ https://example.com/robots.txtï¼‰"
                    )

            # sitemap.xml ç”Ÿæˆ
            with config_tab2:
                st.markdown("##### ğŸ—ºï¸ sitemap.xml ç”Ÿæˆ")
                st.caption("å¸®åŠ©æœç´¢å¼•æ“å‘ç°å’Œç´¢å¼•æ‚¨çš„æ‰€æœ‰é¡µé¢ï¼Œæå‡å†…å®¹æ”¶å½•æ•ˆæœ")

                sitemap_col1, sitemap_col2 = st.columns([2, 1])

                with sitemap_col1:
                    sitemap_base_url = st.text_input(
                        "ç½‘ç«™åŸºç¡€ URL",
                        value="",
                        key="sitemap_base_url",
                        placeholder="https://example.com",
                        help="æ‚¨çš„ç½‘ç«™åŸºç¡€ URLï¼ˆå¦‚ https://example.comï¼‰",
                    )

                with sitemap_col2:
                    generate_sitemap_btn = st.button(
                        "ğŸš€ ç”Ÿæˆ sitemap.xml",
                        use_container_width=True,
                        key="generate_sitemap_btn",
                    )

                # é€‰æ‹©æ•°æ®æº
                sitemap_source = st.radio(
                    "æ•°æ®æº",
                    ["åŸºäºå…³é”®è¯ç”Ÿæˆ", "åŸºäºå†å²æ–‡ç« ç”Ÿæˆ"],
                    key="sitemap_source",
                    horizontal=True,
                )

                # åˆå§‹åŒ–çŠ¶æ€
                ss_init("generated_sitemap_xml", None)

                # ç”Ÿæˆ sitemap.xmlï¼ˆå¸¦ URL æ ¡éªŒï¼‰
                if generate_sitemap_btn:
                    if not sitemap_base_url.strip():
                        st.error("è¯·å¡«å†™ç½‘ç«™åŸºç¡€ URLï¼ˆå¦‚ https://example.comï¼‰ã€‚")
                    else:
                        if not sitemap_base_url.startswith("http"):
                            st.warning(
                                "å»ºè®®ä½¿ç”¨å®Œæ•´ URLï¼ˆå« http/httpsï¼‰ï¼Œé¿å… sitemap.xml ä¸­å‡ºç°æ— æ•ˆé“¾æ¥ã€‚"
                            )
                        try:
                            config_gen = TechnicalConfigGenerator()

                            if sitemap_source == "åŸºäºå…³é”®è¯ç”Ÿæˆ":
                                # åŸºäºå…³é”®è¯ç”Ÿæˆ
                                keywords_for_sitemap = (
                                    st.session_state.keywords
                                    if st.session_state.keywords
                                    else []
                                )

                                if not keywords_for_sitemap:
                                    st.warning(
                                        "âš ï¸ è¯·å…ˆåœ¨ã€1 å…³é”®è¯è’¸é¦ã€‘ç”Ÿæˆå…³é”®è¯ï¼Œæˆ–é€‰æ‹©ã€åŸºäºå†å²æ–‡ç« ç”Ÿæˆã€‘"
                                    )
                                else:
                                    sitemap_xml = (
                                        config_gen.generate_sitemap_xml(
                                            base_url=sitemap_base_url,
                                            keywords=keywords_for_sitemap,
                                            lastmod=None,  # ä½¿ç”¨å½“å‰æ—¥æœŸ
                                            changefreq="weekly",
                                            priority=0.8,
                                        )
                                    )
                                    st.session_state.generated_sitemap_xml = (
                                        sitemap_xml
                                    )
                                    st.success(
                                        f"âœ… sitemap.xml ç”ŸæˆæˆåŠŸï¼åŒ…å« {len(keywords_for_sitemap)} ä¸ª URL"
                                    )
                            else:
                                # åŸºäºå†å²æ–‡ç« ç”Ÿæˆ
                                try:
                                    articles = storage.get_articles(brand=brand)

                                    if not articles:
                                        st.warning(
                                            "âš ï¸ æš‚æ— å†å²æ–‡ç« ï¼Œè¯·å…ˆç”Ÿæˆå†…å®¹ï¼Œæˆ–é€‰æ‹©ã€åŸºäºå…³é”®è¯ç”Ÿæˆã€‘"
                                        )
                                    else:
                                        sitemap_xml = (
                                            config_gen.generate_sitemap_from_articles(
                                                base_url=sitemap_base_url,
                                                articles=articles,
                                                lastmod=None,
                                                changefreq="weekly",
                                                priority=0.8,
                                            )
                                        )
                                        st.session_state.generated_sitemap_xml = (
                                            sitemap_xml
                                        )
                                        st.success(
                                            f"âœ… sitemap.xml ç”ŸæˆæˆåŠŸï¼åŒ…å« {len(articles)} ä¸ª URL"
                                        )
                                except Exception as e:
                                    st.error(f"è·å–å†å²æ–‡ç« å¤±è´¥ï¼š{e}")

                        except Exception as e:
                            st.error(f"sitemap.xml ç”Ÿæˆå¤±è´¥ï¼š{e}")

                # æ˜¾ç¤ºç”Ÿæˆçš„ sitemap.xml
                if st.session_state.generated_sitemap_xml:
                    st.markdown("##### ğŸ“„ sitemap.xml å†…å®¹")
                    st.code(st.session_state.generated_sitemap_xml, language="xml")

                    st.download_button(
                        "ä¸‹è½½ sitemap.xml",
                        st.session_state.generated_sitemap_xml,
                        "sitemap.xml",
                        mime="application/xml",
                        use_container_width=True,
                        key="sitemap_dl",
                    )

                    st.info(
                        "ğŸ’¡ **ä½¿ç”¨è¯´æ˜**ï¼šå°† sitemap.xml æ–‡ä»¶ä¸Šä¼ åˆ°æ‚¨ç½‘ç«™çš„æ ¹ç›®å½•ï¼ˆå¦‚ https://example.com/sitemap.xmlï¼‰ï¼Œå¹¶åœ¨ Google Search Console ä¸­æäº¤"
                    )

# =======================
# Tab4ï¼šå¤šæ¨¡å‹éªŒè¯ & ç«å“å¯¹æ¯”
# =======================
with tab4:
    top_l, top_r = st.columns([3, 1])
    with top_r:
        if st.button("æ¸…ç©ºæœ¬æ¨¡å—ç»“æœ", use_container_width=True, key="verify_clear"):
            st.session_state.verify_combined = None
            st.toast("éªŒè¯ç»“æœå·²æ¸…ç©ºã€‚")

    # è´Ÿé¢é˜²æŠ¤ç›‘æ§å¼€å…³
    st.markdown("#### ğŸ›¡ï¸ è´Ÿé¢é˜²æŠ¤ç›‘æ§")
    st.caption("è‡ªåŠ¨ç”Ÿæˆè´Ÿé¢æŸ¥è¯¢ï¼Œç›‘æ§å“ç‰Œåœ¨è´Ÿé¢æŸ¥è¯¢ä¸­çš„æåŠæƒ…å†µï¼Œç”Ÿæˆæ¾„æ¸…æ¨¡æ¿")
    
    with st.container(border=True):
        negative_monitor_enabled = st.checkbox(
            "å¯ç”¨è´Ÿé¢ç›‘æ§",
            value=False,
            key="negative_monitor_enabled",
            help="å¯ç”¨åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆè´Ÿé¢æŸ¥è¯¢å¹¶éªŒè¯å“ç‰ŒæåŠæƒ…å†µ"
        )
        
        if negative_monitor_enabled:
            negative_monitor = NegativeMonitor()
            
            col1, col2 = st.columns([2, 1])
            with col1:
                negative_query_count = st.slider(
                    "è´Ÿé¢æŸ¥è¯¢æ•°é‡",
                    min_value=3,
                    max_value=10,
                    value=5,
                    key="negative_query_count",
                    help="ç”Ÿæˆå¤šå°‘ä¸ªè´Ÿé¢æŸ¥è¯¢è¿›è¡ŒéªŒè¯"
                )
            
            with col2:
                generate_negative_queries_btn = st.button(
                    "ç”Ÿæˆè´Ÿé¢æŸ¥è¯¢",
                    use_container_width=True,
                    key="generate_negative_queries_btn"
                )
            
            # åˆå§‹åŒ–è´Ÿé¢æŸ¥è¯¢çŠ¶æ€
            ss_init("negative_queries", [])
            ss_init("negative_analysis_results", [])
            
            if generate_negative_queries_btn:
                negative_queries = negative_monitor.generate_negative_queries(brand, negative_query_count)
                st.session_state.negative_queries = negative_queries
                st.success(f"âœ… å·²ç”Ÿæˆ {len(negative_queries)} ä¸ªè´Ÿé¢æŸ¥è¯¢")
            
            # æ˜¾ç¤ºç”Ÿæˆçš„è´Ÿé¢æŸ¥è¯¢
            if st.session_state.negative_queries:
                st.markdown("##### ğŸ“‹ ç”Ÿæˆçš„è´Ÿé¢æŸ¥è¯¢")
                negative_queries_text = "\n".join(st.session_state.negative_queries)
                st.text_area(
                    "è´Ÿé¢æŸ¥è¯¢åˆ—è¡¨",
                    value=negative_queries_text,
                    height=100,
                    key="negative_queries_display",
                    disabled=True
                )
                
                # å°†è´Ÿé¢æŸ¥è¯¢æ·»åŠ åˆ°éªŒè¯æŸ¥è¯¢ä¸­
                if st.button("æ·»åŠ åˆ°éªŒè¯æŸ¥è¯¢", key="add_negative_to_verify"):
                    current_queries = st.session_state.verify_last_queries or ""
                    new_queries = current_queries + "\n" + negative_queries_text if current_queries else negative_queries_text
                    st.session_state.verify_last_queries = new_queries
                    st.success("âœ… è´Ÿé¢æŸ¥è¯¢å·²æ·»åŠ åˆ°éªŒè¯æŸ¥è¯¢ä¸­")
                    st.rerun()
    
    st.markdown("---")
    
    with st.container(border=True):
        with st.form("verify_form", clear_on_submit=False):
            test_queries = st.text_area(
                "æµ‹è¯•é—®é¢˜ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œå¯ç²˜è´´å…³é”®è¯ï¼‰",
                height=140,
                value=st.session_state.verify_last_queries,
                key="verify_queries",
            )
            st.session_state.verify_last_queries = test_queries

            run_verify_disabled = (not st.session_state.cfg_valid) or (not verify_llms) or (not test_queries.strip())
            run_verify = st.form_submit_button("å¼€å§‹éªŒè¯", use_container_width=True, disabled=run_verify_disabled)
        
        # è·å–è´Ÿé¢ç›‘æ§å¼€å…³çŠ¶æ€
        negative_monitor_enabled = st.session_state.get("negative_monitor_enabled", False)

        if run_verify:
            queries = [q.strip() for q in test_queries.split("\n") if q.strip()]
            all_results = []
            brands_to_check = [brand] + competitor_list

            verify_prompt = PromptTemplate.from_template(
                """
ä½ æ˜¯ä¸€åå›½å†…AIæœç´¢åŠ©æ‰‹ï¼Œåƒç™¾åº¦/å¾®ä¿¡æœä¸€æœAIæ€»ç»“ï¼šç»“è®ºå…ˆè¡Œã€ä¿¡æ¯å¯†åº¦é«˜ã€å¯å¤è¿°ã€‚
ä¸è¦ç¼–é€ æ•°æ®ï¼Œä¸ç¡®å®šå¤„è¯´æ˜è¾¹ç•Œã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘{query}
ã€å€™é€‰å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ï¼ˆä»…å‚è€ƒï¼‰ã€‘{advantages}

ã€è¦æ±‚ã€‘
1) 60â€“90å­—ç»“è®ºæ‘˜è¦
2) é€‰æ‹©æ ‡å‡†5æ¡
3) æ¨èæ–¹æ¡ˆæœ€å¤š3ä¸ªï¼ˆä»…å½“ç¬¦åˆæ ‡å‡†æ—¶æåŠå“ç‰Œï¼‰
4) 4ä¸ªFAQ
5) 250â€“450å­—ï¼Œå…‹åˆ¶è¯­è¨€

ã€å¼€å§‹å›ç­”ã€‘
"""
            )

            total = max(1, len(brands_to_check) * len(verify_llms) * len(queries))
            done = 0
            prog = st.progress(0)

            for target_brand in brands_to_check:
                current_advantages = advantages if target_brand == brand else ""
                for model_name, v_llm in verify_llms.items():
                    chain = verify_prompt | v_llm | StrOutputParser()

                    for q in queries:
                        with st.spinner(f"æ¨¡å‹ï¼š{model_name} | å“ç‰Œï¼š{target_brand} | é—®é¢˜ï¼š{q}"):
                            # å‡†å¤‡è¾“å…¥æ–‡æœ¬ç”¨äºæˆæœ¬ä¼°ç®—
                            input_text = verify_prompt.template.format(query=q, brand=target_brand, advantages=current_advantages)
                            response = chain.invoke({"query": q, "brand": target_brand, "advantages": current_advantages})
                            
                            # è®°å½•æˆæœ¬
                            if v_llm:
                                try:
                                    # model_name æ˜¯ verify_llms å­—å…¸çš„ keyï¼Œå°±æ˜¯ provider åç§°
                                    provider = model_name
                                    model_name_for_cost = getattr(v_llm, 'model_name', None) or getattr(v_llm, 'model', None) or model_defaults(provider)
                                    record_api_cost(
                                        operation_type="éªŒè¯",
                                        provider=provider,
                                        model=model_name_for_cost,
                                        input_text=input_text,
                                        output_text=response,
                                        keyword=q,
                                        brand=target_brand
                                    )
                                except Exception:
                                    pass  # é™é»˜å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹

                        resp_l = response.lower()
                        tb_l = target_brand.lower()
                        count = resp_l.count(tb_l)
                        first_pos = resp_l.find(tb_l)
                        rank = "å‰1/3ï¼ˆä¼˜å…ˆï¼‰" if first_pos != -1 and first_pos < len(response) // 3 else ("ä¸­åæ®µ" if first_pos != -1 else "æœªæåŠ")

                        all_results.append({"é—®é¢˜": q, "æåŠæ¬¡æ•°": count, "ä½ç½®": rank, "å“ç‰Œ": target_brand, "éªŒè¯æ¨¡å‹": model_name})
                        
                        # å¦‚æœæ˜¯è´Ÿé¢ç›‘æ§æ¨¡å¼ï¼Œè¿›è¡Œè´Ÿé¢åˆ†æ
                        if negative_monitor_enabled and target_brand == brand:
                            try:
                                negative_monitor = NegativeMonitor()
                                negative_analysis = negative_monitor.analyze_negative_mentions(
                                    brand=brand,
                                    query=q,
                                    response=response,
                                    mention_count=count
                                )
                                # ä¿å­˜è´Ÿé¢åˆ†æç»“æœ
                                if "negative_analysis_results" not in st.session_state:
                                    st.session_state.negative_analysis_results = []
                                st.session_state.negative_analysis_results.append(negative_analysis)
                            except Exception as e:
                                pass  # é™é»˜å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹

                        done += 1
                        prog.progress(min(done / total, 1.0))

            combined = pd.DataFrame(all_results)
            st.session_state.verify_combined = combined
            # ä¿å­˜åˆ°æ•°æ®åº“
            try:
                storage.save_verify_results(all_results)
            except Exception as e:
                st.warning(f"éªŒè¯å®Œæˆï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{e}")
            st.success("éªŒè¯å®Œæˆ")

    if st.session_state.verify_combined is not None:
        combined = st.session_state.verify_combined

        st.markdown("#### è·¨æ¨¡å‹æåŠæ¬¡æ•°å¯¹æ¯”")
        pivot = combined.pivot_table(index=["é—®é¢˜", "éªŒè¯æ¨¡å‹"], columns="å“ç‰Œ", values="æåŠæ¬¡æ•°", fill_value=0)
        st.dataframe(pivot, use_container_width=True)

        st.markdown("#### å¤šæ¨¡å‹ç«å“æåŠå¯¹æ¯”ï¼ˆå¯è§†åŒ–ï¼‰")
        fig = px.bar(
            combined,
            x="é—®é¢˜",
            y="æåŠæ¬¡æ•°",
            color="å“ç‰Œ",
            facet_col="éªŒè¯æ¨¡å‹",
            barmode="group",
            title="å¤šæ¨¡å‹ç«å“æåŠå¯¹æ¯”ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰",
        )
        st.plotly_chart(fig, use_container_width=True)

        st.markdown("#### å¹³å‡æåŠæ¬¡æ•°ï¼ˆè·¨æ¨¡å‹ï¼‰")
        summary = combined.groupby(["å“ç‰Œ", "éªŒè¯æ¨¡å‹"])["æåŠæ¬¡æ•°"].mean().round(2).unstack()
        st.dataframe(summary, use_container_width=True)

        st.download_button(
            "ä¸‹è½½éªŒè¯æŠ¥è¡¨CSV",
            combined.to_csv(index=False, encoding="utf-8-sig"),
            f"{sanitize_filename(brand,40)}_éªŒè¯ç»“æœ.csv",
            mime="text/csv",
            use_container_width=True,
            key="verify_dl_csv",
        )
        
        # è´Ÿé¢ç›‘æ§åˆ†æç»“æœ
        if negative_monitor_enabled and st.session_state.negative_analysis_results:
            st.markdown("---")
            st.markdown("#### ğŸ›¡ï¸ è´Ÿé¢ç›‘æ§åˆ†æç»“æœ")
            
            negative_results = st.session_state.negative_analysis_results
            negative_df = pd.DataFrame(negative_results)
            
            # é£é™©ç­‰çº§ç»Ÿè®¡
            risk_col1, risk_col2, risk_col3 = st.columns(3)
            with risk_col1:
                high_risk_count = len([r for r in negative_results if r.get("risk_level") == "é«˜"])
                st.metric("é«˜é£é™©", high_risk_count, delta=None, delta_color="inverse")
            with risk_col2:
                medium_risk_count = len([r for r in negative_results if r.get("risk_level") == "ä¸­"])
                st.metric("ä¸­é£é™©", medium_risk_count, delta=None, delta_color="normal")
            with risk_col3:
                low_risk_count = len([r for r in negative_results if r.get("risk_level") == "ä½"])
                st.metric("ä½é£é™©", low_risk_count, delta=None, delta_color="normal")
            
            # æ˜¾ç¤ºè¯¦ç»†åˆ†æç»“æœ
            st.markdown("##### ğŸ“Š è¯¦ç»†åˆ†æ")
            display_cols = ["query", "mention_count", "risk_level", "negative_score", "risk_description"]
            st.dataframe(negative_df[display_cols], use_container_width=True, hide_index=True)
            
            # é«˜é£é™©æŸ¥è¯¢è¯¦æƒ…
            high_risk_queries = [r for r in negative_results if r.get("risk_level") == "é«˜"]
            if high_risk_queries:
                st.markdown("##### âš ï¸ é«˜é£é™©æŸ¥è¯¢è¯¦æƒ…")
                for result in high_risk_queries:
                    with st.expander(f"ğŸ”´ {result.get('query')} - é«˜é£é™©", expanded=False):
                        st.markdown(f"**æŸ¥è¯¢**ï¼š{result.get('query')}")
                        st.markdown(f"**æåŠæ¬¡æ•°**ï¼š{result.get('mention_count')}")
                        st.markdown(f"**è´Ÿé¢å¾—åˆ†**ï¼š{result.get('negative_score')}")
                        st.markdown(f"**é£é™©è¯´æ˜**ï¼š{result.get('risk_description')}")
                        if result.get('negative_keywords'):
                            st.markdown(f"**è´Ÿé¢å…³é”®è¯**ï¼š{', '.join(result.get('negative_keywords'))}")
                        
                        # ç”Ÿæˆæ¾„æ¸…æ¨¡æ¿
                        if st.button(f"ç”Ÿæˆæ¾„æ¸…æ¨¡æ¿", key=f"clarify_{result.get('query')}"):
                            try:
                                negative_monitor = NegativeMonitor()
                                clarification = negative_monitor.generate_clarification_template(
                                    brand=brand,
                                    negative_query=result.get('query'),
                                    advantages=advantages
                                )
                                st.text_area("æ¾„æ¸…æ¨¡æ¿", value=clarification, height=400, key=f"clarification_{result.get('query')}")
                                
                                st.download_button(
                                    "ä¸‹è½½æ¾„æ¸…æ¨¡æ¿",
                                    clarification,
                                    f"{sanitize_filename(brand,40)}_æ¾„æ¸…_{sanitize_filename(result.get('query'),20)}.md",
                                    mime="text/markdown",
                                    use_container_width=True,
                                    key=f"dl_clarify_{result.get('query')}"
                                )
                            except Exception as e:
                                st.error(f"ç”Ÿæˆæ¾„æ¸…æ¨¡æ¿å¤±è´¥ï¼š{e}")
            
            # ä¸‹è½½è´Ÿé¢åˆ†ææŠ¥å‘Š
            negative_csv = negative_df.to_csv(index=False, encoding="utf-8-sig")
            st.download_button(
                "ä¸‹è½½è´Ÿé¢ç›‘æ§æŠ¥å‘Š CSV",
                negative_csv,
                f"{sanitize_filename(brand,40)}_è´Ÿé¢ç›‘æ§æŠ¥å‘Š.csv",
                mime="text/csv",
                use_container_width=True,
                key="negative_dl_csv"
            )

# =======================
# Tab5ï¼šå†å²è®°å½•
# =======================
with tab5:
    st.header("å†å²è®°å½•")
    
    # ç»Ÿè®¡æ•°æ®
    try:
        stats = storage.get_stats(brand)
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("å…³é”®è¯æ€»æ•°", stats["keywords_count"])
        col2.metric("æ–‡ç« æ€»æ•°", stats["articles_count"])
        col3.metric("ä¼˜åŒ–è®°å½•", stats["optimizations_count"])
        col4.metric("éªŒè¯ç»“æœ", stats["verify_results_count"])
    except Exception as e:
        st.error(f"è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥ï¼š{e}")
        stats = {"keywords_count": 0, "articles_count": 0, "optimizations_count": 0, "verify_results_count": 0}
    
    st.markdown("---")
    
    # å†å²æ–‡ç« åˆ—è¡¨
    st.markdown("#### å†å²æ–‡ç« ")
    try:
        articles = storage.get_articles(brand=brand)
        if articles:
            articles_df = pd.DataFrame(articles)
            # åªæ˜¾ç¤ºå…³é”®åˆ—
            display_cols = ["keyword", "platform", "created_at"]
            available_cols = [col for col in display_cols if col in articles_df.columns]
            if available_cols:
                st.dataframe(articles_df[available_cols], use_container_width=True, hide_index=True)
            else:
                st.dataframe(articles_df, use_container_width=True, hide_index=True)
            
            # æ–‡ç« è¯¦æƒ…æŸ¥çœ‹
            if len(articles) > 0:
                selected_idx = st.selectbox("é€‰æ‹©æ–‡ç« æŸ¥çœ‹è¯¦æƒ…", range(len(articles)), format_func=lambda x: f"{articles[x].get('keyword', 'N/A')} - {articles[x].get('platform', 'N/A')}")
                if selected_idx is not None:
                    selected_article = articles[selected_idx]
                    with st.expander("æ–‡ç« å†…å®¹", expanded=True):
                        if selected_article.get("content"):
                            if selected_article.get("platform", "").startswith("GitHub"):
                                st.code(selected_article["content"], language="markdown")
                            else:
                                st.text_area("å†…å®¹", selected_article["content"], height=400, disabled=True, key=f"article_content_{selected_idx}")
        else:
            st.info("æš‚æ— å†å²æ–‡ç« è®°å½•ã€‚")
    except Exception as e:
        st.error(f"è·å–å†å²æ–‡ç« å¤±è´¥ï¼š{e}")
    
    st.markdown("---")
    
    # å†å²ä¼˜åŒ–è®°å½•
    st.markdown("#### å†å²ä¼˜åŒ–è®°å½•")
    try:
        optimizations = storage.get_optimizations(brand=brand)
        if optimizations:
            opt_df = pd.DataFrame(optimizations)
            display_cols = ["platform", "created_at"]
            available_cols = [col for col in display_cols if col in opt_df.columns]
            if available_cols:
                st.dataframe(opt_df[available_cols], use_container_width=True, hide_index=True)
            else:
                st.dataframe(opt_df.head(10), use_container_width=True, hide_index=True)
            
            if len(optimizations) > 0:
                selected_opt_idx = st.selectbox("é€‰æ‹©ä¼˜åŒ–è®°å½•æŸ¥çœ‹è¯¦æƒ…", range(len(optimizations)), format_func=lambda x: f"{optimizations[x].get('platform', 'N/A')} - {optimizations[x].get('created_at', 'N/A')[:10] if optimizations[x].get('created_at') else 'N/A'}")
                if selected_opt_idx is not None:
                    selected_opt = optimizations[selected_opt_idx]
                    with st.expander("ä¼˜åŒ–è¯¦æƒ…", expanded=True):
                        if selected_opt.get("changes"):
                            st.markdown("**å˜æ›´è¯´æ˜**")
                            st.markdown(selected_opt["changes"])
                        if selected_opt.get("optimized_content"):
                            st.markdown("**ä¼˜åŒ–åå†…å®¹**")
                            if "GitHub" in selected_opt.get("platform", ""):
                                st.code(selected_opt["optimized_content"], language="markdown")
                            else:
                                st.text_area("å†…å®¹", selected_opt["optimized_content"], height=300, disabled=True, key=f"opt_content_{selected_opt_idx}")
        else:
            st.info("æš‚æ— ä¼˜åŒ–è®°å½•ã€‚")
    except Exception as e:
        st.error(f"è·å–ä¼˜åŒ–è®°å½•å¤±è´¥ï¼š{e}")
    
    st.markdown("---")
    
    # å†å²éªŒè¯ç»“æœ
    st.markdown("#### å†å²éªŒè¯ç»“æœ")
    try:
        verify_df = storage.get_verify_results(brand=brand)
        if not verify_df.empty:
            st.dataframe(verify_df, use_container_width=True, hide_index=True)
            
            # å¯è§†åŒ–å†å²éªŒè¯ç»“æœ
            if len(verify_df) > 0:
                st.markdown("#### å†å²éªŒè¯ç»“æœå¯è§†åŒ–")
                fig = px.bar(
                    verify_df,
                    x="é—®é¢˜",
                    y="æåŠæ¬¡æ•°",
                    color="å“ç‰Œ",
                    facet_col="éªŒè¯æ¨¡å‹",
                    barmode="group",
                    title="å†å²éªŒè¯ç»“æœå¯¹æ¯”",
                )
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("æš‚æ— éªŒè¯ç»“æœè®°å½•ã€‚")
    except Exception as e:
        st.error(f"è·å–éªŒè¯ç»“æœå¤±è´¥ï¼š{e}")

# =======================
# Tab6ï¼šAI æ•°æ®æŠ¥è¡¨
# =======================
with tab6:
    st.markdown("### ğŸ“Š AI æ•°æ®æŠ¥è¡¨")
    st.caption("è‡ªåŠ¨åŒ–ç›‘æ§ GEO æ•ˆæœï¼Œæ•°æ®é©±åŠ¨ä¼˜åŒ–å†…å®¹ç­–ç•¥")
    
    # è·å–å†å²å…³é”®è¯ç”¨äºè‡ªåŠ¨éªŒè¯
    historical_keywords = storage.get_keywords(brand=brand)
    
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        st.markdown("#### ğŸš€ è‡ªåŠ¨éªŒè¯ä»»åŠ¡")
        st.caption("ä½¿ç”¨å†å²å…³é”®è¯è‡ªåŠ¨è¿›è¡Œå¤šæ¨¡å‹éªŒè¯ï¼Œç”Ÿæˆæ•°æ®æŠ¥è¡¨")
    
    with col2:
        auto_verify_btn = st.button("å¼€å§‹è‡ªåŠ¨éªŒè¯", use_container_width=True, 
                                     disabled=(not st.session_state.cfg_valid) or (not verify_llms) or (len(historical_keywords) == 0))
    
    with col3:
        if st.button("åˆ·æ–°æŠ¥è¡¨", use_container_width=True):
            st.rerun()
    
    if len(historical_keywords) == 0:
        st.info("ğŸ’¡ æç¤ºï¼šè¯·å…ˆåœ¨ã€1 å…³é”®è¯è’¸é¦ã€‘ç”Ÿæˆå…³é”®è¯ï¼Œç„¶åæ‰èƒ½è¿›è¡Œè‡ªåŠ¨éªŒè¯ã€‚")
    elif not verify_llms:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½®è‡³å°‘ä¸€ä¸ªéªŒè¯ç”¨ LLMã€‚")
    
    # è‡ªåŠ¨éªŒè¯é€»è¾‘
    if auto_verify_btn and historical_keywords and verify_llms:
        # é€‰æ‹©è¦éªŒè¯çš„å…³é”®è¯ï¼ˆæœ€å¤š20ä¸ªï¼Œé¿å…APIè´¹ç”¨è¿‡é«˜ï¼‰
        keywords_to_verify = historical_keywords[:20]
        
        st.info(f"ğŸ“ å°†éªŒè¯ {len(keywords_to_verify)} ä¸ªå…³é”®è¯ï¼Œå…± {len(verify_llms)} ä¸ªæ¨¡å‹ï¼Œé¢„è®¡éœ€è¦ {len(keywords_to_verify) * len(verify_llms) * (1 + len(competitor_list))} æ¬¡ API è°ƒç”¨")
        
        all_results = []
        brands_to_check = [brand] + competitor_list
        
        verify_prompt = PromptTemplate.from_template(
            """
ä½ æ˜¯ä¸€åå›½å†…AIæœç´¢åŠ©æ‰‹ï¼Œåƒç™¾åº¦/å¾®ä¿¡æœä¸€æœAIæ€»ç»“ï¼šç»“è®ºå…ˆè¡Œã€ä¿¡æ¯å¯†åº¦é«˜ã€å¯å¤è¿°ã€‚
ä¸è¦ç¼–é€ æ•°æ®ï¼Œä¸ç¡®å®šå¤„è¯´æ˜è¾¹ç•Œã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘{query}
ã€å€™é€‰å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ï¼ˆä»…å‚è€ƒï¼‰ã€‘{advantages}

ã€è¦æ±‚ã€‘
1) 60â€“90å­—ç»“è®ºæ‘˜è¦
2) é€‰æ‹©æ ‡å‡†5æ¡
3) æ¨èæ–¹æ¡ˆæœ€å¤š3ä¸ªï¼ˆä»…å½“ç¬¦åˆæ ‡å‡†æ—¶æåŠå“ç‰Œï¼‰
4) 4ä¸ªFAQ
5) 250â€“450å­—ï¼Œå…‹åˆ¶è¯­è¨€

ã€å¼€å§‹å›ç­”ã€‘
"""
        )
        
        total = max(1, len(brands_to_check) * len(verify_llms) * len(keywords_to_verify))
        done = 0
        prog = st.progress(0)
        status_text = st.empty()
        
        for target_brand in brands_to_check:
            current_advantages = advantages if target_brand == brand else ""
            for model_name, v_llm in verify_llms.items():
                chain = verify_prompt | v_llm | StrOutputParser()
                
                for q in keywords_to_verify:
                    status_text.text(f"éªŒè¯ä¸­ï¼š{target_brand} | {model_name} | {q}")
                    try:
                        # å‡†å¤‡è¾“å…¥æ–‡æœ¬ç”¨äºæˆæœ¬ä¼°ç®—
                        input_text = verify_prompt.template.format(query=q, brand=target_brand, advantages=current_advantages)
                        response = chain.invoke({"query": q, "brand": target_brand, "advantages": current_advantages})
                        
                        # è®°å½•æˆæœ¬
                        if v_llm:
                            try:
                                # model_name æ˜¯ verify_llms å­—å…¸çš„ keyï¼Œå°±æ˜¯ provider åç§°
                                provider = model_name
                                model_name_for_cost = getattr(v_llm, 'model_name', None) or getattr(v_llm, 'model', None) or model_defaults(provider)
                                record_api_cost(
                                    operation_type="éªŒè¯",
                                    provider=provider,
                                    model=model_name_for_cost,
                                    input_text=input_text,
                                    output_text=response,
                                    keyword=q,
                                    brand=target_brand
                                )
                            except Exception:
                                pass  # é™é»˜å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
                        
                        resp_l = response.lower()
                        tb_l = target_brand.lower()
                        count = resp_l.count(tb_l)
                        first_pos = resp_l.find(tb_l)
                        rank = "å‰1/3ï¼ˆä¼˜å…ˆï¼‰" if first_pos != -1 and first_pos < len(response) // 3 else ("ä¸­åæ®µ" if first_pos != -1 else "æœªæåŠ")
                        
                        all_results.append({"é—®é¢˜": q, "æåŠæ¬¡æ•°": count, "ä½ç½®": rank, "å“ç‰Œ": target_brand, "éªŒè¯æ¨¡å‹": model_name})
                    except Exception as e:
                        st.warning(f"éªŒè¯å¤±è´¥ï¼š{target_brand} | {model_name} | {q} - {str(e)}")
                    
                    done += 1
                    prog.progress(min(done / total, 1.0))
        
        # ä¿å­˜éªŒè¯ç»“æœ
        if all_results:
            try:
                storage.save_verify_results(all_results)
                st.success(f"âœ… è‡ªåŠ¨éªŒè¯å®Œæˆï¼å…±éªŒè¯ {len(all_results)} æ¡è®°å½•")
            except Exception as e:
                st.warning(f"éªŒè¯å®Œæˆï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{e}")
        
        status_text.empty()
        prog.empty()
    
    # è·å–æ‰€æœ‰éªŒè¯æ•°æ®ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    verify_df = storage.get_verify_results(brand=brand, include_timestamp=True)
    
    if verify_df.empty:
        st.info("ğŸ“Š æš‚æ— éªŒè¯æ•°æ®ã€‚è¯·å…ˆè¿è¡Œè‡ªåŠ¨éªŒè¯ä»»åŠ¡æˆ–æ‰‹åŠ¨éªŒè¯ã€‚")
    else:
        # æ•°æ®æ¦‚è§ˆ
        st.markdown("---")
        st.markdown("#### ğŸ“ˆ æ•°æ®æ¦‚è§ˆ")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            total_verifications = len(verify_df)
            st.metric("æ€»éªŒè¯æ¬¡æ•°", total_verifications)
        
        with col2:
            avg_mentions = verify_df[verify_df["å“ç‰Œ"] == brand]["æåŠæ¬¡æ•°"].mean() if len(verify_df[verify_df["å“ç‰Œ"] == brand]) > 0 else 0
            st.metric("å¹³å‡æåŠæ¬¡æ•°", f"{avg_mentions:.2f}")
        
        with col3:
            if "éªŒè¯æ—¶é—´" in verify_df.columns:
                latest_date = verify_df["éªŒè¯æ—¶é—´"].max()
                st.metric("æœ€æ–°éªŒè¯æ—¶é—´", latest_date.strftime("%Y-%m-%d") if pd.notna(latest_date) else "N/A")
            else:
                st.metric("æœ€æ–°éªŒè¯æ—¶é—´", "N/A")
        
        with col4:
            unique_queries = verify_df["é—®é¢˜"].nunique()
            st.metric("å·²éªŒè¯å…³é”®è¯", unique_queries)
        
        # 1. æåŠç‡è¶‹åŠ¿å›¾
        if "éªŒè¯æ—¶é—´" in verify_df.columns and len(verify_df) > 0:
            st.markdown("---")
            st.markdown("#### ğŸ“Š æåŠç‡è¶‹åŠ¿å›¾")
            
            # æŒ‰æ—¥æœŸèšåˆæ•°æ®
            brand_df = verify_df[verify_df["å“ç‰Œ"] == brand].copy()
            if len(brand_df) > 0:
                brand_df["æ—¥æœŸ"] = brand_df["éªŒè¯æ—¶é—´"].dt.date
                daily_mentions = brand_df.groupby(["æ—¥æœŸ", "éªŒè¯æ¨¡å‹"])["æåŠæ¬¡æ•°"].mean().reset_index()
                daily_mentions["æ—¥æœŸ"] = pd.to_datetime(daily_mentions["æ—¥æœŸ"])
                
                fig_trend = px.line(
                    daily_mentions,
                    x="æ—¥æœŸ",
                    y="æåŠæ¬¡æ•°",
                    color="éªŒè¯æ¨¡å‹",
                    title="å“ç‰ŒæåŠç‡è¶‹åŠ¿ï¼ˆæŒ‰æ—¥æœŸï¼‰",
                    labels={"æåŠæ¬¡æ•°": "å¹³å‡æåŠæ¬¡æ•°", "æ—¥æœŸ": "æ—¥æœŸ"},
                    markers=True
                )
                fig_trend.update_layout(hovermode='x unified')
                st.plotly_chart(fig_trend, use_container_width=True)
        
        # 2. å¹³å°è´¡çŒ®åº¦åˆ†æï¼ˆåŸºäºæ–‡ç« å¹³å°ï¼‰
        st.markdown("---")
        st.markdown("#### ğŸŒ å¹³å°è´¡çŒ®åº¦åˆ†æ")
        
        articles = storage.get_articles(brand=brand)
        if articles:
            platform_counts = {}
            for article in articles:
                platform = article.get("platform", "æœªçŸ¥")
                platform_counts[platform] = platform_counts.get(platform, 0) + 1
            
            platform_df = pd.DataFrame(list(platform_counts.items()), columns=["å¹³å°", "æ–‡ç« æ•°é‡"])
            platform_df = platform_df.sort_values("æ–‡ç« æ•°é‡", ascending=False)
            
            fig_platform = px.bar(
                platform_df,
                x="å¹³å°",
                y="æ–‡ç« æ•°é‡",
                title="å„å¹³å°æ–‡ç« æ•°é‡åˆ†å¸ƒ",
                labels={"æ–‡ç« æ•°é‡": "æ–‡ç« æ•°é‡", "å¹³å°": "å‘å¸ƒå¹³å°"},
                color="æ–‡ç« æ•°é‡",
                color_continuous_scale="Blues"
            )
            st.plotly_chart(fig_platform, use_container_width=True)
        else:
            st.info("æš‚æ— æ–‡ç« æ•°æ®ã€‚")
        
        # è¯é¢˜é›†ç¾¤åˆ†ææ¨¡å—
        st.markdown("---")
        st.markdown("#### ğŸ¯ è¯é¢˜é›†ç¾¤åˆ†æ")
        st.caption("åŸºäºå†å²å…³é”®è¯ç”Ÿæˆè¯é¢˜é›†ç¾¤ï¼Œåˆ†æå†…å®¹è¦†ç›–æƒ…å†µï¼Œå‘ç°å†…å®¹ç›²åŒº")
        
        # åˆå§‹åŒ–è¯é¢˜é›†ç¾¤åˆ†æç›¸å…³çŠ¶æ€
        ss_init("tab6_topic_clusters", [])
        ss_init("tab6_cluster_relationships", [])
        ss_init("tab6_cluster_stats", None)
        ss_init("tab6_content_planning", None)
        
        with st.container(border=True):
            tab6_cluster_col1, tab6_cluster_col2 = st.columns([2, 1])
            
            with tab6_cluster_col1:
                tab6_cluster_count = st.slider(
                    "è¯é¢˜é›†ç¾¤æ•°é‡",
                    3,
                    10,
                    5,
                    key="tab6_cluster_count",
                    help="å»ºè®®èŒƒå›´ï¼š3-10ä¸ªè¯é¢˜é›†ç¾¤"
                )
            
            with tab6_cluster_col2:
                tab6_generate_clusters_btn = st.button(
                    "ğŸš€ ç”Ÿæˆè¯é¢˜é›†ç¾¤åˆ†æ",
                    use_container_width=True,
                    disabled=(not st.session_state.cfg_valid) or (gen_llm is None) or (len(historical_keywords) == 0),
                    key="tab6_generate_clusters_btn"
                )
        
        # æ‰§è¡Œè¯é¢˜èšç±»åˆ†æ
        if tab6_generate_clusters_btn and gen_llm and historical_keywords:
            topic_cluster = TopicCluster()
            with st.spinner(f"æ­£åœ¨åˆ†æè¯é¢˜é›†ç¾¤ï¼ˆç›®æ ‡ï¼š{tab6_cluster_count} ä¸ªï¼‰..."):
                try:
                    cluster_chain = PromptTemplate.from_template("{input}") | gen_llm | StrOutputParser()
                    cluster_result = topic_cluster.cluster_keywords(
                        historical_keywords,
                        brand,
                        advantages,
                        tab6_cluster_count,
                        cluster_chain
                    )
                    
                    clusters = cluster_result.get("clusters", [])
                    relationships = cluster_result.get("relationships", [])
                    cluster_stats = cluster_result.get("cluster_stats", {})
                    
                    st.session_state.tab6_topic_clusters = clusters
                    st.session_state.tab6_cluster_relationships = relationships
                    st.session_state.tab6_cluster_stats = cluster_stats
                    
                    if clusters:
                        st.success(f"âœ… è¯é¢˜é›†ç¾¤åˆ†æå®Œæˆï¼å…±ç”Ÿæˆ {len(clusters)} ä¸ªè¯é¢˜é›†ç¾¤")
                        
                        # åˆ†æè¦†ç›–æƒ…å†µ
                        coverage = topic_cluster.analyze_cluster_coverage(clusters, historical_keywords)
                        
                        # ç”Ÿæˆå†…å®¹è§„åˆ’å»ºè®®
                        with st.spinner("æ­£åœ¨ç”Ÿæˆå†…å®¹è§„åˆ’å»ºè®®..."):
                            try:
                                planning_result = topic_cluster.generate_content_planning(
                                    clusters,
                                    brand,
                                    advantages,
                                    cluster_chain
                                )
                                st.session_state.tab6_content_planning = planning_result
                            except Exception as e:
                                st.warning(f"å†…å®¹è§„åˆ’ç”Ÿæˆå¤±è´¥ï¼š{e}")
                    else:
                        st.warning("âš ï¸ æœªç”Ÿæˆè¯é¢˜é›†ç¾¤ï¼Œè¯·æ£€æŸ¥è¾“å…¥æˆ–é‡è¯•")
                except Exception as e:
                    st.error(f"è¯é¢˜é›†ç¾¤åˆ†æå¤±è´¥ï¼š{e}")
        
        # æ˜¾ç¤ºè¯é¢˜é›†ç¾¤åˆ†æç»“æœ
        if st.session_state.tab6_topic_clusters:
            clusters = st.session_state.tab6_topic_clusters
            relationships = st.session_state.tab6_cluster_relationships
            cluster_stats = st.session_state.tab6_cluster_stats
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            if cluster_stats:
                st.markdown("##### ğŸ“Š è¯é¢˜é›†ç¾¤ç»Ÿè®¡")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("è¯é¢˜æ€»æ•°", cluster_stats.get("total_clusters", 0))
                with col2:
                    st.metric("å…³é”®è¯æ€»æ•°", cluster_stats.get("total_keywords", 0))
                with col3:
                    st.metric("å¹³å‡å…³é”®è¯/è¯é¢˜", f"{cluster_stats.get('avg_keywords_per_cluster', 0):.1f}")
                with col4:
                    st.metric("æœ€å¤§è¯é¢˜å…³é”®è¯æ•°", cluster_stats.get("max_keywords", 0))
            
            # è¯é¢˜åˆ†å¸ƒå¯è§†åŒ–
            if clusters:
                st.markdown("##### ğŸ“ˆ è¯é¢˜åˆ†å¸ƒå›¾")
                cluster_names = [c.get("name", "N/A") for c in clusters]
                cluster_counts = [c.get("keyword_count", 0) for c in clusters]
                
                cluster_dist_df = pd.DataFrame({
                    "è¯é¢˜": cluster_names,
                    "å…³é”®è¯æ•°é‡": cluster_counts
                })
                cluster_dist_df = cluster_dist_df.sort_values("å…³é”®è¯æ•°é‡", ascending=False)
                
                fig_cluster_dist = px.bar(
                    cluster_dist_df,
                    x="è¯é¢˜",
                    y="å…³é”®è¯æ•°é‡",
                    title="å„è¯é¢˜é›†ç¾¤å…³é”®è¯æ•°é‡åˆ†å¸ƒ",
                    labels={"å…³é”®è¯æ•°é‡": "å…³é”®è¯æ•°é‡", "è¯é¢˜": "è¯é¢˜é›†ç¾¤"},
                    color="å…³é”®è¯æ•°é‡",
                    color_continuous_scale="Viridis"
                )
                fig_cluster_dist.update_xaxes(tickangle=-45)
                st.plotly_chart(fig_cluster_dist, use_container_width=True)
            
            # æ˜¾ç¤ºè¯é¢˜é›†ç¾¤åˆ—è¡¨
            st.markdown("##### ğŸ“‹ è¯é¢˜é›†ç¾¤è¯¦æƒ…")
            for cluster in clusters:
                with st.expander(f"**{cluster.get('name', 'N/A')}** - {cluster.get('keyword_count', 0)} ä¸ªå…³é”®è¯ | ä¼˜å…ˆçº§ï¼š{cluster.get('priority', 'ä¸­')}", expanded=False):
                    st.markdown(f"**æè¿°**ï¼š{cluster.get('description', 'æ— æè¿°')}")
                    keywords_list = cluster.get('keywords', [])
                    if keywords_list:
                        st.markdown(f"**å…³é”®è¯**ï¼š{', '.join(keywords_list[:15])}{' ...' if len(keywords_list) > 15 else ''}")
                        st.caption(f"å…± {len(keywords_list)} ä¸ªå…³é”®è¯")
            
            # æ˜¾ç¤ºè¯é¢˜å…³è”å…³ç³»
            if relationships:
                st.markdown("##### ğŸ”— è¯é¢˜å…³è”å…³ç³»")
                rel_df = pd.DataFrame(relationships)
                st.dataframe(rel_df, use_container_width=True, hide_index=True)
            
            # æ˜¾ç¤ºå†…å®¹è§„åˆ’å»ºè®®
            if st.session_state.tab6_content_planning:
                planning = st.session_state.tab6_content_planning
                st.markdown("##### ğŸ’¡ å†…å®¹è§„åˆ’å»ºè®®")
                
                # å†…å®¹ç›²åŒºåˆ†æ
                content_gaps = planning.get("content_gaps", [])
                if content_gaps:
                    st.markdown("**ğŸ“Œ å†…å®¹ç›²åŒºåˆ†æ**")
                    gaps_df = pd.DataFrame(content_gaps)
                    st.dataframe(gaps_df, use_container_width=True, hide_index=True)
                
                # å†…å®¹ä¼˜å…ˆçº§
                content_priorities = planning.get("content_priorities", [])
                if content_priorities:
                    st.markdown("**ğŸ¯ å†…å®¹ä¼˜å…ˆçº§**")
                    priority_df = pd.DataFrame(content_priorities)
                    priority_df = priority_df.sort_values("priority", key=lambda x: x.map({"é«˜": 3, "ä¸­": 2, "ä½": 1}), ascending=False)
                    st.dataframe(priority_df, use_container_width=True, hide_index=True)
                
                # å†…å®¹å»ºè®®
                content_suggestions = planning.get("content_suggestions", [])
                if content_suggestions:
                    with st.expander("ğŸ“ è¯¦ç»†å†…å®¹å»ºè®®", expanded=False):
                        for suggestion in content_suggestions:
                            st.markdown(f"**{suggestion.get('cluster_name', 'N/A')}**")
                            st.markdown(f"- **å†…å®¹ç±»å‹**ï¼š{', '.join(suggestion.get('content_types', []))}")
                            st.markdown(f"- **å‘å¸ƒå¹³å°**ï¼š{', '.join(suggestion.get('platforms', []))}")
                            st.markdown(f"- **å…³é”®è¯ç­–ç•¥**ï¼š{suggestion.get('keyword_strategy', 'N/A')}")
                            ideas = suggestion.get('content_ideas', [])
                            if ideas:
                                st.markdown(f"- **å†…å®¹åˆ›æ„**ï¼š{', '.join(ideas[:3])}")
                            st.markdown("---")
        
        # ROI åˆ†æä¸æˆæœ¬ä¼˜åŒ–æ¨¡å—
        st.markdown("---")
        st.markdown("#### ğŸ’° ROI åˆ†æä¸æˆæœ¬ä¼˜åŒ–")
        st.caption("é‡åŒ– GEO æŠ•å…¥äº§å‡ºæ¯”ï¼Œä¼˜åŒ–æˆæœ¬ç»“æ„ï¼Œæ•°æ®é©±åŠ¨å†³ç­–")
        
        # åˆå§‹åŒ– ROI åˆ†æå™¨
        roi_analyzer = ROIAnalyzer()
        
        # è·å– API è°ƒç”¨è®°å½•
        api_calls_df = storage.get_api_calls(brand=brand)
        
        if api_calls_df.empty:
            st.info("ğŸ“Š æš‚æ—  API è°ƒç”¨è®°å½•ã€‚å¼€å§‹ä½¿ç”¨å·¥å…·åï¼Œæˆæœ¬æ•°æ®å°†è‡ªåŠ¨è®°å½•ã€‚")
        else:
            # æˆæœ¬åˆ†æ
            cost_analysis = roi_analyzer.analyze_costs(api_calls_df, verify_df)
            
            # æˆæœ¬æ¦‚è§ˆ
            st.markdown("##### ğŸ“Š æˆæœ¬æ¦‚è§ˆ")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æ€»æˆæœ¬(CNY)", f"Â¥{cost_analysis['total_cost_cny']:.2f}")
            with col2:
                st.metric("æ€»æˆæœ¬(USD)", f"${cost_analysis['total_cost_usd']:.2f}")
            with col3:
                st.metric("æ€»Tokenæ•°", f"{cost_analysis['total_tokens']:,}")
            with col4:
                st.metric("APIè°ƒç”¨æ¬¡æ•°", cost_analysis['total_calls'])
            
            # æˆæœ¬è¶‹åŠ¿å›¾
            if cost_analysis.get('daily_costs'):
                st.markdown("##### ğŸ“ˆ æˆæœ¬è¶‹åŠ¿")
                daily_df = pd.DataFrame(cost_analysis['daily_costs'])
                daily_df['date'] = pd.to_datetime(daily_df['date'])
                
                fig_cost_trend = px.line(
                    daily_df,
                    x='date',
                    y='cost_cny',
                    title='æ¯æ—¥æˆæœ¬è¶‹åŠ¿',
                    labels={'cost_cny': 'æˆæœ¬(CNY)', 'date': 'æ—¥æœŸ'},
                    markers=True
                )
                fig_cost_trend.update_layout(hovermode='x unified')
                st.plotly_chart(fig_cost_trend, use_container_width=True)
            
            # æˆæœ¬åˆ†å¸ƒåˆ†æ
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("##### ğŸ’¼ æŒ‰æä¾›å•†ç»Ÿè®¡")
                cost_by_provider = cost_analysis.get('cost_by_provider', {})
                if cost_by_provider:
                    provider_df = pd.DataFrame([
                        {
                            "æä¾›å•†": provider,
                            "æˆæœ¬(CNY)": data['cost_cny'],
                            "è°ƒç”¨æ¬¡æ•°": data['calls'],
                            "Tokenæ•°": data['tokens']
                        }
                        for provider, data in cost_by_provider.items()
                    ])
                    provider_df = provider_df.sort_values("æˆæœ¬(CNY)", ascending=False)
                    
                    fig_provider = px.pie(
                        provider_df,
                        values="æˆæœ¬(CNY)",
                        names="æä¾›å•†",
                        title="æˆæœ¬åˆ†å¸ƒï¼ˆæŒ‰æä¾›å•†ï¼‰"
                    )
                    st.plotly_chart(fig_provider, use_container_width=True)
                else:
                    st.info("æš‚æ— æä¾›å•†æ•°æ®")
            
            with col2:
                st.markdown("##### ğŸ”§ æŒ‰æ“ä½œç±»å‹ç»Ÿè®¡")
                cost_by_operation = cost_analysis.get('cost_by_operation', {})
                if cost_by_operation:
                    operation_df = pd.DataFrame([
                        {
                            "æ“ä½œç±»å‹": op_type,
                            "æˆæœ¬(CNY)": data['cost_cny'],
                            "è°ƒç”¨æ¬¡æ•°": data['calls']
                        }
                        for op_type, data in cost_by_operation.items()
                    ])
                    operation_df = operation_df.sort_values("æˆæœ¬(CNY)", ascending=False)
                    
                    fig_operation = px.bar(
                        operation_df,
                        x="æ“ä½œç±»å‹",
                        y="æˆæœ¬(CNY)",
                        title="æˆæœ¬åˆ†å¸ƒï¼ˆæŒ‰æ“ä½œç±»å‹ï¼‰",
                        color="æˆæœ¬(CNY)",
                        color_continuous_scale="Reds"
                    )
                    st.plotly_chart(fig_operation, use_container_width=True)
                else:
                    st.info("æš‚æ— æ“ä½œç±»å‹æ•°æ®")
            
            # ROI åˆ†æ
            roi_analysis = cost_analysis.get('roi_analysis', {})
            if roi_analysis and roi_analysis.get('total_cost', 0) > 0:
                st.markdown("##### ğŸ“ˆ ROI åˆ†æ")
                roi_col1, roi_col2, roi_col3, roi_col4 = st.columns(4)
                with roi_col1:
                    st.metric("æ€»æŠ•å…¥æˆæœ¬", f"Â¥{roi_analysis.get('total_cost', 0):.2f}")
                with roi_col2:
                    st.metric("æ€»æåŠæ¬¡æ•°", roi_analysis.get('total_mentions', 0))
                with roi_col3:
                    st.metric("ä¼°ç®—ä»·å€¼", f"Â¥{roi_analysis.get('estimated_value', 0):.2f}")
                with roi_col4:
                    roi_ratio = roi_analysis.get('roi_ratio', 0)
                    st.metric("ROI", f"{roi_ratio:.1f}%", delta=f"Â¥{roi_analysis.get('roi_value', 0):.2f}")
                
                # å…³é”®è¯ ROI æ’å
                keyword_roi = roi_analysis.get('keyword_roi', {})
                if keyword_roi:
                    st.markdown("##### ğŸ¯ å…³é”®è¯ ROI æ’å")
                    keyword_roi_df = pd.DataFrame([
                        {
                            "å…³é”®è¯": kw,
                            "æˆæœ¬(CNY)": data['cost'],
                            "æåŠæ¬¡æ•°": data['mentions'],
                            "ä¼°ç®—ä»·å€¼(CNY)": data['value'],
                            "ROI(%)": data['roi']
                        }
                        for kw, data in keyword_roi.items()
                    ])
                    keyword_roi_df = keyword_roi_df.sort_values("ROI(%)", ascending=False)
                    
                    # æ˜¾ç¤º Top 10
                    top_roi = keyword_roi_df.head(10)
                    st.dataframe(top_roi, use_container_width=True, hide_index=True)
                    
                    with st.expander("æŸ¥çœ‹å®Œæ•´å…³é”®è¯ ROI æ’å", expanded=False):
                        st.dataframe(keyword_roi_df, use_container_width=True, hide_index=True)
            
            # æˆæœ¬ä¼˜åŒ–å»ºè®®
            st.markdown("##### ğŸ’¡ æˆæœ¬ä¼˜åŒ–å»ºè®®")
            suggestions = roi_analyzer.get_optimization_suggestions(cost_analysis)
            
            for suggestion in suggestions:
                priority_color = {
                    "é«˜": "ğŸ”´",
                    "ä¸­": "ğŸŸ¡",
                    "ä½": "ğŸŸ¢"
                }.get(suggestion.get('priority', 'ä½'), 'âšª')
                
                with st.container(border=True):
                    st.markdown(f"**{priority_color} {suggestion.get('title', 'N/A')}**")
                    st.markdown(suggestion.get('description', ''))
                    
                    if 'savings_estimate' in suggestion:
                        st.info(f"ğŸ’µ é¢„è®¡å¯èŠ‚çœï¼šÂ¥{suggestion['savings_estimate']:.2f}")
                    
                    if 'keywords' in suggestion:
                        st.markdown(f"**ç›¸å…³å…³é”®è¯**ï¼š{', '.join(suggestion['keywords'])}")
            
            # æœªæ¥æˆæœ¬é¢„æµ‹
            st.markdown("##### ğŸ”® æœªæ¥æˆæœ¬é¢„æµ‹")
            future_cost = roi_analyzer.estimate_future_cost(api_calls_df, days=30)
            
            pred_col1, pred_col2, pred_col3 = st.columns(3)
            with pred_col1:
                st.metric("é¢„è®¡æ—¥å‡æˆæœ¬", f"Â¥{future_cost.get('estimated_daily_cost_cny', 0):.2f}")
            with pred_col2:
                st.metric("é¢„è®¡30å¤©æ€»æˆæœ¬", f"Â¥{future_cost.get('estimated_total_cost_cny', 0):.2f}")
            with pred_col3:
                confidence = future_cost.get('confidence', 'ä½')
                confidence_icon = {"é«˜": "ğŸŸ¢", "ä¸­": "ğŸŸ¡", "ä½": "ğŸ”´"}.get(confidence, "âšª")
                st.metric("é¢„æµ‹ç½®ä¿¡åº¦", f"{confidence_icon} {confidence}")
            
            if future_cost.get('data_points', 0) < 3:
                st.warning("âš ï¸ æ•°æ®ç‚¹è¾ƒå°‘ï¼Œé¢„æµ‹å‡†ç¡®æ€§è¾ƒä½ã€‚å»ºè®®ç§¯ç´¯æ›´å¤šæ•°æ®åå†æŸ¥çœ‹é¢„æµ‹ã€‚")
            
            # å¯¼å‡ºæˆæœ¬æ•°æ®
            st.markdown("##### ğŸ“¥ å¯¼å‡ºæ•°æ®")
            export_col1, export_col2 = st.columns(2)
            with export_col1:
                if not api_calls_df.empty:
                    api_calls_csv = api_calls_df.to_csv(index=False, encoding="utf-8-sig")
                    st.download_button(
                        "ä¸‹è½½ API è°ƒç”¨è®°å½• CSV",
                        api_calls_csv,
                        f"{sanitize_filename(brand,40)}_api_calls.csv",
                        "text/csv",
                        use_container_width=True,
                        key="export_api_calls"
                    )
            with export_col2:
                # ç”Ÿæˆæˆæœ¬æŠ¥å‘Š
                cost_report = f"""
# GEO æˆæœ¬åˆ†ææŠ¥å‘Š

## æˆæœ¬æ¦‚è§ˆ
- æ€»æˆæœ¬(CNY): Â¥{cost_analysis['total_cost_cny']:.2f}
- æ€»æˆæœ¬(USD): ${cost_analysis['total_cost_usd']:.2f}
- æ€»Tokenæ•°: {cost_analysis['total_tokens']:,}
- APIè°ƒç”¨æ¬¡æ•°: {cost_analysis['total_calls']}

## ROI åˆ†æ
"""
                if roi_analysis:
                    cost_report += f"""
- æ€»æŠ•å…¥æˆæœ¬: Â¥{roi_analysis.get('total_cost', 0):.2f}
- æ€»æåŠæ¬¡æ•°: {roi_analysis.get('total_mentions', 0)}
- ä¼°ç®—ä»·å€¼: Â¥{roi_analysis.get('estimated_value', 0):.2f}
- ROI: {roi_analysis.get('roi_ratio', 0):.1f}%
"""
                cost_report += f"""
## ä¼˜åŒ–å»ºè®®
"""
                for suggestion in suggestions:
                    cost_report += f"""
- [{suggestion.get('priority', 'ä½')}] {suggestion.get('title', 'N/A')}
  {suggestion.get('description', '')}
"""
                
                st.download_button(
                    "ä¸‹è½½æˆæœ¬åˆ†ææŠ¥å‘Š",
                    cost_report,
                    f"{sanitize_filename(brand,40)}_cost_report.md",
                    "text/markdown",
                    use_container_width=True,
                    key="export_cost_report"
                )
        
        # 3. å†…å®¹è´¨é‡æŒ‡æ ‡åˆ†æ
        st.markdown("---")
        st.markdown("#### ğŸ“ˆ å†…å®¹è´¨é‡æŒ‡æ ‡åˆ†æ")
        st.caption("åˆ†æå†…å®¹çš„ä¿¡ä»»åº¦ã€æƒå¨æ€§ã€å‚ä¸åº¦ç­‰å…³é”®æŒ‡æ ‡ï¼Œé‡åŒ–å†…å®¹è´¨é‡")
        
        # åˆå§‹åŒ–æŒ‡æ ‡åˆ†æå™¨
        metrics_analyzer = ContentMetricsAnalyzer()
        
        # è·å–å†å²æ–‡ç« 
        try:
            articles = storage.get_articles(brand=brand)
            
            if articles and len(articles) > 0:
                # åˆ†ææ‰€æœ‰æ–‡ç« 
                with st.spinner("æ­£åœ¨åˆ†æå†…å®¹è´¨é‡æŒ‡æ ‡..."):
                    metrics_results = metrics_analyzer.analyze_batch(articles, brand)
                    summary = metrics_analyzer.get_metrics_summary(metrics_results)
                
                # æ˜¾ç¤ºæŒ‡æ ‡æ¦‚è§ˆ
                st.markdown("##### ğŸ“Š æŒ‡æ ‡æ¦‚è§ˆ")
                metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
                
                with metric_col1:
                    st.metric(
                        "å¹³å‡ Trust Density",
                        f"{summary['avg_trust_density']:.2f}",
                        help="æ¯100å­—ä¿¡ä»»ä¿¡å·æ•°ï¼ˆæ¥æºå ä½ã€æ•°æ®ã€æ¡ˆä¾‹ç­‰ï¼‰"
                    )
                
                with metric_col2:
                    st.metric(
                        "å¹³å‡ Citation Share",
                        f"{summary['avg_citation_share']:.2f}%",
                        help="å“ç‰Œå¼•ç”¨æ¯”ä¾‹ï¼ˆå“ç‰ŒæåŠæ¬¡æ•° / æ€»æåŠæ¬¡æ•°ï¼‰"
                    )
                
                with metric_col3:
                    st.metric(
                        "å¹³å‡ Authority Score",
                        f"{summary['avg_authority_score']:.2f}",
                        help="æƒå¨æ€§å¾—åˆ†ï¼ˆåŸºäºæ¥æºå ä½æ•°é‡ï¼Œ0-100ï¼‰"
                    )
                
                with metric_col4:
                    st.metric(
                        "å¹³å‡ Engagement Potential",
                        f"{summary['avg_engagement_potential']:.2f}",
                        help="å‚ä¸åº¦æ½œåŠ›ï¼ˆåŸºäºç»“æ„åŒ–ç¨‹åº¦ï¼Œ0-100ï¼‰"
                    )
                
                # è¯¦ç»†æŒ‡æ ‡åˆ†æ
                st.markdown("##### ğŸ“‹ è¯¦ç»†æŒ‡æ ‡åˆ†æ")
                
                # åˆ›å»ºæŒ‡æ ‡æ•°æ®æ¡†
                metrics_df = pd.DataFrame([
                    {
                        "å…³é”®è¯": r.get('keyword', ''),
                        "å¹³å°": r.get('platform', ''),
                        "Trust Density": r.get('trust_density', 0),
                        "Citation Share (%)": r.get('citation_share', 0),
                        "Authority Score": r.get('authority_score', 0),
                        "Engagement Potential": r.get('engagement_potential', 0),
                        "ä¿¡ä»»ä¿¡å·æ•°": r.get('trust_signals', 0),
                        "æ¥æºå ä½": r.get('citations', 0),
                        "å“ç‰ŒæåŠ": r.get('brand_mentions', 0),
                    }
                    for r in metrics_results
                ])
                
                if not metrics_df.empty:
                    # æ˜¾ç¤ºæŒ‡æ ‡è¡¨æ ¼
                    st.dataframe(metrics_df, use_container_width=True, hide_index=True)
                    
                    # æŒ‡æ ‡å¯è§†åŒ–
                    viz_col1, viz_col2 = st.columns(2)
                    
                    with viz_col1:
                        # Trust Density åˆ†å¸ƒ
                        fig_trust = px.histogram(
                            metrics_df,
                            x="Trust Density",
                            nbins=20,
                            title="Trust Density åˆ†å¸ƒ",
                            labels={"Trust Density": "Trust Density", "count": "æ–‡ç« æ•°é‡"},
                            color_discrete_sequence=["#2563EB"]
                        )
                        st.plotly_chart(fig_trust, use_container_width=True)
                    
                    with viz_col2:
                        # Authority Score åˆ†å¸ƒ
                        fig_authority = px.histogram(
                            metrics_df,
                            x="Authority Score",
                            nbins=20,
                            title="Authority Score åˆ†å¸ƒ",
                            labels={"Authority Score": "Authority Score", "count": "æ–‡ç« æ•°é‡"},
                            color_discrete_sequence=["#10B981"]
                        )
                        st.plotly_chart(fig_authority, use_container_width=True)
                    
                    # æŒ‡æ ‡çƒ­åŠ›å›¾ï¼ˆæŒ‰å¹³å°ï¼‰
                    if len(metrics_df['å¹³å°'].unique()) > 1:
                        st.markdown("##### ğŸ”¥ å¹³å°æŒ‡æ ‡çƒ­åŠ›å›¾")
                        platform_metrics = metrics_df.groupby('å¹³å°').agg({
                            'Trust Density': 'mean',
                            'Citation Share (%)': 'mean',
                            'Authority Score': 'mean',
                            'Engagement Potential': 'mean',
                        }).round(2)
                        
                        fig_heatmap = px.imshow(
                            platform_metrics.T,
                            labels=dict(x="å¹³å°", y="æŒ‡æ ‡", color="å¾—åˆ†"),
                            title="å„å¹³å°å¹³å‡æŒ‡æ ‡çƒ­åŠ›å›¾",
                            color_continuous_scale="RdYlGn",
                            aspect="auto"
                        )
                        st.plotly_chart(fig_heatmap, use_container_width=True)
                    
                    # æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ
                    st.markdown("##### ğŸ”— æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ")
                    correlation_cols = ['Trust Density', 'Citation Share (%)', 'Authority Score', 'Engagement Potential']
                    corr_df = metrics_df[correlation_cols].corr()
                    
                    fig_corr = px.imshow(
                        corr_df,
                        labels=dict(x="æŒ‡æ ‡", y="æŒ‡æ ‡", color="ç›¸å…³ç³»æ•°"),
                        title="æŒ‡æ ‡ç›¸å…³æ€§çŸ©é˜µ",
                        color_continuous_scale="RdBu",
                        aspect="auto",
                        text_auto=True
                    )
                    st.plotly_chart(fig_corr, use_container_width=True)
                    
                    # Top å†…å®¹æ’å
                    st.markdown("##### ğŸ† Top å†…å®¹æ’å")
                    top_col1, top_col2, top_col3, top_col4 = st.columns(4)
                    
                    with top_col1:
                        top_trust = metrics_df.nlargest(5, 'Trust Density')[['å…³é”®è¯', 'å¹³å°', 'Trust Density']]
                        st.markdown("**Top 5 Trust Density**")
                        st.dataframe(top_trust, use_container_width=True, hide_index=True)
                    
                    with top_col2:
                        top_citation = metrics_df.nlargest(5, 'Citation Share (%)')[['å…³é”®è¯', 'å¹³å°', 'Citation Share (%)']]
                        st.markdown("**Top 5 Citation Share**")
                        st.dataframe(top_citation, use_container_width=True, hide_index=True)
                    
                    with top_col3:
                        top_authority = metrics_df.nlargest(5, 'Authority Score')[['å…³é”®è¯', 'å¹³å°', 'Authority Score']]
                        st.markdown("**Top 5 Authority Score**")
                        st.dataframe(top_authority, use_container_width=True, hide_index=True)
                    
                    with top_col4:
                        top_engagement = metrics_df.nlargest(5, 'Engagement Potential')[['å…³é”®è¯', 'å¹³å°', 'Engagement Potential']]
                        st.markdown("**Top 5 Engagement Potential**")
                        st.dataframe(top_engagement, use_container_width=True, hide_index=True)
                    
                    # å¯¼å‡ºæŒ‡æ ‡æ•°æ®
                    st.markdown("##### ğŸ“¥ å¯¼å‡ºæŒ‡æ ‡æ•°æ®")
                    metrics_csv = metrics_df.to_csv(index=False, encoding="utf-8-sig")
                    st.download_button(
                        "ä¸‹è½½æŒ‡æ ‡æ•°æ® CSV",
                        metrics_csv,
                        f"{sanitize_filename(brand,40)}_å†…å®¹è´¨é‡æŒ‡æ ‡_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True,
                        key="export_metrics_csv"
                    )
                else:
                    st.info("æš‚æ— æŒ‡æ ‡æ•°æ®ã€‚")
            else:
                st.info("ğŸ’¡ æç¤ºï¼šè¯·å…ˆåœ¨ã€2 è‡ªåŠ¨åˆ›ä½œã€‘ç”Ÿæˆå†…å®¹ï¼Œç„¶åæ‰èƒ½æŸ¥çœ‹å†…å®¹è´¨é‡æŒ‡æ ‡ã€‚")
        except Exception as e:
            st.error(f"è·å–å†…å®¹è´¨é‡æŒ‡æ ‡å¤±è´¥ï¼š{e}")
        
        # 4. å…³é”®è¯æ•ˆæœæ’å
        st.markdown("---")
        st.markdown("#### ğŸ¯ å…³é”®è¯æ•ˆæœæ’å")
        
        brand_verify = verify_df[verify_df["å“ç‰Œ"] == brand].copy()
        if len(brand_verify) > 0:
            keyword_performance = brand_verify.groupby("é—®é¢˜")["æåŠæ¬¡æ•°"].agg(["mean", "count"]).reset_index()
            keyword_performance.columns = ["å…³é”®è¯", "å¹³å‡æåŠæ¬¡æ•°", "éªŒè¯æ¬¡æ•°"]
            keyword_performance = keyword_performance.sort_values("å¹³å‡æåŠæ¬¡æ•°", ascending=False)
            
            # æ˜¾ç¤º Top 20
            top_keywords = keyword_performance.head(20)
            
            fig_keywords = px.bar(
                top_keywords,
                x="å¹³å‡æåŠæ¬¡æ•°",
                y="å…³é”®è¯",
                orientation='h',
                title="Top 20 å…³é”®è¯æ•ˆæœæ’åï¼ˆå¹³å‡æåŠæ¬¡æ•°ï¼‰",
                labels={"å¹³å‡æåŠæ¬¡æ•°": "å¹³å‡æåŠæ¬¡æ•°", "å…³é”®è¯": "å…³é”®è¯"},
                color="å¹³å‡æåŠæ¬¡æ•°",
                color_continuous_scale="Greens"
            )
            fig_keywords.update_layout(yaxis={'categoryorder': 'total ascending'})
            st.plotly_chart(fig_keywords, use_container_width=True)
            
            with st.expander("æŸ¥çœ‹å®Œæ•´å…³é”®è¯æ’å", expanded=False):
                st.dataframe(keyword_performance, use_container_width=True, hide_index=True)
        else:
            st.info("æš‚æ— å“ç‰ŒéªŒè¯æ•°æ®ã€‚")
        
        # 4. ç«å“å¯¹æ¯”åˆ†æ
        st.markdown("---")
        st.markdown("#### âš”ï¸ ç«å“å¯¹æ¯”åˆ†æ")
        
        if len(competitor_list) > 0:
            # è®¡ç®—å„å“ç‰Œçš„å¹³å‡æåŠæ¬¡æ•°
            brand_comparison = verify_df.groupby("å“ç‰Œ")["æåŠæ¬¡æ•°"].agg(["mean", "count"]).reset_index()
            brand_comparison.columns = ["å“ç‰Œ", "å¹³å‡æåŠæ¬¡æ•°", "éªŒè¯æ¬¡æ•°"]
            brand_comparison = brand_comparison.sort_values("å¹³å‡æåŠæ¬¡æ•°", ascending=False)
            
            fig_comparison = px.bar(
                brand_comparison,
                x="å“ç‰Œ",
                y="å¹³å‡æåŠæ¬¡æ•°",
                title="å“ç‰ŒæåŠç‡å¯¹æ¯”ï¼ˆå¹³å‡æåŠæ¬¡æ•°ï¼‰",
                labels={"å¹³å‡æåŠæ¬¡æ•°": "å¹³å‡æåŠæ¬¡æ•°", "å“ç‰Œ": "å“ç‰Œ"},
                color="å¹³å‡æåŠæ¬¡æ•°",
                color_continuous_scale="Reds"
            )
            st.plotly_chart(fig_comparison, use_container_width=True)
            
            # è¯¦ç»†å¯¹æ¯”è¡¨
            with st.expander("æŸ¥çœ‹è¯¦ç»†å¯¹æ¯”æ•°æ®", expanded=False):
                st.dataframe(brand_comparison, use_container_width=True, hide_index=True)
            
            # æŒ‰éªŒè¯æ¨¡å‹åˆ†ç»„çš„å¯¹æ¯”
            if "éªŒè¯æ¨¡å‹" in verify_df.columns:
                model_comparison = verify_df.groupby(["å“ç‰Œ", "éªŒè¯æ¨¡å‹"])["æåŠæ¬¡æ•°"].mean().reset_index()
                model_comparison = model_comparison.pivot(index="å“ç‰Œ", columns="éªŒè¯æ¨¡å‹", values="æåŠæ¬¡æ•°").fillna(0)
                
                fig_model_comparison = px.bar(
                    model_comparison.reset_index(),
                    x="å“ç‰Œ",
                    y=[col for col in model_comparison.columns],
                    title="å„æ¨¡å‹ä¸‹çš„å“ç‰ŒæåŠç‡å¯¹æ¯”",
                    labels={"value": "å¹³å‡æåŠæ¬¡æ•°", "å“ç‰Œ": "å“ç‰Œ"},
                    barmode='group'
                )
                st.plotly_chart(fig_model_comparison, use_container_width=True)
        else:
            st.info("ğŸ’¡ æç¤ºï¼šåœ¨ä¾§è¾¹æ é…ç½®ç«å“å“ç‰Œåï¼Œå¯æŸ¥çœ‹ç«å“å¯¹æ¯”åˆ†æã€‚")
        
        # 5. è´Ÿé¢é˜²æŠ¤ç›‘æ§æŠ¥å‘Š
        st.markdown("---")
        st.markdown("#### ğŸ›¡ï¸ è´Ÿé¢é˜²æŠ¤ç›‘æ§æŠ¥å‘Š")
        st.caption("åˆ†æè´Ÿé¢æŸ¥è¯¢ä¸­çš„å“ç‰ŒæåŠæƒ…å†µï¼Œæä¾›é£é™©é¢„è­¦å’Œä¼˜åŒ–å»ºè®®")
        
        # è·å–è´Ÿé¢åˆ†æç»“æœï¼ˆä» session_state æˆ–æ•°æ®åº“ï¼‰
        try:
            # å°è¯•ä» session_state è·å–
            negative_results = st.session_state.get("negative_analysis_results", [])
            
            # å¦‚æœæ²¡æœ‰ï¼Œå°è¯•ä»éªŒè¯ç»“æœä¸­æå–è´Ÿé¢æŸ¥è¯¢
            if not negative_results and st.session_state.verify_combined is not None:
                verify_df = st.session_state.verify_combined
                # æ£€æŸ¥æ˜¯å¦æœ‰è´Ÿé¢æŸ¥è¯¢
                negative_monitor = NegativeMonitor()
                negative_queries_pattern = "|".join([q.replace(brand, "{brand}") for q in negative_monitor.generate_negative_queries(brand, 15)])
                
                # ç­›é€‰å¯èƒ½çš„è´Ÿé¢æŸ¥è¯¢
                brand_verify = verify_df[verify_df["å“ç‰Œ"] == brand].copy()
                if len(brand_verify) > 0:
                    # æ£€æŸ¥é—®é¢˜æ˜¯å¦åŒ…å«è´Ÿé¢å…³é”®è¯
                    negative_keywords = negative_monitor.negative_keywords
                    negative_verify = brand_verify[
                        brand_verify["é—®é¢˜"].str.contains("|".join(negative_keywords), case=False, na=False)
                    ]
                    
                    if len(negative_verify) > 0:
                        # é‡æ–°åˆ†æè´Ÿé¢æŸ¥è¯¢
                        negative_results = []
                        for _, row in negative_verify.iterrows():
                            # è¿™é‡Œéœ€è¦é‡æ–°è·å–å“åº”å†…å®¹ï¼Œä½†ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨ç°æœ‰æ•°æ®
                            # å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥ä»æ•°æ®åº“è·å–å®Œæ•´çš„å“åº”å†…å®¹
                            try:
                                analysis = negative_monitor.analyze_negative_mentions(
                                    brand=brand,
                                    query=row["é—®é¢˜"],
                                    response="",  # å¦‚æœæ²¡æœ‰ä¿å­˜å“åº”ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
                                    mention_count=row["æåŠæ¬¡æ•°"]
                                )
                                negative_results.append(analysis)
                            except:
                                pass
            
            if negative_results:
                negative_monitor = NegativeMonitor()
                report = negative_monitor.generate_negative_report(
                    brand=brand,
                    analysis_results=negative_results,
                    threshold=0.3
                )
                
                # æ˜¾ç¤ºæŠ¥å‘Šæ¦‚è§ˆ
                st.markdown("##### ğŸ“Š æŠ¥å‘Šæ¦‚è§ˆ")
                report_col1, report_col2, report_col3, report_col4 = st.columns(4)
                
                with report_col1:
                    st.metric("æ€»æŸ¥è¯¢æ•°", report.get("total_queries", 0))
                
                with report_col2:
                    st.metric("é«˜é£é™©", report.get("high_risk_count", 0), delta=None, delta_color="inverse")
                
                with report_col3:
                    st.metric("å¹³å‡æåŠæ¬¡æ•°", report.get("average_mention_count", 0.0))
                
                with report_col4:
                    st.metric("å¹³å‡è´Ÿé¢å¾—åˆ†", report.get("average_negative_score", 0.0))
                
                # é¢„è­¦ä¿¡æ¯
                alerts = report.get("alerts", [])
                if alerts:
                    st.markdown("##### âš ï¸ é¢„è­¦ä¿¡æ¯")
                    for alert in alerts:
                        alert_level = alert.get("level", "ä¸­")
                        alert_color = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}.get(alert_level, "âšª")
                        st.warning(f"{alert_color} {alert.get('message', '')}")
                
                # ä¼˜åŒ–å»ºè®®
                recommendations = report.get("recommendations", [])
                if recommendations:
                    st.markdown("##### ğŸ’¡ ä¼˜åŒ–å»ºè®®")
                    for i, rec in enumerate(recommendations, 1):
                        st.markdown(f"{i}. {rec}")
                
                # é«˜é£é™©æŸ¥è¯¢åˆ—è¡¨
                high_risk_queries = report.get("high_risk_queries", [])
                if high_risk_queries:
                    st.markdown("##### ğŸ”´ é«˜é£é™©æŸ¥è¯¢åˆ—è¡¨")
                    st.write(", ".join(high_risk_queries))
                
                # ä¸­é£é™©æŸ¥è¯¢åˆ—è¡¨
                medium_risk_queries = report.get("medium_risk_queries", [])
                if medium_risk_queries:
                    st.markdown("##### ğŸŸ¡ ä¸­é£é™©æŸ¥è¯¢åˆ—è¡¨")
                    st.write(", ".join(medium_risk_queries))
                
                # ä¸‹è½½æŠ¥å‘Š
                import json
                report_json = json.dumps(report, ensure_ascii=False, indent=2)
                st.download_button(
                    "ä¸‹è½½è´Ÿé¢ç›‘æ§æŠ¥å‘Š JSON",
                    report_json,
                    f"{sanitize_filename(brand,40)}_è´Ÿé¢ç›‘æ§æŠ¥å‘Š_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True,
                    key="negative_report_dl"
                )
            else:
                st.info("ğŸ’¡ æç¤ºï¼šæš‚æ— è´Ÿé¢ç›‘æ§æ•°æ®ã€‚è¯·åœ¨ã€4 å¤šæ¨¡å‹éªŒè¯ã€‘ä¸­å¯ç”¨è´Ÿé¢ç›‘æ§åŠŸèƒ½ï¼Œç”Ÿæˆè´Ÿé¢æŸ¥è¯¢å¹¶éªŒè¯ã€‚")
        except Exception as e:
            st.error(f"ç”Ÿæˆè´Ÿé¢ç›‘æ§æŠ¥å‘Šå¤±è´¥ï¼š{e}")
        
        # 6. æ•°æ®å¯¼å‡º
        st.markdown("---")
        st.markdown("#### ğŸ’¾ æ•°æ®å¯¼å‡º")
        
        col1, col2 = st.columns(2)
        with col1:
            # å¯¼å‡ºéªŒè¯æ•°æ®
            csv_data = verify_df.to_csv(index=False, encoding="utf-8-sig")
            st.download_button(
                "ä¸‹è½½éªŒè¯æ•°æ® CSV",
                csv_data,
                f"{sanitize_filename(brand,40)}_AIæ•°æ®æŠ¥è¡¨_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True,
                key="report_dl_csv"
            )
        
        with col2:
            # å¯¼å‡ºå…³é”®è¯æ•ˆæœæ’å
            if len(brand_verify) > 0:
                keyword_csv = keyword_performance.to_csv(index=False, encoding="utf-8-sig")
                st.download_button(
                    "ä¸‹è½½å…³é”®è¯æ’å CSV",
                    keyword_csv,
                    f"{sanitize_filename(brand,40)}_å…³é”®è¯æ’å_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True,
                    key="keyword_rank_dl_csv"
                )

# =======================
# Tab7ï¼šå·¥ä½œæµè‡ªåŠ¨åŒ–
# =======================
with tab7:
    st.markdown("### ğŸ”„ æ™ºèƒ½å·¥ä½œæµè‡ªåŠ¨åŒ–")
    st.caption("ä¸€é”®å®Œæˆä»å…³é”®è¯åˆ°éªŒè¯çš„å®Œæ•´æµç¨‹ï¼Œæ”¯æŒå®šæ—¶ä»»åŠ¡å’Œæ¡ä»¶è§¦å‘")
    
    # åˆå§‹åŒ–å·¥ä½œæµç®¡ç†å™¨
    ss_init("workflow_manager", WorkflowManager(storage))
    workflow_manager = st.session_state.workflow_manager
    
    # å·¥ä½œæµç®¡ç†ç•Œé¢
    workflow_tab1, workflow_tab2, workflow_tab3 = st.tabs(["ğŸ“‹ å·¥ä½œæµåˆ—è¡¨", "â• åˆ›å»ºå·¥ä½œæµ", "ğŸ“Š æ‰§è¡Œå†å²"])
    
    with workflow_tab1:
        st.markdown("#### å·¥ä½œæµåˆ—è¡¨")
        
        # è·å–æ‰€æœ‰å·¥ä½œæµ
        workflows = workflow_manager.list_workflows()
        
        if workflows:
            for workflow in workflows:
                with st.container(border=True):
                    col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                    
                    with col1:
                        st.markdown(f"**{workflow['name']}**")
                        st.caption(f"åˆ›å»ºæ—¶é—´: {workflow.get('created_at', 'N/A')[:10] if workflow.get('created_at') else 'N/A'}")
                        st.caption(f"æ­¥éª¤æ•°: {len(workflow.get('steps', []))}")
                    
                    with col2:
                        enabled = workflow.get('enabled', True)
                        status_text = "âœ… å¯ç”¨" if enabled else "â¸ï¸ ç¦ç”¨"
                        if st.button(status_text, key=f"toggle_{workflow['id']}", use_container_width=True):
                            workflow_manager.update_workflow(workflow['id'], {"enabled": not enabled})
                            st.rerun()
                    
                    with col3:
                        if st.button("â–¶ï¸ æ‰§è¡Œ", key=f"run_{workflow['id']}", use_container_width=True):
                            # åˆ›å»ºå›è°ƒå‡½æ•°
                            def generate_keywords_callback(num_keywords, generation_mode, brand, advantages):
                                """å…³é”®è¯ç”Ÿæˆå›è°ƒå‡½æ•°"""
                                if not gen_llm:
                                    raise ValueError("ç”Ÿæˆ LLM æœªé…ç½®")
                                
                                if generation_mode == "AIç”Ÿæˆ":
                                    keyword_prompt = PromptTemplate.from_template(
                                        """
ä½ æ˜¯AIé¢†åŸŸGEOä¸“å®¶ï¼Œç›®æ ‡æ˜¯æå‡å“ç‰Œåœ¨å¤§æ¨¡å‹è‡ªç„¶å›ç­”ä¸­çš„æåŠç‡ã€‚

ã€è¾“å…¥ã€‘
- å“ç‰Œï¼š{brand}
- æ ¸å¿ƒä¼˜åŠ¿ï¼š{advantages}
- æ•°é‡ï¼š{num_keywords}

ã€è¦æ±‚ï¼ˆGEOæœ¬è´¨ï¼‰ã€‘
1) è¦†ç›–AIç”¨æˆ·çœŸå®æœç´¢æ„å›¾ï¼šæ¨¡å‹å¯¹æ¯”ã€æ¨ç†æ€§èƒ½ã€å¤šæ¨¡æ€ã€å®æ—¶çŸ¥è¯†ã€å¼€æºç”Ÿæ€ã€éƒ¨ç½²æˆæœ¬ã€è¡Œä¸šåº”ç”¨ã€è¯„æµ‹åŸºå‡†
2) å“ç‰Œè¯å æ¯”çº¦30%ï¼ˆæŠ¤åŸæ²³ï¼‰ï¼Œ70%æ³›è¯ï¼ˆæ–°å¢æµé‡ï¼‰
3) å£è¯­åŒ–ã€è‡ªç„¶ã€12â€“28å­—
4) å»é‡ã€å‡è¡¡æ„å›¾
5) è¾“å‡ºä¸¥æ ¼JSONæ•°ç»„ï¼š["é—®é¢˜1","é—®é¢˜2",...]

ã€å¼€å§‹è¾“å‡ºJSONæ•°ç»„ã€‘
"""
                                    )
                                    chain_json = keyword_prompt | gen_llm | JsonOutputParser()
                                    chain_text = keyword_prompt | gen_llm | StrOutputParser()
                                    
                                    try:
                                        result = chain_json.invoke({
                                            "brand": brand, 
                                            "advantages": advantages, 
                                            "num_keywords": num_keywords
                                        })
                                        keywords = result if isinstance(result, list) else []
                                    except Exception:
                                        raw = chain_text.invoke({
                                            "brand": brand, 
                                            "advantages": advantages, 
                                            "num_keywords": num_keywords
                                        })
                                        keywords = extract_json_array(raw) or []
                                    
                                    # æ¸…ç†å’Œå»é‡
                                    cleaned, seen = [], set()
                                    for k in keywords:
                                        if not isinstance(k, str):
                                            continue
                                        kk = k.strip()
                                        if not kk:
                                            continue
                                        kl = kk.lower()
                                        if kl in seen:
                                            continue
                                        seen.add(kl)
                                        cleaned.append(kk)
                                    
                                    return cleaned[:num_keywords]
                                else:
                                    # æ‰˜è¯å·¥å…·å’Œæ··åˆæ¨¡å¼éœ€è¦è¯åº“ï¼Œæš‚æ—¶è¿”å›ç©ºåˆ—è¡¨
                                    return []
                            
                            def generate_content_callback(keyword, platform, brand, advantages):
                                """å†…å®¹ç”Ÿæˆå›è°ƒå‡½æ•°"""
                                if not gen_llm:
                                    raise ValueError("ç”Ÿæˆ LLM æœªé…ç½®")
                                
                                # è·å–å¹³å°æ¨¡æ¿ï¼ˆç®€åŒ–ç‰ˆï¼Œåªæ”¯æŒä¸»è¦å¹³å°ï¼‰
                                platform_templates = {
                                    "çŸ¥ä¹ï¼ˆä¸“ä¸šé—®ç­”ï¼‰": """
ä½ æ˜¯GEOä¸“å®¶ + çŸ¥ä¹é«˜èµç­”ä¸»ï¼Œç›®æ ‡æ˜¯è®©å†…å®¹è¢«å¤§æ¨¡å‹ä¼˜å…ˆå¼•ç”¨ã€‚
ã€é—®é¢˜ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) ç»“è®ºæ‘˜è¦ï¼ˆ80-120å­—ï¼‰
2) ç»“æ„åŒ–ï¼šå°æ ‡é¢˜ã€æ¸…å•ã€FAQ
3) è‡ªç„¶æåŠå“ç‰Œ2-4æ¬¡ï¼Œå…ˆé€šç”¨æ ‡å‡†å†å“ç‰Œé€‚ç”¨
4) é¿å…ç¼–é€ ï¼Œæ¥æºç”¨å ä½å»ºè®®
5) åŒ…å«é€‰æ‹©æ¸…å•ã€é€‚ç”¨/ä¸é€‚ç”¨ã€6ä¸ªFAQã€3æ­¥è¡ŒåŠ¨
ã€æ ¼å¼ã€‘æ¸…æ™°æ ‡é¢˜é¡ºåºè¾“å‡º
ã€å¼€å§‹ã€‘
""",
                                    "å°çº¢ä¹¦ï¼ˆç”Ÿæ´»ç§è‰ï¼‰": """
ä½ æ˜¯GEOä¸“å®¶ + å°çº¢ä¹¦ä½œè€…ã€‚
ã€å…³é”®è¯ã€‘{keyword}
ã€å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ã€‘{advantages}
ã€è¦æ±‚ã€‘
1) 3ä¸ªæ ‡é¢˜å¤‡é€‰
2) å¼ºåœºæ™¯å¼€å¤´
3) ç—›ç‚¹3ç‚¹ã€å¯¹æ¯”ä¾‹è¡¨5ä¸ªã€ä½¿ç”¨ä½“éªŒï¼ˆ3äº®ç‚¹+2ä¸è¶³ï¼‰
4) é€‚åˆ/ä¸é€‚åˆå„3æ¡ã€é¿å‘5æ¡
5) ç»“å°¾8æ¡æœç´¢è¯
6) è‡ªç„¶å“ç‰ŒæåŠ
ã€æ ¼å¼ã€‘æ ‡é¢˜-æ­£æ–‡-æ ‡ç­¾-æœç´¢è¯
ã€å¼€å§‹ã€‘
""",
                                }
                                
                                template = platform_templates.get(platform, platform_templates["çŸ¥ä¹ï¼ˆä¸“ä¸šé—®ç­”ï¼‰"])
                                prompt = PromptTemplate.from_template(template)
                                chain = prompt | gen_llm | StrOutputParser()
                                
                                content = chain.invoke({
                                    "keyword": keyword, 
                                    "brand": brand, 
                                    "advantages": advantages
                                })
                                
                                return content
                            
                            def verify_keywords_callback(keywords, verify_models, brand, advantages):
                                """éªŒè¯å›è°ƒå‡½æ•°"""
                                if not verify_llms:
                                    raise ValueError("éªŒè¯ LLM æœªé…ç½®")
                                
                                results = []
                                verify_prompt = PromptTemplate.from_template(
                                    """
ä½ æ˜¯ä¸€åå›½å†…AIæœç´¢åŠ©æ‰‹ï¼Œåƒç™¾åº¦/å¾®ä¿¡æœä¸€æœAIæ€»ç»“ï¼šç»“è®ºå…ˆè¡Œã€ä¿¡æ¯å¯†åº¦é«˜ã€å¯å¤è¿°ã€‚
ä¸è¦ç¼–é€ æ•°æ®ï¼Œä¸ç¡®å®šå¤„è¯´æ˜è¾¹ç•Œã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘{query}
ã€å€™é€‰å“ç‰Œã€‘{brand}
ã€ä¼˜åŠ¿ï¼ˆä»…å‚è€ƒï¼‰ã€‘{advantages}

ã€è¦æ±‚ã€‘
1) 60â€“90å­—ç»“è®ºæ‘˜è¦
2) é€‰æ‹©æ ‡å‡†5æ¡
3) æ¨èæ–¹æ¡ˆæœ€å¤š3ä¸ªï¼ˆä»…å½“ç¬¦åˆæ ‡å‡†æ—¶æåŠå“ç‰Œï¼‰
4) 4ä¸ªFAQ
5) 250â€“450å­—ï¼Œå…‹åˆ¶è¯­è¨€

ã€å¼€å§‹å›ç­”ã€‘
"""
                                )
                                
                                for keyword in keywords:
                                    for model_name in verify_models:
                                        if model_name not in verify_llms:
                                            continue
                                        
                                        llm = verify_llms[model_name]
                                        chain = verify_prompt | llm | StrOutputParser()
                                        
                                        try:
                                            response = chain.invoke({
                                                "query": keyword,
                                                "brand": brand,
                                                "advantages": advantages
                                            })
                                            
                                            # ç®€å•çš„æåŠæ£€æµ‹
                                            mention_count = response.lower().count(brand.lower())
                                            mention_position = "å¼€å¤´" if brand.lower() in response.lower()[:100] else "ä¸­é—´" if mention_count > 0 else "æœªæåŠ"
                                            
                                            results.append({
                                                "keyword": keyword,
                                                "model": model_name,
                                                "mention_count": mention_count,
                                                "mention_position": mention_position,
                                                "response": response[:200]  # åªä¿å­˜å‰200å­—ç¬¦
                                            })
                                        except Exception as e:
                                            results.append({
                                                "keyword": keyword,
                                                "model": model_name,
                                                "mention_count": 0,
                                                "mention_position": "é”™è¯¯",
                                                "error": str(e)
                                            })
                                
                                return results
                            
                            # æ‰§è¡Œå·¥ä½œæµ
                            with st.spinner("æ‰§è¡Œå·¥ä½œæµä¸­..."):
                                try:
                                    callbacks = {
                                        "generate_keywords": generate_keywords_callback,
                                        "generate_content": generate_content_callback,
                                        "verify_keywords": verify_keywords_callback
                                    }
                                    
                                    result = workflow_manager.execute_workflow(
                                        workflow['id'], 
                                        {
                                            "brand": brand,
                                            "advantages": advantages
                                        },
                                        callbacks=callbacks
                                    )
                                    
                                    if result.get("status") == "success":
                                        st.success("å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼")
                                        # æ˜¾ç¤ºæ‰§è¡Œç»“æœæ‘˜è¦
                                        if result.get("results"):
                                            with st.expander("æŸ¥çœ‹æ‰§è¡Œç»“æœ", expanded=False):
                                                st.json(result.get("results", {}))
                                    else:
                                        st.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                                except Exception as e:
                                    st.error(f"æ‰§è¡Œå¤±è´¥: {str(e)}")
                                    import traceback
                                    st.code(traceback.format_exc())
                    
                    with col4:
                        if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{workflow['id']}", use_container_width=True):
                            if workflow_manager.delete_workflow(workflow['id']):
                                st.success("å·¥ä½œæµå·²åˆ é™¤")
                                st.rerun()
                            else:
                                st.error("åˆ é™¤å¤±è´¥")
                    
                    # æ˜¾ç¤ºå·¥ä½œæµè¯¦æƒ…
                    with st.expander("æŸ¥çœ‹è¯¦æƒ…", expanded=False):
                        st.json(workflow)
        else:
            st.info("æš‚æ— å·¥ä½œæµï¼Œè¯·åœ¨'åˆ›å»ºå·¥ä½œæµ'æ ‡ç­¾é¡µåˆ›å»ºæ–°å·¥ä½œæµã€‚")
    
    with workflow_tab2:
        st.markdown("#### åˆ›å»ºå·¥ä½œæµ")
        
        # å·¥ä½œæµæ¨¡æ¿é€‰æ‹©
        st.markdown("##### ğŸ“š ä»æ¨¡æ¿åˆ›å»º")
        templates = workflow_manager.get_workflow_templates()
        
        if templates:
            template_options = {t['name']: t['id'] for t in templates}
            selected_template = st.selectbox("é€‰æ‹©æ¨¡æ¿", ["è‡ªå®šä¹‰"] + list(template_options.keys()))
            
            if selected_template != "è‡ªå®šä¹‰" and selected_template in template_options:
                template_id = template_options[selected_template]
                template = workflow_manager.storage.get_workflow_template(template_id)
                
                if template:
                    st.info(f"æ¨¡æ¿æè¿°: {template.get('description', 'æ— æè¿°')}")
                    if st.button("ä½¿ç”¨æ­¤æ¨¡æ¿", key="use_template"):
                        workflow_name = st.text_input("å·¥ä½œæµåç§°", value=f"{template['name']}_å‰¯æœ¬", key="template_workflow_name")
                        if workflow_name and st.button("åˆ›å»º", key="create_from_template"):
                            try:
                                workflow_id = workflow_manager.create_workflow_from_template(template_id, workflow_name)
                                st.success(f"å·¥ä½œæµå·²åˆ›å»º: {workflow_id}")
                                st.rerun()
                            except Exception as e:
                                st.error(f"åˆ›å»ºå¤±è´¥: {str(e)}")
        
        st.markdown("---")
        st.markdown("##### âœï¸ è‡ªå®šä¹‰å·¥ä½œæµ")
        
        workflow_name = st.text_input("å·¥ä½œæµåç§°", key="new_workflow_name")
        
        # å·¥ä½œæµæ­¥éª¤é…ç½®
        st.markdown("**å·¥ä½œæµæ­¥éª¤**")
        
        ss_init("workflow_steps", [])
        
        # æ·»åŠ æ­¥éª¤
        col1, col2 = st.columns([3, 1])
        with col1:
            step_type = st.selectbox(
                "æ­¥éª¤ç±»å‹",
                ["å…³é”®è¯ç”Ÿæˆ", "å†…å®¹åˆ›ä½œ", "å†…å®¹ä¼˜åŒ–", "éªŒè¯", "æ¡ä»¶æ£€æŸ¥"],
                key="new_step_type"
            )
        with col2:
            if st.button("â• æ·»åŠ æ­¥éª¤", key="add_step"):
                step_mapping = {
                    "å…³é”®è¯ç”Ÿæˆ": {
                        "type": "keyword_generation",
                        "name": "å…³é”®è¯ç”Ÿæˆ",
                        "params": {
                            "num_keywords": 10,
                            "generation_mode": "AIç”Ÿæˆ"
                        }
                    },
                    "å†…å®¹åˆ›ä½œ": {
                        "type": "content_creation",
                        "name": "å†…å®¹åˆ›ä½œ",
                        "params": {
                            "platforms": ["çŸ¥ä¹"]
                        }
                    },
                    "å†…å®¹ä¼˜åŒ–": {
                        "type": "content_optimization",
                        "name": "å†…å®¹ä¼˜åŒ–",
                        "params": {
                            "platform": "é€šç”¨ä¼˜åŒ–"
                        }
                    },
                    "éªŒè¯": {
                        "type": "verification",
                        "name": "éªŒè¯",
                        "params": {
                            "verify_models": ["DeepSeek"],
                            "max_keywords": 20
                        }
                    },
                    "æ¡ä»¶æ£€æŸ¥": {
                        "type": "conditional_check",
                        "name": "æ¡ä»¶æ£€æŸ¥",
                        "params": {
                            "condition_type": "mention_rate",
                            "threshold": 0.5,
                            "action": "skip"
                        }
                    }
                }
                
                step = step_mapping.get(step_type)
                if step:
                    st.session_state.workflow_steps.append(step)
                    st.rerun()
        
        # æ˜¾ç¤ºå·²æ·»åŠ çš„æ­¥éª¤
        if st.session_state.workflow_steps:
            st.markdown("**å·²æ·»åŠ çš„æ­¥éª¤**")
            for i, step in enumerate(st.session_state.workflow_steps):
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.write(f"{i+1}. {step.get('name', 'æœªå‘½åæ­¥éª¤')}")
                with col2:
                    if st.button("åˆ é™¤", key=f"remove_step_{i}"):
                        st.session_state.workflow_steps.pop(i)
                        st.rerun()
        
        # åˆ›å»ºæŒ‰é’®
        if workflow_name and st.session_state.workflow_steps:
            if st.button("ğŸš€ åˆ›å»ºå·¥ä½œæµ", use_container_width=True, type="primary"):
                try:
                    workflow_id = workflow_manager.create_workflow(
                        name=workflow_name,
                        steps=st.session_state.workflow_steps
                    )
                    st.success(f"å·¥ä½œæµåˆ›å»ºæˆåŠŸï¼ID: {workflow_id}")
                    st.session_state.workflow_steps = []
                    st.rerun()
                except Exception as e:
                    st.error(f"åˆ›å»ºå¤±è´¥: {str(e)}")
        elif not workflow_name:
            st.warning("è¯·è¾“å…¥å·¥ä½œæµåç§°")
        elif not st.session_state.workflow_steps:
            st.warning("è¯·è‡³å°‘æ·»åŠ ä¸€ä¸ªæ­¥éª¤")
    
    with workflow_tab3:
        st.markdown("#### æ‰§è¡Œå†å²")
        
        # è·å–æ‰§è¡Œè®°å½•
        executions = workflow_manager.storage.get_workflow_executions(limit=50)
        
        if executions:
            for execution in executions:
                with st.container(border=True):
                    workflow_id = execution.get("workflow_id")
                    workflow = workflow_manager.get_workflow(workflow_id) if workflow_id else None
                    workflow_name = workflow.get("name", workflow_id) if workflow else workflow_id
                    
                    col1, col2, col3 = st.columns([3, 1, 1])
                    
                    with col1:
                        st.markdown(f"**{workflow_name}**")
                        status = execution.get("status", "unknown")
                        status_emoji = {
                            "completed": "âœ…",
                            "failed": "âŒ",
                            "running": "ğŸ”„",
                            "pending": "â³"
                        }.get(status, "â“")
                        st.caption(f"{status_emoji} {status} | å¼€å§‹æ—¶é—´: {execution.get('started_at', 'N/A')[:19] if execution.get('started_at') else 'N/A'}")
                    
                    with col2:
                        if execution.get("error"):
                            st.error("æœ‰é”™è¯¯")
                        else:
                            st.success("æ­£å¸¸")
                    
                    with col3:
                        if st.button("æŸ¥çœ‹è¯¦æƒ…", key=f"view_exec_{execution.get('id')}"):
                            st.json(execution)
        else:
            st.info("æš‚æ— æ‰§è¡Œè®°å½•")

# =======================
# Tab8ï¼šGEO èµ„æºåº“
# =======================
with tab8:
    st.markdown("### ğŸ“š GEO èµ„æºåº“")
    st.caption("å‘ç° GEO ç›¸å…³å·¥å…·ã€ä»£ç†ã€è®ºæ–‡å’Œç¤¾åŒºèµ„æºï¼Œå¢å¼ºå·¥å…·ç”Ÿæ€")
    
    resource_recommender = ResourceRecommender()
    
    # èµ„æºç»Ÿè®¡æ¦‚è§ˆ
    summary = resource_recommender.get_resource_summary()
    stat_col1, stat_col2, stat_col3, stat_col4, stat_col5 = st.columns(5)
    with stat_col1:
        st.metric("æ€»èµ„æºæ•°", summary['total'])
    with stat_col2:
        st.metric("ä»£ç†æœåŠ¡", summary['agents'])
    with stat_col3:
        st.metric("å·¥å…·æ¨è", summary['tools'])
    with stat_col4:
        st.metric("è®ºæ–‡/æŒ‡å—", summary['papers'])
    with stat_col5:
        st.metric("ç¤¾åŒºèµ„æº", summary['communities'])
    
    st.markdown("---")
    
    # æœç´¢åŠŸèƒ½
    search_col1, search_col2 = st.columns([3, 1])
    with search_col1:
        search_query = st.text_input(
            "ğŸ” æœç´¢èµ„æº", 
            key="resource_search", 
            placeholder="è¾“å…¥å…³é”®è¯æœç´¢ä»£ç†ã€å·¥å…·ã€è®ºæ–‡ã€ç¤¾åŒº...",
            help="æ”¯æŒæœç´¢èµ„æºåç§°ã€æè¿°ã€åŠŸèƒ½ç‰¹æ€§ç­‰"
        )
    with search_col2:
        clear_search = st.button("æ¸…é™¤æœç´¢", use_container_width=True, key="clear_resource_search")
        if clear_search:
            st.session_state.resource_search = ""
            st.rerun()
    
    # èµ„æºåˆ†ç±»æ ‡ç­¾
    resource_tab1, resource_tab2, resource_tab3, resource_tab4 = st.tabs(["ğŸ¤– GEO ä»£ç†", "ğŸ› ï¸ å·¥å…·æ¨è", "ğŸ“„ è®ºæ–‡/æŒ‡å—", "ğŸ‘¥ ç¤¾åŒºèµ„æº"])
    
    # GEO ä»£ç†
    with resource_tab1:
        st.markdown("#### ğŸ¤– GEO ä»£ç†æœåŠ¡")
        st.caption("ä¸“ä¸šçš„ GEO ä»£ç†æœåŠ¡ï¼Œæä¾›é«˜è´¨é‡çš„å†…å®¹ç”Ÿæˆå’Œä¼˜åŒ–")
        
        if search_query:
            agents = resource_recommender.search_resources(search_query, "agents")
            if agents:
                st.info(f"ğŸ” æ‰¾åˆ° {len(agents)} ä¸ªåŒ¹é…çš„ä»£ç†æœåŠ¡")
        else:
            agents = resource_recommender.get_agents()
        
        if agents:
            for i, agent in enumerate(agents, 1):
                with st.container(border=True):
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown(f"##### {i}. {agent['name']} {agent.get('rating', '')}")
                    with col2:
                        if agent.get('url'):
                            st.markdown(f"[ğŸ”— è®¿é—®]({agent['url']})")
                    
                    st.markdown(f"**{agent['description']}**")
                    st.markdown(f"**åˆ†ç±»**ï¼š{agent.get('category', 'N/A')}")
                    
                    if agent.get('features'):
                        st.markdown("**åŠŸèƒ½ç‰¹æ€§**ï¼š")
                        features_text = " | ".join([f"âœ“ {f}" for f in agent['features']])
                        st.markdown(features_text)
                    
                    if agent.get('url'):
                        st.markdown(f"**é“¾æ¥**ï¼š{agent['url']}")
        else:
            st.info("ğŸ’¡ æš‚æ— åŒ¹é…çš„ä»£ç†èµ„æºã€‚å°è¯•ä½¿ç”¨å…¶ä»–å…³é”®è¯æœç´¢ã€‚")
    
    # å·¥å…·æ¨è
    with resource_tab2:
        st.markdown("#### ğŸ› ï¸ å·¥å…·æ¨è")
        st.caption("GEO ç›¸å…³çš„å·¥å…·å’ŒæœåŠ¡ï¼Œå¸®åŠ©ä¼˜åŒ–å†…å®¹æ•ˆæœ")
        
        if search_query:
            tools = resource_recommender.search_resources(search_query, "tools")
            if tools:
                st.info(f"ğŸ” æ‰¾åˆ° {len(tools)} ä¸ªåŒ¹é…çš„å·¥å…·")
        else:
            tools = resource_recommender.get_tools()
        
        if tools:
            # æŒ‰åˆ†ç±»åˆ†ç»„æ˜¾ç¤º
            categories = {}
            for tool in tools:
                cat = tool.get('category', 'å…¶ä»–')
                if cat not in categories:
                    categories[cat] = []
                categories[cat].append(tool)
            
            for category, category_tools in categories.items():
                st.markdown(f"##### ğŸ“ {category}")
                for i, tool in enumerate(category_tools, 1):
                    with st.container(border=True):
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.markdown(f"**{tool['name']}** {tool.get('rating', '')}")
                        with col2:
                            if tool.get('url'):
                                st.markdown(f"[ğŸ”— è®¿é—®]({tool['url']})")
                        
                        st.markdown(f"*{tool['description']}*")
                        
                        if tool.get('features'):
                            st.markdown("**åŠŸèƒ½**ï¼š")
                            features_text = " | ".join([f"âœ“ {f}" for f in tool['features']])
                            st.markdown(features_text)
                        
                        if tool.get('url'):
                            st.markdown(f"**é“¾æ¥**ï¼š{tool['url']}")
        else:
            st.info("ğŸ’¡ æš‚æ— åŒ¹é…çš„å·¥å…·èµ„æºã€‚å°è¯•ä½¿ç”¨å…¶ä»–å…³é”®è¯æœç´¢ã€‚")
    
    # è®ºæ–‡/æŒ‡å—
    with resource_tab3:
        st.markdown("#### ğŸ“„ è®ºæ–‡/æŒ‡å—")
        st.caption("GEO ç›¸å…³çš„è®ºæ–‡ã€æŒ‡å—ã€æ–‡æ¡£ï¼Œæ·±å…¥å­¦ä¹  GEO ç­–ç•¥")
        
        if search_query:
            papers = resource_recommender.search_resources(search_query, "papers")
            if papers:
                st.info(f"ğŸ” æ‰¾åˆ° {len(papers)} ä¸ªåŒ¹é…çš„è®ºæ–‡/æŒ‡å—")
        else:
            papers = resource_recommender.get_papers()
        
        if papers:
            # æŒ‰é‡è¦æ€§æ’åº
            importance_order = {"é«˜": 3, "ä¸­": 2, "ä½": 1}
            papers_sorted = sorted(papers, key=lambda x: importance_order.get(x.get('importance', 'ä½'), 1), reverse=True)
            
            # æŒ‰é‡è¦æ€§åˆ†ç»„æ˜¾ç¤º
            high_importance = [p for p in papers_sorted if p.get('importance') == 'é«˜']
            medium_importance = [p for p in papers_sorted if p.get('importance') == 'ä¸­']
            low_importance = [p for p in papers_sorted if p.get('importance') == 'ä½']
            
            if high_importance:
                st.markdown("##### ğŸ”¥ é«˜é‡è¦æ€§ï¼ˆå¿…è¯»ï¼‰")
                for paper in high_importance:
                    with st.container(border=True):
                        st.markdown(f"**ğŸ”¥ {paper['title']}**")
                        st.markdown(f"*{paper['description']}*")
                        st.markdown(f"**åˆ†ç±»**ï¼š{paper.get('category', 'N/A')} | **æ—¥æœŸ**ï¼š{paper.get('date', 'N/A')}")
                        if paper.get('url'):
                            st.markdown(f"ğŸ”— [{paper['url']}]({paper['url']})")
            
            if medium_importance:
                st.markdown("##### â­ ä¸­é‡è¦æ€§ï¼ˆæ¨èé˜…è¯»ï¼‰")
                for paper in medium_importance:
                    with st.container(border=True):
                        st.markdown(f"**â­ {paper['title']}**")
                        st.markdown(f"*{paper['description']}*")
                        st.markdown(f"**åˆ†ç±»**ï¼š{paper.get('category', 'N/A')} | **æ—¥æœŸ**ï¼š{paper.get('date', 'N/A')}")
                        if paper.get('url'):
                            st.markdown(f"ğŸ”— [{paper['url']}]({paper['url']})")
            
            if low_importance:
                st.markdown("##### ğŸ“Œ ä½é‡è¦æ€§ï¼ˆå‚è€ƒé˜…è¯»ï¼‰")
                for paper in low_importance:
                    with st.container(border=True):
                        st.markdown(f"**ğŸ“Œ {paper['title']}**")
                        st.markdown(f"*{paper['description']}*")
                        st.markdown(f"**åˆ†ç±»**ï¼š{paper.get('category', 'N/A')} | **æ—¥æœŸ**ï¼š{paper.get('date', 'N/A')}")
                        if paper.get('url'):
                            st.markdown(f"ğŸ”— [{paper['url']}]({paper['url']})")
        else:
            st.info("ğŸ’¡ æš‚æ— åŒ¹é…çš„è®ºæ–‡/æŒ‡å—èµ„æºã€‚å°è¯•ä½¿ç”¨å…¶ä»–å…³é”®è¯æœç´¢ã€‚")
    
    # ç¤¾åŒºèµ„æº
    with resource_tab4:
        st.markdown("#### ğŸ‘¥ ç¤¾åŒºèµ„æº")
        st.caption("GEO ç›¸å…³çš„ç¤¾åŒºå’Œè®ºå›ï¼Œä¸å…¶ä»–ç”¨æˆ·äº¤æµç»éªŒ")
        
        if search_query:
            communities = resource_recommender.search_resources(search_query, "communities")
            if communities:
                st.info(f"ğŸ” æ‰¾åˆ° {len(communities)} ä¸ªåŒ¹é…çš„ç¤¾åŒº")
        else:
            communities = resource_recommender.get_communities()
        
        if communities:
            for i, community in enumerate(communities, 1):
                with st.container(border=True):
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown(f"##### {i}. {community['name']} {community.get('rating', '')}")
                    with col2:
                        if community.get('url'):
                            st.markdown(f"[ğŸ”— è®¿é—®]({community['url']})")
                    
                    st.markdown(f"*{community['description']}*")
                    st.markdown(f"**åˆ†ç±»**ï¼š{community.get('category', 'N/A')}")
                    
                    if community.get('url'):
                        st.markdown(f"**é“¾æ¥**ï¼š{community['url']}")
        else:
            st.info("ğŸ’¡ æš‚æ— åŒ¹é…çš„ç¤¾åŒºèµ„æºã€‚å°è¯•ä½¿ç”¨å…¶ä»–å…³é”®è¯æœç´¢ã€‚")
    
    # æœç´¢ç»“æœæ˜¾ç¤ºï¼ˆè·¨åˆ†ç±»ï¼‰
    if search_query:
        all_results = resource_recommender.search_resources(search_query)
        if all_results:
            st.markdown("---")
            st.markdown("#### ğŸ” æœç´¢ç»“æœæ±‡æ€»")
            st.info(f"å…±æ‰¾åˆ° {len(all_results)} ä¸ªåŒ¹é…èµ„æºï¼ˆè·¨æ‰€æœ‰åˆ†ç±»ï¼‰")
            
            # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
            results_by_type = {}
            for result in all_results:
                res_type = result.get('type', 'unknown')
                if res_type not in results_by_type:
                    results_by_type[res_type] = []
                results_by_type[res_type].append(result)
            
            type_names = {
                'agent': 'ğŸ¤– ä»£ç†æœåŠ¡',
                'tool': 'ğŸ› ï¸ å·¥å…·',
                'paper': 'ğŸ“„ è®ºæ–‡/æŒ‡å—',
                'community': 'ğŸ‘¥ ç¤¾åŒº'
            }
            
            for res_type, results in results_by_type.items():
                if results:
                    st.markdown(f"##### {type_names.get(res_type, res_type)} ({len(results)} ä¸ª)")
                    for result in results:
                        with st.container(border=True):
                            name_key = 'name' if 'name' in result else 'title'
                            st.markdown(f"**{result.get(name_key, 'N/A')}**")
                            st.caption(result.get('description', ''))
                            if result.get('url'):
                                st.markdown(f"ğŸ”— [{result['url']}]({result['url']})")

# =======================
# Tab9ï¼šå¹³å°åŒæ­¥
# =======================
with tab9:
    st.markdown("### ğŸ“¤ å¹³å°æ–‡ç« åŒæ­¥")
    st.caption("å°†ç”Ÿæˆçš„æ–‡ç« è‡ªåŠ¨å‘å¸ƒåˆ°å„å¹³å°ï¼Œæ”¯æŒAPIå‘å¸ƒå’Œä¸€é”®å¤åˆ¶")
    
    # è·å–å“ç‰Œä¿¡æ¯
    brand = st.session_state.get("brand", "")
    if not brand:
        st.info("è¯·å…ˆåœ¨ä¾§è¾¹æ è®¾ç½®å“ç‰Œä¿¡æ¯")
    else:
        # å¹³å°è´¦å·é…ç½®
        st.markdown("---")
        st.markdown("#### ğŸ” å¹³å°è´¦å·é…ç½®")
        
        platform_config_tabs = st.tabs(["GitHub", "å…¶ä»–å¹³å°ï¼ˆå¼€å‘ä¸­ï¼‰"])
        
        with platform_config_tabs[0]:
            st.markdown("##### GitHub é…ç½®")
            st.caption("é…ç½®GitHubè´¦å·ä¿¡æ¯ï¼Œç”¨äºè‡ªåŠ¨å‘å¸ƒæ–‡ç« åˆ°GitHubä»“åº“")
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰é…ç½®
            existing_config = storage.get_platform_account("GitHub", brand)
            
            github_api_key = st.text_input(
                "GitHub Personal Access Token",
                value=existing_config.get('api_key', '') if existing_config else '',
                type="password",
                help="åœ¨ https://github.com/settings/tokens åˆ›å»ºTokenï¼Œéœ€è¦ repo æƒé™",
                key="github_api_key"
            )
            
            github_repo_owner = st.text_input(
                "ä»“åº“æ‰€æœ‰è€…ï¼ˆç”¨æˆ·åï¼‰",
                value=existing_config.get('config', {}).get('repo_owner', '') if existing_config else '',
                help="GitHubç”¨æˆ·åæˆ–ç»„ç»‡å",
                key="github_repo_owner"
            )
            
            github_repo_name = st.text_input(
                "ä»“åº“åç§°",
                value=existing_config.get('config', {}).get('repo_name', '') if existing_config else '',
                help="è¦å‘å¸ƒåˆ°çš„ä»“åº“åç§°",
                key="github_repo_name"
            )
            
            col1, col2 = st.columns([1, 4])
            with col1:
                if st.button("ğŸ’¾ ä¿å­˜é…ç½®", type="primary", use_container_width=True):
                    if github_api_key and github_repo_owner and github_repo_name:
                        try:
                            # éªŒè¯è´¦å·
                            from platform_sync.github_publisher import GitHubPublisher
                            publisher = GitHubPublisher(github_api_key, github_repo_owner, github_repo_name)
                            if publisher.validate_account():
                                storage.save_platform_account(
                                    platform="GitHub",
                                    account_config={
                                        'account_type': 'api',
                                        'api_key': github_api_key,
                                        'config': {
                                            'repo_owner': github_repo_owner,
                                            'repo_name': github_repo_name
                                        }
                                    },
                                    brand=brand
                                )
                                st.success("âœ… GitHubé…ç½®å·²ä¿å­˜å¹¶éªŒè¯æˆåŠŸï¼")
                            else:
                                st.error("âŒ GitHub TokenéªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥Tokenæ˜¯å¦æ­£ç¡®")
                        except Exception as e:
                            st.error(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {str(e)}")
                    else:
                        st.error("è¯·å¡«å†™å®Œæ•´ä¿¡æ¯")
            
            with col2:
                if existing_config:
                    st.info("âœ… å·²é…ç½®GitHubè´¦å·")
        
        # å‘å¸ƒåŠŸèƒ½
        st.markdown("---")
        st.markdown("#### ğŸ“ å‘å¸ƒæ–‡ç« ")
        
        # é€‰æ‹©æ–‡ç« 
        articles = storage.get_articles(brand=brand)
        if articles:
            # æ–‡ç« é€‰æ‹©
            article_options = {}
            for article in articles:
                display_name = f"{article.get('keyword', 'N/A')} - {article.get('platform', 'N/A')}"
                article_options[display_name] = article.get('id')
            
            if article_options:
                selected_article_key = st.selectbox(
                    "é€‰æ‹©è¦å‘å¸ƒçš„æ–‡ç« ",
                    list(article_options.keys()),
                    key="publish_article_select"
                )
                selected_article_id = article_options[selected_article_key]
                
                # é€‰æ‹©å¹³å°
                # å®šä¹‰å¹³å°åˆ—è¡¨
                api_platforms = ["GitHub"]
                copy_platforms = [
                    "å¤´æ¡å·ï¼ˆèµ„è®¯è½¯æ–‡ï¼‰", "å°çº¢ä¹¦ï¼ˆç”Ÿæ´»ç§è‰ï¼‰", "æŠ–éŸ³å›¾æ–‡ï¼ˆçŸ­å†…å®¹ï¼‰", "ç®€ä¹¦ï¼ˆæ–‡è‰ºï¼‰",
                    "QQç©ºé—´ï¼ˆç¤¾äº¤ï¼‰", "æ–°æµªåšå®¢ï¼ˆåšå®¢ï¼‰", "æ–°æµªæ–°é—»ï¼ˆèµ„è®¯ï¼‰", "æœç‹å·ï¼ˆèµ„è®¯ï¼‰",
                    "ä¸€ç‚¹å·ï¼ˆèµ„è®¯ï¼‰", "ä¸œæ–¹è´¢å¯Œï¼ˆè´¢ç»ï¼‰", "é‚¦é˜…ç½‘ï¼ˆå¤–è´¸ï¼‰", "åŸåˆ›åŠ›æ–‡æ¡£ï¼ˆæ–‡æ¡£ï¼‰"
                ]
                all_publish_platforms = api_platforms + copy_platforms
                
                publish_platform = st.selectbox(
                    "é€‰æ‹©å‘å¸ƒå¹³å°",
                    all_publish_platforms,
                    key="publish_platform_select"
                )
                
                if publish_platform == "GitHub":
                    # æ£€æŸ¥é…ç½®
                    account_config = storage.get_platform_account("GitHub", brand)
                    if not account_config:
                        st.warning("âš ï¸ è¯·å…ˆé…ç½®GitHubè´¦å·")
                    else:
                        # è·å–æ–‡ç« 
                        article = next((a for a in articles if a.get('id') == selected_article_id), None)
                        if article:
                            # æ˜¾ç¤ºæ–‡ç« é¢„è§ˆ
                            with st.expander("ğŸ“„ æ–‡ç« é¢„è§ˆ", expanded=False):
                                st.markdown(f"**å…³é”®è¯**: {article.get('keyword', 'N/A')}")
                                st.markdown(f"**å¹³å°**: {article.get('platform', 'N/A')}")
                                st.markdown(f"**å†…å®¹é•¿åº¦**: {len(article.get('content', ''))} å­—ç¬¦")
                                st.markdown("---")
                                st.text_area("å†…å®¹", article.get('content', ''), height=200, disabled=True)
                            
                            # å‘å¸ƒé€‰é¡¹
                            file_path = st.text_input(
                                "æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰",
                                value=f"content/{article.get('keyword', 'article').replace(' ', '_')[:50]}.md",
                                help="GitHubä»“åº“ä¸­çš„æ–‡ä»¶è·¯å¾„ï¼Œç•™ç©ºä½¿ç”¨é»˜è®¤è·¯å¾„",
                                key="github_file_path"
                            )
                            
                            if st.button("ğŸš€ å‘å¸ƒåˆ°GitHub", type="primary", use_container_width=True):
                                try:
                                    from platform_sync.github_publisher import GitHubPublisher
                                    publisher = GitHubPublisher(
                                        api_key=account_config['api_key'],
                                        repo_owner=account_config['config']['repo_owner'],
                                        repo_name=account_config['config']['repo_name']
                                    )
                                    
                                    with st.spinner("æ­£åœ¨å‘å¸ƒåˆ°GitHub..."):
                                        result = publisher.publish(
                                            content=article.get('content', ''),
                                            title=article.get('keyword', 'Untitled'),
                                            file_path=file_path if file_path else None
                                        )
                                    
                                    # ä¿å­˜å‘å¸ƒè®°å½•
                                    storage.save_publish_record(
                                        article_id=selected_article_id,
                                        platform="GitHub",
                                        publish_method="api",
                                        publish_status="success" if result['success'] else "failed",
                                        publish_url=result.get('publish_url', ''),
                                        publish_id=result.get('publish_id', ''),
                                        error_message=result.get('error', '')
                                    )
                                    
                                    # æ˜¾ç¤ºç»“æœ
                                    if result['success']:
                                        st.success(f"âœ… å‘å¸ƒæˆåŠŸï¼")
                                        st.markdown(f"**å‘å¸ƒé“¾æ¥**: [{result['publish_url']}]({result['publish_url']})")
                                        st.balloons()
                                    else:
                                        st.error(f"âŒ å‘å¸ƒå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                                except Exception as e:
                                    st.error(f"âŒ å‘å¸ƒè¿‡ç¨‹å‡ºé”™: {str(e)}")
                                    storage.save_publish_record(
                                        article_id=selected_article_id,
                                        platform="GitHub",
                                        publish_method="api",
                                        publish_status="failed",
                                        error_message=str(e)
                                    )
                else:
                    # ä¸€é”®å¤åˆ¶å¹³å°
                    article = next((a for a in articles if a.get('id') == selected_article_id), None)
                    if article:
                        from platform_sync.copy_manager import CopyManager
                        copy_manager = CopyManager()
                        
                        # æ ¼å¼åŒ–å†…å®¹
                        formatted_content = copy_manager.format_for_platform(
                            platform=publish_platform,
                            content=article.get('content', ''),
                            title=article.get('keyword', 'Untitled'),
                            keyword=article.get('keyword', ''),
                            brand=brand
                        )
                        
                        # æ˜¾ç¤ºæ ¼å¼åŒ–åçš„å†…å®¹
                        with st.expander("ğŸ“„ æ ¼å¼åŒ–åçš„å†…å®¹ï¼ˆå·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼‰", expanded=True):
                            st.text_area(
                                "å†…å®¹",
                                formatted_content,
                                height=300,
                                key="formatted_content_display"
                            )
                        
                        # å‘å¸ƒæŒ‡å—
                        guide = copy_manager.generate_publish_guide(publish_platform)
                        with st.expander("ğŸ“‹ å‘å¸ƒæŒ‡å—", expanded=True):
                            st.markdown(guide)
                        
                        # å¤åˆ¶æŒ‰é’®
                        col1, col2 = st.columns([1, 1])
                        with col1:
                            if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿", type="primary", use_container_width=True):
                                if copy_manager.copy_to_clipboard(formatted_content):
                                    st.success("âœ… å†…å®¹å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼")
                                    st.info("ğŸ’¡ è¯·æŒ‰ç…§ä¸Šæ–¹å‘å¸ƒæŒ‡å—ï¼Œå°†å†…å®¹ç²˜è´´åˆ°å¯¹åº”å¹³å°å‘å¸ƒ")
                                    
                                    # ä¿å­˜å‘å¸ƒè®°å½•ï¼ˆæ ‡è®°ä¸ºå·²å¤åˆ¶ï¼‰
                                    storage.save_publish_record(
                                        article_id=selected_article_id,
                                        platform=publish_platform,
                                        publish_method="copy",
                                        publish_status="copied",
                                        error_message=""
                                    )
                                else:
                                    st.error("âŒ å¤åˆ¶å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶å†…å®¹")
                        
                        with col2:
                            if st.button("ğŸ“¥ ä¸‹è½½å†…å®¹", use_container_width=True):
                                # ç”Ÿæˆä¸‹è½½æ–‡ä»¶
                                safe_title = article.get('keyword', 'article').replace(' ', '_')[:50]
                                filename = f"{publish_platform.replace('ï¼ˆ', '_').replace('ï¼‰', '')}_{safe_title}.txt"
                                st.download_button(
                                    label="â¬‡ï¸ ä¸‹è½½",
                                    data=formatted_content,
                                    file_name=filename,
                                    mime="text/plain",
                                    key="download_formatted_content"
                                )
        else:
            st.info("ğŸ“ è¯·å…ˆåœ¨ã€2 è‡ªåŠ¨åˆ›ä½œã€‘ä¸­ç”Ÿæˆæ–‡ç« ")
        
        # å‘å¸ƒè®°å½•
        st.markdown("---")
        st.markdown("#### ğŸ“Š å‘å¸ƒè®°å½•")
        
        publish_records = storage.get_publish_records(brand=brand)
        if publish_records:
            # ç»Ÿè®¡ä¿¡æ¯
            total_records = len(publish_records)
            success_records = len([r for r in publish_records if r.get('publish_status') == 'success'])
            copied_records = len([r for r in publish_records if r.get('publish_status') == 'copied'])
            failed_records = len([r for r in publish_records if r.get('publish_status') == 'failed'])
            
            stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
            with stat_col1:
                st.metric("æ€»å‘å¸ƒæ•°", total_records)
            with stat_col2:
                st.metric("APIæˆåŠŸ", success_records, delta=f"{success_records/total_records*100:.1f}%" if total_records > 0 else "0%")
            with stat_col3:
                st.metric("å·²å¤åˆ¶", copied_records, delta=f"{copied_records/total_records*100:.1f}%" if total_records > 0 else "0%")
            with stat_col4:
                st.metric("å¤±è´¥", failed_records)
            
            # è®°å½•åˆ—è¡¨
            st.markdown("##### æœ€è¿‘å‘å¸ƒè®°å½•")
            records_df = pd.DataFrame(publish_records[:20])  # æ˜¾ç¤ºæœ€è¿‘20æ¡
            if not records_df.empty:
                # æ ¼å¼åŒ–æ˜¾ç¤º
                display_df = records_df[['platform', 'publish_method', 'publish_status', 'publish_url', 'published_at', 'created_at']].copy()
                display_df.columns = ['å¹³å°', 'å‘å¸ƒæ–¹å¼', 'çŠ¶æ€', 'é“¾æ¥', 'å‘å¸ƒæ—¶é—´', 'åˆ›å»ºæ—¶é—´']
                display_df['çŠ¶æ€'] = display_df['çŠ¶æ€'].map({
                    'success': 'âœ… æˆåŠŸ',
                    'failed': 'âŒ å¤±è´¥',
                    'pending': 'â³ å¾…å‘å¸ƒ',
                    'copied': 'ğŸ“‹ å·²å¤åˆ¶'
                })
                display_df['å‘å¸ƒæ–¹å¼'] = display_df['å‘å¸ƒæ–¹å¼'].map({
                    'api': 'API',
                    'copy': 'ä¸€é”®å¤åˆ¶'
                })
                
                st.dataframe(display_df, use_container_width=True, hide_index=True)
        else:
            st.info("æš‚æ— å‘å¸ƒè®°å½•")

# =======================
# Tab10ï¼šé…ç½®ä¼˜åŒ–åŠ©æ‰‹
# =======================
with tab10:
    # é…ç½®ä¼˜åŒ–åŠ©æ‰‹ï¼ˆä¸å…¶ä»–Tabä¿æŒä¸€è‡´çš„æ ‡é¢˜æ ¼å¼ï¼‰
    st.markdown("### ğŸ¯ é…ç½®ä¼˜åŒ–åŠ©æ‰‹")
    st.caption("åˆ†æå“ç‰Œåå’Œä¼˜åŠ¿æ˜¯å¦ GEO å‹å¥½ï¼Œæä¾›ä¼˜åŒ–å»ºè®®ã€‚ä¼˜åŒ–åå¯ä¸€é”®åº”ç”¨åˆ°å…¨å±€é…ç½®ã€‚")
    
    # åˆå§‹åŒ–ä¼˜åŒ–ç»“æœå­˜å‚¨
    if "config_optimization_result" not in st.session_state:
        st.session_state.config_optimization_result = None
    
    # åˆå§‹åŒ–é…ç½®hashï¼ˆç”¨äºæ£€æµ‹é…ç½®å˜åŒ–ï¼‰
    if "config_hash" not in st.session_state:
        st.session_state.config_hash = None
    
    # è®¡ç®—å½“å‰é…ç½®çš„hashï¼ˆä½¿ç”¨cfgä¸­çš„æœ€æ–°å€¼ï¼‰
    import hashlib
    brand_for_hash = cfg.get("brand", "").strip() or brand or ""
    advantages_for_hash = cfg.get("advantages", "").strip() or advantages or ""
    current_config_str = f"{brand_for_hash}|{advantages_for_hash}|{cfg.get('competitors', '')}"
    current_config_hash = hashlib.md5(current_config_str.encode()).hexdigest()
    
    # å¦‚æœé…ç½®å˜åŒ–äº†ï¼Œæ¸…é™¤æ—§çš„ä¼˜åŒ–ç»“æœ
    # ä½†å¦‚æœæ˜¯å› ä¸ºåº”ç”¨ç‰ˆæœ¬å¯¼è‡´çš„é…ç½®å˜åŒ–ï¼Œä¿ç•™ä¼˜åŒ–ç»“æœ
    if st.session_state.config_hash != current_config_hash:
        # æ£€æŸ¥æ˜¯å¦æ˜¯åº”ç”¨ç‰ˆæœ¬å¯¼è‡´çš„é…ç½®å˜åŒ–
        if not st.session_state.get("_applying_version", False):
            st.session_state.config_optimization_result = None
        st.session_state.config_hash = current_config_hash
        # æ¸…é™¤åº”ç”¨ç‰ˆæœ¬æ ‡å¿—
        st.session_state["_applying_version"] = False
    
    # æ£€æŸ¥é…ç½®æ˜¯å¦æœ‰æ•ˆ
    if not st.session_state.cfg_valid:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ å®Œæˆé…ç½®å¹¶ç‚¹å‡»'åº”ç”¨é…ç½®'")
        st.info("é…ç½®ä¼˜åŒ–åŠ©æ‰‹éœ€è¦æœ‰æ•ˆçš„é…ç½®æ‰èƒ½è¿›è¡Œåˆ†æã€‚")
    else:
        # æ˜¾ç¤ºå½“å‰é…ç½®
        with st.expander("ğŸ“‹ å½“å‰é…ç½®", expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                brand_display = cfg.get("brand", "") or brand or "æœªè®¾ç½®"
                st.markdown(f"**å“ç‰Œå**ï¼š{brand_display}")
            with col2:
                st.markdown(f"**ç«å“æ•°é‡**ï¼š{len(competitor_list)}ä¸ª")
            advantages_display = cfg.get("advantages", "") or advantages or "æœªè®¾ç½®"
            st.markdown(f"**æ ¸å¿ƒä¼˜åŠ¿**ï¼š{advantages_display}")
            if competitor_list:
                st.markdown(f"**ç«å“åˆ—è¡¨**ï¼š{', '.join(competitor_list[:5])}{'...' if len(competitor_list) > 5 else ''}")
        
        # åˆ†ææŒ‰é’®
        col1, col2 = st.columns([1, 3])
        with col1:
            analyze_btn = st.button("ğŸ” åˆ†æé…ç½®ä¼˜åŒ–", type="primary", use_container_width=True, key="tab10_optimize_config")
        
        with col2:
            if st.session_state.config_optimization_result:
                st.success("âœ… å·²æœ‰ä¼˜åŒ–ç»“æœï¼Œå¯ç›´æ¥æŸ¥çœ‹ä¸‹æ–¹å»ºè®®")
        
        # æ‰§è¡Œåˆ†æ
        if analyze_btn:
            with st.spinner("æ­£åœ¨åˆ†æé…ç½®ï¼Œä¼˜åŒ–å»ºè®®ç”Ÿæˆä¸­..."):
                try:
                    from modules.config_optimizer import ConfigOptimizer
                    
                    optimizer = ConfigOptimizer()
                    
                    # ä»é…ç½®ä¸­è·å–å“ç‰Œåã€ä¼˜åŠ¿æè¿°å’Œç«å“åˆ—è¡¨ï¼ˆç¡®ä¿ä½¿ç”¨æœ€æ–°é…ç½®ï¼‰
                    brand_for_optimizer = cfg.get("brand", "").strip() or brand or ""
                    advantages_for_optimizer = cfg.get("advantages", "").strip() or advantages or ""
                    competitors_str = cfg.get("competitors", "")
                    competitor_list_for_optimizer = [c.strip() for c in competitors_str.split("\n") if c.strip()]
                    
                    # éªŒè¯å¿…è¦é…ç½®
                    if not brand_for_optimizer:
                        st.error("âŒ å“ç‰Œåä¸èƒ½ä¸ºç©ºï¼Œè¯·åœ¨ä¾§è¾¹æ é…ç½®ä¸»å“ç‰Œåç§°")
                        st.stop()
                    
                    if not advantages_for_optimizer:
                        st.warning("âš ï¸ ä¼˜åŠ¿æè¿°ä¸ºç©ºï¼Œå»ºè®®åœ¨ä¾§è¾¹æ é…ç½®æ ¸å¿ƒä¼˜åŠ¿/å–ç‚¹")
                    
                    # ä¸´æ—¶æ„å»ºLLMç”¨äºåˆ†æï¼ˆä½¿ç”¨å½“å‰é…ç½®ï¼‰
                    temp_llm = build_llm(
                        cfg["gen_provider"],
                        cfg["gen_api_key"],
                        model_defaults(cfg["gen_provider"]),
                        float(cfg.get("temperature", 0.7))
                    )
                    
                    result = optimizer.optimize_config(
                        brand=brand_for_optimizer,
                        advantages=advantages_for_optimizer,
                        competitors=competitor_list_for_optimizer,
                        llm_chain=temp_llm
                    )
                    st.session_state.config_optimization_result = result
                    st.session_state.config_hash = current_config_hash
                    st.success("âœ… é…ç½®åˆ†æå®Œæˆï¼")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ é…ç½®ä¼˜åŒ–åˆ†æå¤±è´¥ï¼š{e}")
                    import traceback
                    with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                        st.code(traceback.format_exc())
                    st.session_state.config_optimization_result = None
        
        # æ˜¾ç¤ºä¼˜åŒ–ç»“æœ
        if st.session_state.config_optimization_result:
            result = st.session_state.config_optimization_result
            if result.get("success", False):
                st.markdown("---")
                st.markdown("#### ğŸ“Š ä¼˜åŒ–åˆ†æç»“æœ")
                
                # è¯„ä¼°æ€»ç»“
                if result.get("summary"):
                    st.markdown("**ğŸ“ è¯„ä¼°æ€»ç»“**")
                    st.info(result["summary"])
                
                # ä¼˜åŒ–å»ºè®®
                if result.get("suggestions"):
                    st.markdown("**ğŸ’¡ ä¼˜åŒ–å»ºè®®**")
                    suggestions = result["suggestions"]
                    
                    if suggestions.get("brand", {}).get("problem"):
                        st.markdown("**ğŸ”¸ å“ç‰Œåé—®é¢˜**ï¼š")
                        # ç›´æ¥ä½¿ç”¨st.markdownæ¸²æŸ“ï¼ŒCSSä¼šé™åˆ¶æ ‡é¢˜å¤§å°
                        problem_text = suggestions["brand"]["problem"]
                        st.markdown(problem_text)
                        if suggestions["brand"].get("suggestion"):
                            st.markdown("**âœ… å»ºè®®**ï¼š")
                            suggestion_text = suggestions["brand"]["suggestion"]
                            st.markdown(suggestion_text)
                    
                    if suggestions.get("advantages", {}).get("problem"):
                        st.markdown("**ğŸ”¸ ä¼˜åŠ¿æè¿°é—®é¢˜**ï¼š")
                        problem_text = suggestions["advantages"]["problem"]
                        st.markdown(problem_text)
                        if suggestions["advantages"].get("suggestion"):
                            st.markdown("**âœ… å»ºè®®**ï¼š")
                            suggestion_text = suggestions["advantages"]["suggestion"]
                            st.markdown(suggestion_text)
                
                # æ¨èç‰ˆæœ¬
                recommended_versions = result.get("recommended_versions", [])
                if recommended_versions:
                    st.markdown("**ğŸ¯ æ¨èç‰ˆæœ¬**")
                    st.caption("é€‰æ‹©æœ€é€‚åˆçš„ç‰ˆæœ¬ï¼Œç‚¹å‡»ã€Œåº”ç”¨ç‰ˆæœ¬ã€æŒ‰é’®å³å¯æ›´æ–°é…ç½®")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ¨èç‰ˆæœ¬
                    valid_versions = [v for v in recommended_versions if v.get("brand") or v.get("advantages")]
                    if not valid_versions:
                        st.warning("âš ï¸ æ¨èç‰ˆæœ¬æ•°æ®ä¸ºç©ºï¼Œå¯èƒ½æ˜¯è§£æå¤±è´¥ã€‚è¯·æŸ¥çœ‹å®Œæ•´æŠ¥å‘Šæˆ–é‡æ–°åˆ†æã€‚")
                        if result.get("raw_result"):
                            with st.expander("æŸ¥çœ‹åŸå§‹è¾“å‡ºä¸­çš„æ¨èç‰ˆæœ¬éƒ¨åˆ†"):
                                raw = result["raw_result"]
                                if "ã€æ¨èç‰ˆæœ¬ã€‘" in raw:
                                    raw_versions = raw.split("ã€æ¨èç‰ˆæœ¬ã€‘")[1].split("ã€")[0]
                                    st.code(raw_versions)
                    
                    for i, version in enumerate(recommended_versions[:3], 1):
                        version_name_map = {
                            1: "ä¿å®ˆä¼˜åŒ–",
                            2: "å¹³è¡¡ä¼˜åŒ–",
                            3: "æ¿€è¿›ä¼˜åŒ–"
                        }
                        version_name = version_name_map.get(i, f"ç‰ˆæœ¬{i}")
                        
                        with st.expander(f"ç‰ˆæœ¬{i}ï¼š{version_name}", expanded=False):  # é»˜è®¤ä¸å±•å¼€ï¼Œç”¨æˆ·è‡ªè¡Œé€‰æ‹©
                            # æ£€æŸ¥ç‰ˆæœ¬æ•°æ®æ˜¯å¦æœ‰æ•ˆ
                            has_brand = bool(version.get("brand", "").strip())
                            has_advantages = bool(version.get("advantages", "").strip())
                            has_reason = bool(version.get("reason", "").strip())
                            
                            if not has_brand and not has_advantages:
                                st.warning("âš ï¸ è¯¥ç‰ˆæœ¬æ•°æ®ä¸å®Œæ•´ï¼Œè¯·æŸ¥çœ‹å®Œæ•´æŠ¥å‘Šæˆ–é‡æ–°åˆ†æ")
                                if result.get("raw_result"):
                                    with st.expander("æŸ¥çœ‹åŸå§‹è¾“å‡ºä¸­çš„è¯¥ç‰ˆæœ¬"):
                                        # å°è¯•ä»åŸå§‹è¾“å‡ºä¸­æå–
                                        raw = result["raw_result"]
                                        if f"ç‰ˆæœ¬{i}" in raw:
                                            version_raw = raw.split(f"ç‰ˆæœ¬{i}")[1]
                                            if i < 3:
                                                next_version = f"ç‰ˆæœ¬{i+1}"
                                                if next_version in version_raw:
                                                    version_raw = version_raw.split(next_version)[0]
                                            st.code(version_raw[:500])  # æ˜¾ç¤ºå‰500å­—ç¬¦
                            else:
                                col1, col2 = st.columns([2, 1])
                                with col1:
                                    if has_brand:
                                        st.markdown(f"**å“ç‰Œå**ï¼š`{version['brand']}`")
                                    else:
                                        st.warning("âš ï¸ å“ç‰Œåä¸ºç©º")
                                    
                                    if has_advantages:
                                        st.markdown(f"**ä¼˜åŠ¿æè¿°**ï¼š{version['advantages']}")
                                    else:
                                        st.warning("âš ï¸ ä¼˜åŠ¿æè¿°ä¸ºç©º")
                                    
                                    if has_reason:
                                        st.caption(f"ğŸ’­ ç†ç”±ï¼š{version['reason']}")
                                    else:
                                        st.caption("ğŸ’­ ç†ç”±ï¼šæœªæä¾›")
                                
                                with col2:
                                    # åº”ç”¨æŒ‰é’®
                                    apply_disabled = not (has_brand and has_advantages)
                                    if st.button(
                                        f"âœ… åº”ç”¨ç‰ˆæœ¬{i}", 
                                        key=f"tab10_apply_version_{i}", 
                                        use_container_width=True, 
                                        type="primary",
                                        disabled=apply_disabled
                                    ):
                                        if has_brand and has_advantages:
                                            # è®¾ç½®æ ‡å¿—ï¼Œè¡¨ç¤ºæ­£åœ¨åº”ç”¨ç‰ˆæœ¬ï¼ˆé˜²æ­¢ä¼˜åŒ–ç»“æœè¢«æ¸…é™¤ï¼‰
                                            st.session_state["_applying_version"] = True
                                            # æ›´æ–°é…ç½®
                                            st.session_state.cfg["brand"] = version["brand"]
                                            st.session_state.cfg["advantages"] = version["advantages"]
                                            # è®¾ç½®æ ‡å¿—ï¼Œè¡¨ç¤ºéœ€è¦æ›´æ–°ä¾§è¾¹æ è¾“å…¥æ¡†
                                            st.session_state["_pending_brand_update"] = version["brand"]
                                            st.session_state["_pending_advantages_update"] = version["advantages"]
                                            st.session_state.cfg_applied = False  # éœ€è¦é‡æ–°åº”ç”¨é…ç½®
                                            st.success(f"âœ… å·²åº”ç”¨ç‰ˆæœ¬{i}ï¼Œä¾§è¾¹æ å·²æ›´æ–°ï¼Œè¯·ç‚¹å‡»'åº”ç”¨é…ç½®'ä»¥ç”Ÿæ•ˆ")
                                            st.info("ğŸ’¡ é…ç½®æ›´æ–°åï¼Œå»ºè®®é‡æ–°è¿è¡Œå…³é”®è¯è’¸é¦å’Œå†…å®¹åˆ›ä½œï¼Œä»¥è·å¾—æœ€ä½³æ•ˆæœ")
                                            st.rerun()
                                    if apply_disabled:
                                        st.caption("âš ï¸ æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•åº”ç”¨")
                
                # é¢„æœŸæ•ˆæœ
                if result.get("expected_effects"):
                    st.markdown("**ğŸ“ˆ é¢„æœŸæ•ˆæœ**")
                    effects = result["expected_effects"]
                    # ä½¿ç”¨æ–‡æœ¬è€Œä¸æ˜¯ metricï¼Œé¿å…å†…å®¹è¢«æˆªæ–­
                    if effects.get("mention_rate"):
                        st.markdown(f"- æåŠç‡æå‡é¢„æœŸï¼š{effects['mention_rate']}")
                    if effects.get("geo_friendliness"):
                        st.markdown(f"- GEOå‹å¥½åº¦æå‡ï¼š{effects['geo_friendliness']}")
                
                # å®Œæ•´æŠ¥å‘Š
                if result.get("raw_result"):
                    with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´åˆ†ææŠ¥å‘Š", expanded=False):
                        st.markdown(result["raw_result"])
                        
                        # å¦‚æœæ¨èç‰ˆæœ¬ä¸ºç©ºæˆ–è§£æå¤±è´¥ï¼Œæ˜¾ç¤ºåŸå§‹è¾“å‡ºä¸­çš„æ¨èç‰ˆæœ¬éƒ¨åˆ†
                        recommended_versions = result.get("recommended_versions", [])
                        if not recommended_versions or all(
                            not v.get("brand") and not v.get("advantages") 
                            for v in recommended_versions
                        ):
                            st.warning("âš ï¸ æ¨èç‰ˆæœ¬è§£æå¤±è´¥ï¼Œä»¥ä¸‹æ˜¯åŸå§‹è¾“å‡ºä¸­çš„æ¨èç‰ˆæœ¬éƒ¨åˆ†ï¼Œè¯·æ£€æŸ¥æ ¼å¼ï¼š")
                            raw = result["raw_result"]
                            if "ã€æ¨èç‰ˆæœ¬ã€‘" in raw:
                                raw_versions = raw.split("ã€æ¨èç‰ˆæœ¬ã€‘")[1].split("ã€")[0]
                                st.code(raw_versions, language="text")
                                st.info("ğŸ’¡ å¦‚æœåŸå§‹è¾“å‡ºä¸­åŒ…å«æ¨èç‰ˆæœ¬ä½†è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ ¼å¼æ˜¯å¦ç¬¦åˆè¦æ±‚")
                
                # è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                if st.checkbox("ğŸ” æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯", key="tab10_debug"):
                    st.markdown("#### è°ƒè¯•ä¿¡æ¯")
                    debug_info = {
                        "æ¨èç‰ˆæœ¬æ•°é‡": len(result.get("recommended_versions", [])),
                        "ç‰ˆæœ¬è¯¦æƒ…": result.get("recommended_versions", []),
                        "é…ç½®hash": st.session_state.config_hash,
                        "è§£æé”™è¯¯": result.get("parse_errors", [])
                    }
                    st.json(debug_info)
                    
                    # æ˜¾ç¤ºåŸå§‹è¾“å‡ºçš„å…³é”®éƒ¨åˆ†
                    if result.get("raw_result"):
                        raw = result["raw_result"]
                        if "ã€æ¨èç‰ˆæœ¬ã€‘" in raw:
                            st.markdown("**åŸå§‹è¾“å‡ºä¸­çš„æ¨èç‰ˆæœ¬éƒ¨åˆ†ï¼š**")
                            raw_versions = raw.split("ã€æ¨èç‰ˆæœ¬ã€‘")[1].split("ã€")[0]
                            st.code(raw_versions[:1000], language="text")  # æ˜¾ç¤ºå‰1000å­—ç¬¦
            else:
                st.error(f"âŒ åˆ†æå¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                if result.get("raw_result"):
                    with st.expander("æŸ¥çœ‹åŸå§‹è¾“å‡º"):
                        st.code(result["raw_result"])
        else:
            st.info("ğŸ’¡ ç‚¹å‡»ä¸Šæ–¹ã€Œåˆ†æé…ç½®ä¼˜åŒ–ã€æŒ‰é’®å¼€å§‹åˆ†æï¼Œç³»ç»Ÿä¼šæ ¹æ®å½“å‰é…ç½®ç”Ÿæˆä¼˜åŒ–å»ºè®®ã€‚")
            st.caption("æç¤ºï¼šå½“æ‚¨ä¿®æ”¹å“ç‰Œåã€ä¼˜åŠ¿æè¿°æˆ–ç«å“åˆ—è¡¨åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ¸…é™¤æ—§ç»“æœï¼Œéœ€è¦é‡æ–°åˆ†æã€‚")

st.caption("æœ€å®Œæ•´ç‰ˆï¼šGitHubæ¨¡æ¿ + çœŸå®å¤šæ¨¡å‹éªŒè¯ + ç°æœ‰æ–‡ç« ä¼˜åŒ– â€¢ GEOå…¨é—­ç¯ï¼Œä¸“æ³¨AIå“ç‰Œå½±å“åŠ›")
